"""
Kosmos-2 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìº¡ì…”ë‹ (3ê°€ì§€ ì ‘ê·¼ ë°©ë²•)
1. ê¸°ë³¸ ì¶œë ¥
2. ë…¸ì´ì¦ˆ ì œê±° ë²„ì „
3. í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ë° ê°•í™”ëœ ì •ë¦¬
í•„ìš”í•œ íŒ¨í‚¤ì§€: transformers, accelerate, pillow, torchvision
"""

from transformers import AutoProcessor, AutoModelForVision2Seq
from PIL import Image
import torch
import re


def load_kosmos2_model(device):
    """Kosmos-2 ëª¨ë¸ ë¡œë“œ"""
    print("â³ Kosmos-2 ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    processor = AutoProcessor.from_pretrained("microsoft/kosmos-2-patch14-224")
    model = AutoModelForVision2Seq.from_pretrained(
        "microsoft/kosmos-2-patch14-224", 
        torch_dtype=torch.float16
    )
    model.to(device)
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
    return processor, model


def generate_caption_basic(image, processor, model, device):
    """ê¸°ë³¸ ìº¡ì…˜ ìƒì„± (ìµœì†Œ ì²˜ë¦¬)"""
    prompt = ""
    inputs = processor(text=prompt, images=image, return_tensors="pt")
    
    for k in inputs:
        inputs[k] = inputs[k].to(device)
    
    outputs = model.generate(**inputs, max_new_tokens=50)
    caption = processor.decode(outputs[0], skip_special_tokens=True)
    
    # ìµœì†Œí•œì˜ ì •ë¦¬: ì´ë¯¸ì§€ ê´€ë ¨ íŠ¹ìˆ˜ í† í°ë§Œ ì œê±°
    caption = caption.replace("<image>", "").replace("</image>", "").strip()
    
    return caption


def generate_caption_clean(image, processor, model, device):
    """ë…¸ì´ì¦ˆ ì œê±° ë²„ì „"""
    prompt = ""
    inputs = processor(text=prompt, images=image, return_tensors="pt")
    
    for k in inputs:
        inputs[k] = inputs[k].to(device)
    
    outputs = model.generate(**inputs, max_new_tokens=100)
    caption = processor.decode(outputs[0], skip_special_tokens=True)
    
    # ğŸŒŸ ë…¸ì´ì¦ˆ ë° ë¶ˆí•„ìš” ë¬¸ìì—´ ì œê±°
    # 1. íŠ¹ìˆ˜ í† í° ì œê±°
    caption = caption.replace("<image>", "").replace("</image>", "").replace("<grounding>", "").strip()
    
    # 2. HTML/XML íƒœê·¸ í˜•íƒœ ì œê±°
    caption = re.sub(r'<[^>]+>', '', caption).strip()
    
    # 3. ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ ì°¾ì•„ì„œ ê·¸ ì• ì œê±°
    match = re.search(r'[A-Z]', caption)
    if match:
        caption = caption[match.start():].strip()
    else:
        caption = re.sub(r'^\s*[\.,:;!]+\s*', '', caption).strip()
    
    # 4. ì†Œë¬¸ì ì‹œì‘ ë‹¨ì–´ ì •ë¦¬
    caption = re.sub(r'^(the|to|and|of|as|in|I|that|for|is|was|on|it)\s*', '', caption, flags=re.IGNORECASE).strip()
    
    return caption


def generate_caption_with_prompt(image, processor, model, device):
    """í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ë° ê°•í™”ëœ ë…¸ì´ì¦ˆ ì œê±°"""
    # ëª…í™•í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    prompt = "<grounding>A detailed description of the image, including all visible objects and their attributes:"
    
    inputs = processor(text=prompt, images=image, return_tensors="pt")
    
    for k in inputs:
        inputs[k] = inputs[k].to(device)
    
    outputs = model.generate(**inputs, max_new_tokens=150)
    caption = processor.decode(outputs[0], skip_special_tokens=True)
    
    # ğŸŒŸ ê°•í™”ëœ ë…¸ì´ì¦ˆ ë° ë¶ˆí•„ìš” ë¬¸ìì—´ ì œê±°
    # 1. íŠ¹ìˆ˜ í† í° ì œê±°
    caption = caption.replace("<image>", "").replace("</image>", "").replace("<grounding>", "").strip()
    
    # 2. HTML/XML íƒœê·¸ í˜•íƒœ ì œê±°
    caption = re.sub(r'<[^>]+>', '', caption).strip()
    
    # 3. ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ ì°¾ê¸°
    match = re.search(r'[A-Z]', caption)
    if match:
        caption = caption[match.start():].strip()
    else:
        caption = re.sub(r'^\s*[\.,:;!]+\s*', '', caption).strip()
    
    # 4. í”„ë¡¬í”„íŠ¸ê°€ ìº¡ì…˜ì— í¬í•¨ë  ê²½ìš° ì œê±°
    caption = re.sub(re.escape(prompt.replace("<grounding>", "")), '', caption, flags=re.IGNORECASE, count=1).strip()
    
    # 5. ì†Œë¬¸ì ì‹œì‘ ë‹¨ì–´ ì •ë¦¬
    caption = re.sub(r'^(the|to|and|of|as|in|I|that|for|is|was|on|it)\s*', '', caption, flags=re.IGNORECASE).strip()
    
    # 6. ë¬¸ì¥ ë ì •ë¦¬
    last_punc_match = re.search(r'[.?!](?=[^.?!]*$)', caption)
    if last_punc_match:
        caption = caption[:last_punc_match.end()].strip()
    
    return caption


def main(image_path):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"âœ… Using device: {device}")
    
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        image = Image.open(image_path).convert("RGB")
        print("âœ… ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {image_path}")
        return
    
    # ëª¨ë¸ ë¡œë“œ
    processor, model = load_kosmos2_model(device)
    
    # 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ìº¡ì…˜ ìƒì„±
    print("\nâ³ ìº¡ì…˜ ìƒì„± ì¤‘...")
    
    caption_basic = generate_caption_basic(image, processor, model, device)
    caption_clean = generate_caption_clean(image, processor, model, device)
    caption_prompt = generate_caption_with_prompt(image, processor, model, device)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 50)
    print("ğŸ“¸ Kosmos-2 Caption Comparison")
    print("=" * 50)
    print("\nğŸ”¸ Kosmos-2 Caption (ê¸°ë³¸ ì¶œë ¥):")
    print(caption_basic)
    print("\nğŸ”¸ Kosmos-2 Caption (ë…¸ì´ì¦ˆ ì œê±° í›„):")
    print(caption_clean)
    print("\nğŸ”¸ Kosmos-2 Caption (í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ë° ê°•í™”ëœ ì •ë¦¬):")
    print(caption_prompt)
    
    return {
        "basic": caption_basic,
        "clean": caption_clean,
        "prompt": caption_prompt
    }


if __name__ == "__main__":
    # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•¨)
    IMAGE_PATH = "/content/drive/MyDrive/Colab/T_V_T/htp/test_ë‚˜ë¬´.JPG"
    
    main(IMAGE_PATH)
