{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "avDiRdgZnqqe"
      ],
      "mount_file_id": "1QoDgAk1Qz8SiebfY6ny4J9Lgkd2uDR_c",
      "authorship_tag": "ABX9TyMjagO4/BlQ003KsRx+tOqv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이미지 파인튜닝"
      ],
      "metadata": {
        "id": "tXcX2Nwxns_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t2zrIt_F9eMi",
        "outputId": "7950c3f7-6cb2-44b8-e627-3581a0251304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.223-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.223-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.223 ultralytics-thop-2.0.18\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.2/index.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
            "  Downloading langchain_core-1.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (8.5.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
            "Downloading langchain-1.0.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.2-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, faiss-cpu, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed faiss-cpu-1.12.0 langchain-1.0.3 langchain-core-1.0.2 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.2/index.html\n",
        "!pip install opencv-python\n",
        "!pip install --upgrade langchain transformers sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OqmwkmVEXnk",
        "outputId": "925be97d-c46b-4e19-e2f4-5ff3e3e72efa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-6zg6kg7j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-6zg6kg7j\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit a9c0821a12ad353fb2a96f019515990d5460c5ac\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.0.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.2.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (8.3.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Collecting pytokens>=0.1.10 (from black->detectron2==0.6)\n",
            "  Downloading pytokens-0.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->detectron2==0.6) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytokens-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp312-cp312-linux_x86_64.whl size=6732684 sha256=e30b39b451d54344a83425f65872fc9e255261d78254fa4d29dcf90666096778\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yw0ilss7/wheels/d3/6e/bd/1969578f1456a6be2d6f083da65c669f450b23b8f3d1ac14c1\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=16319554725629db9abe2a9254ea8613363b6b205be34736e1b68e42df8a7f07\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built detectron2 fvcore\n",
            "Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed black-25.9.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-0.12.1 portalocker-3.2.0 pytokens-0.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2.git\n",
        "%cd detectron2\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdC53MolM3rz",
        "outputId": "898da69a-5ea3-4800-c86b-3274831aca79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15920, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 15920 (delta 0), reused 1 (delta 0), pack-reused 15912 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15920/15920), 6.69 MiB | 23.05 MiB/s, done.\n",
            "Resolving deltas: 100% (11329/11329), done.\n",
            "/content/detectron2\n",
            "Obtaining file:///content/detectron2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.0.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.2.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from detectron2==0.6) (25.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (8.3.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Collecting pytokens>=0.1.10 (from black->detectron2==0.6)\n",
            "  Downloading pytokens-0.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->detectron2==0.6) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.3)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytokens-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=09c48329dbae6fcc3a771583d07424c973ee979dd7024a64005799c7c2ecd628\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed black-25.9.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-0.12.1 portalocker-3.2.0 pytokens-0.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI4R8CkDFBLs",
        "outputId": "d553ab68-d1f1-4923-e205-27b5754079cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWFiyyQCOGGe",
        "outputId": "9a1ba009-c79f-4bda-e101-3234e599ea0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#개시 삭제\n",
        "!find /content/drive/MyDrive/Colab/T_V_T/train/labels -name \"*.cache\" -delete\n",
        "!find /content/drive/MyDrive/Colab/T_V_T/val/labels -name \"*.cache\" -delete\n"
      ],
      "metadata": {
        "id": "RPdYcMjr4U_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# YOLO 데이터 루트 경로 (본인 데이터 경로에 맞게 설정)\n",
        "data_root = \"/content/drive/MyDrive/Colab/T_V_T\"\n",
        "\n",
        "# train, val, test 모두 처리\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    labels_dir = os.path.join(data_root, split, \"labels\")\n",
        "    if not os.path.exists(labels_dir):\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n🔍 정리 중: {labels_dir}\")\n",
        "\n",
        "    # labels/ 하위 폴더 탐색 (예: 나무, 집, 사람 등)\n",
        "    for class_dir in os.listdir(labels_dir):\n",
        "        class_path = os.path.join(labels_dir, class_dir)\n",
        "        yolo_subdir = os.path.join(class_path, \"YOLO\")\n",
        "\n",
        "        # YOLO 하위 폴더가 존재할 경우 처리\n",
        "        if os.path.isdir(yolo_subdir):\n",
        "            txt_files = [f for f in os.listdir(yolo_subdir) if f.endswith(\".txt\")]\n",
        "            print(f\"  📁 {class_dir}/YOLO → {len(txt_files)}개 파일 이동 중...\")\n",
        "\n",
        "            # YOLO 폴더 안의 모든 txt를 한 단계 위로 이동\n",
        "            for f in txt_files:\n",
        "                src = os.path.join(yolo_subdir, f)\n",
        "                dst = os.path.join(class_path, f)\n",
        "                shutil.move(src, dst)\n",
        "\n",
        "            # YOLO 폴더 삭제\n",
        "            shutil.rmtree(yolo_subdir)\n",
        "\n",
        "    # .cache 파일 삭제\n",
        "    for cache_file in os.listdir(labels_dir):\n",
        "        if cache_file.endswith(\".cache\"):\n",
        "            cache_path = os.path.join(labels_dir, cache_file)\n",
        "            os.remove(cache_path)\n",
        "            print(f\"  🗑️ 캐시 삭제: {cache_file}\")\n",
        "\n",
        "print(\"\\n✅ 모든 라벨 구조 정리 완료!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOO0BbPbWdIk",
        "outputId": "63188e1a-8872-499e-9bb5-eca2c6947558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 정리 중: /content/drive/MyDrive/Colab/T_V_T/train/labels\n",
            "  📁 나무/YOLO → 8818개 파일 이동 중...\n",
            "  📁 남자사람/YOLO → 8818개 파일 이동 중...\n",
            "  📁 여자사람/YOLO → 8818개 파일 이동 중...\n",
            "  📁 집/YOLO → 8818개 파일 이동 중...\n",
            "  🗑️ 캐시 삭제: 나무.cache\n",
            "\n",
            "🔍 정리 중: /content/drive/MyDrive/Colab/T_V_T/val/labels\n",
            "  📁 남자사람/YOLO → 1890개 파일 이동 중...\n",
            "  📁 집/YOLO → 1890개 파일 이동 중...\n",
            "  📁 여자사람/YOLO → 1890개 파일 이동 중...\n",
            "  📁 나무/YOLO → 1890개 파일 이동 중...\n",
            "  🗑️ 캐시 삭제: 나무.cache\n",
            "\n",
            "🔍 정리 중: /content/drive/MyDrive/Colab/T_V_T/test/labels\n",
            "  📁 여자사람/YOLO → 1892개 파일 이동 중...\n",
            "  📁 집/YOLO → 1892개 파일 이동 중...\n",
            "  📁 남자사람/YOLO → 1892개 파일 이동 중...\n",
            "  📁 나무/YOLO → 1892개 파일 이동 중...\n",
            "\n",
            "✅ 모든 라벨 구조 정리 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/Colab/T_V_T -name \"*.cache\" -type f -delete\n"
      ],
      "metadata": {
        "id": "CgF8t68nX0dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. 환경 세팅\n",
        "# ===============================\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import detectron2\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "# ===============================\n",
        "# 2. 데이터 경로\n",
        "# ===============================\n",
        "data_root = r\"/content/drive/MyDrive/Colab/T_V_T\"\n",
        "yolo_train = os.path.join(data_root, \"train/images\")\n",
        "yolo_val   = os.path.join(data_root, \"val/images\")\n",
        "\n",
        "coco_train_json = os.path.join(data_root, \"train/labels/Detectron2/coco_train.json\")\n",
        "coco_val_json   = os.path.join(data_root, \"val/labels/Detectron2/coco_val.json\")\n",
        "coco_test_json  = os.path.join(data_root, \"test/labels/Detectron2/coco_test.json\")\n",
        "\n",
        "# ===============================\n",
        "# 2-1. YOLOv8용 데이터 YAML 생성\n",
        "# ===============================\n",
        "yolo_data_yaml = os.path.join(data_root, \"yolo_data.yaml\")\n",
        "yolo_data = {\n",
        "    'train': yolo_train,\n",
        "    'val': yolo_val,\n",
        "    'nc': 65,  # 클래스 개수\n",
        "    'names': [\n",
        "        # 집 관련\n",
        "        '집전체','지붕','집벽','문','창문','굴뚝','연기','울타리','길','연못','산','나무','꽃','잔디','태양',\n",
        "        # 나무 관련\n",
        "        '나무전체','기둥','수관','가지','뿌리','나뭇잎','꽃','열매','그네','새','다람쥐','구름','달','별',\n",
        "        # 여자사람 관련\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','여자구두',\n",
        "        # 남자사람 관련\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','남자구두'\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(yolo_data_yaml, 'w') as f:\n",
        "    yaml.dump(yolo_data, f)\n",
        "\n",
        "# ===============================\n",
        "# 3. YOLOv8 학습 (속도 최적화)\n",
        "# ===============================\n",
        "yolo_model = YOLO('yolov8s.pt')  # 중간 크기 모델\n",
        "\n",
        "yolo_model.train(\n",
        "    data=yolo_data_yaml,      # 데이터 YAML 경로\n",
        "    epochs=100,                # 에폭 단축 (50 -> 20)\n",
        "    patience=5,                # 5번 연속 개선 없으면 조기 종료\n",
        "    batch=-64,                 # 자동 배치 사이즈 (GPU VRAM 기준)\n",
        "    imgsz=640,                # 입력 이미지 크기 단축\n",
        "    project=os.path.join(data_root,\"YOLO_train\"),\n",
        "    name=\"yolo_TV_T_fast\",\n",
        "    exist_ok=True,\n",
        "    cache='disk'                # 이미지 캐시 사용으로 속도 향상\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 4. Detectron2 학습 (A100 최적화 + 얼리 스탑핑)\n",
        "# ===============================\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# COCO 데이터셋 등록\n",
        "register_coco_instances(\"TVT_train\", {}, coco_train_json, os.path.join(data_root, \"train/images\"))\n",
        "register_coco_instances(\"TVT_val\", {}, coco_val_json, os.path.join(data_root, \"val/images\"))\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# 데이터셋\n",
        "cfg.DATASETS.TRAIN = (\"TVT_train\",)\n",
        "cfg.DATASETS.TEST = (\"TVT_val\",)\n",
        "\n",
        "# 데이터 로딩\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
        "\n",
        "# 이미지 리사이징\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (640,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 1280\n",
        "cfg.INPUT.MIN_SIZE_TEST = 640\n",
        "cfg.INPUT.MAX_SIZE_TEST = 1280\n",
        "\n",
        "# 모델 설정\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 65\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "\n",
        "# 학습 하이퍼파라미터\n",
        "cfg.SOLVER.IMS_PER_BATCH = 32  # -1 대신 GPU 메모리에 맞게 설정 (예: 8)\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 2500\n",
        "cfg.SOLVER.AMP.ENABLED = True\n",
        "\n",
        "# 출력 경로\n",
        "cfg.OUTPUT_DIR = os.path.join(data_root, \"/content/drive/MyDrive/Colab/T_V_T/Detectron2_train\")\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 얼리 스탑핑 Trainer 정의\n",
        "# ===============================\n",
        "class EarlyStoppingTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg, patience=5):\n",
        "        super().__init__(cfg)\n",
        "        self.best_metric = 0.0\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
        "\n",
        "    def after_step(self):\n",
        "        super().after_step()\n",
        "        iteration = self.iter + 1\n",
        "\n",
        "        # 일정 간격으로 validation 평가\n",
        "        if iteration % 500 == 0 or iteration == cfg.SOLVER.MAX_ITER:\n",
        "            evaluator = self.build_evaluator(cfg, cfg.DATASETS.TEST[0])\n",
        "            val_results = self.test(cfg, self.model, evaluators=[evaluator])\n",
        "\n",
        "            # COCO mAP 가져오기\n",
        "            map_50 = val_results[\"bbox\"][\"AP50\"]\n",
        "\n",
        "            # 향상되면 저장\n",
        "            if map_50 > self.best_metric:\n",
        "                self.best_metric = map_50\n",
        "                self.counter = 0\n",
        "                torch.save(self.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                print(f\"✅ [Iteration {iteration}] mAP50 개선: {map_50:.4f}\")\n",
        "            else:\n",
        "                self.counter += 1\n",
        "                print(f\"⚠️ [Iteration {iteration}] 개선 없음 ({self.counter}/{self.patience})\")\n",
        "\n",
        "            # patience 초과 시 중단\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"🛑 얼리 스탑핑 발동 - 학습 중단\")\n",
        "                raise SystemExit\n",
        "\n",
        "# ===============================\n",
        "# 학습 실행\n",
        "# ===============================\n",
        "trainer = EarlyStoppingTrainer(cfg, patience=5)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WC6m_Np-RB8w",
        "outputId": "3c52dde9-c331-47ee-8a50-0350674b10cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.223 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-64, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Colab/T_V_T/yolo_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_TV_T_fast, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Colab/T_V_T/YOLO_train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=65\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2141203  ultralytics.nn.modules.head.Detect           [65, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,160,755 parameters, 11,160,739 gradients, 28.8 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 36.8±22.5 MB/s, size: 76.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/train/labels/나무.cache... 35272 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 35272/35272 57.6Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 0.81G reserved, 0.20G allocated, 38.54G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    11160755       28.78         1.013          25.6         21.71        (1, 3, 640, 640)                    list\n",
            "    11160755       57.57         1.325         23.22         22.95        (2, 3, 640, 640)                    list\n",
            "    11160755       115.1         1.904         24.89         22.92        (4, 3, 640, 640)                    list\n",
            "    11160755       230.3         3.041         26.62         27.03        (8, 3, 640, 640)                    list\n",
            "    11160755       460.6         5.421         29.85         35.52       (16, 3, 640, 640)                    list\n",
            "    11160755       921.1         9.206         37.73         62.21       (32, 3, 640, 640)                    list\n",
            "    11160755        1842        17.188         74.83         114.4       (64, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 86 for CUDA:0 23.96G/39.56G (61%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 39.5±25.6 MB/s, size: 81.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/train/labels/나무.cache... 35272 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 35272/35272 47.8Mit/s 0.0s\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0m242.2GB disk space required, with 50% safety margin but only 177.8/235.7GB free, not caching images to disk\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 52.5±30.7 MB/s, size: 73.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/val/labels/나무.cache... 7560 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7560/7560 10.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Colab/T_V_T/val/images/남자사람/남자사람_12_남_07461.jpg: 1 duplicate labels removed\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (34.6GB Disk): 100% ━━━━━━━━━━━━ 7560/7560 3.4Kit/s 2.3s\n",
            "Plotting labels to /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0006718750000000001), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 127.3MB/s 0.0s\n",
            "\u001b[K      1/100      28.3G     0.9312      1.801      1.093        343        640: 100% ━━━━━━━━━━━━ 411/411 0.0it/s 2:24:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.2it/s 38.1s\n",
            "                   all       7560     184090      0.858      0.835      0.886      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      21.3G     0.7577     0.6964     0.9777        466        640: 100% ━━━━━━━━━━━━ 411/411 0.5it/s 12:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 35.1s\n",
            "                   all       7560     184090       0.91      0.898      0.941       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      22.9G     0.7628     0.6395     0.9784        423        640: 100% ━━━━━━━━━━━━ 411/411 0.8it/s 8:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 34.9s\n",
            "                   all       7560     184090      0.912      0.889      0.938      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      22.8G     0.7523     0.6075     0.9784        361        640: 100% ━━━━━━━━━━━━ 411/411 1.2it/s 5:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.9s\n",
            "                   all       7560     184090      0.905      0.884      0.935      0.774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      21.3G     0.7238     0.5641     0.9681        383        640: 100% ━━━━━━━━━━━━ 411/411 1.4it/s 4:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.4s\n",
            "                   all       7560     184090      0.926      0.902      0.948      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      21.6G     0.7085     0.5414     0.9628        407        640: 100% ━━━━━━━━━━━━ 411/411 1.5it/s 4:42\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.2s\n",
            "                   all       7560     184090      0.937       0.92       0.96      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      21.6G     0.6923     0.5213     0.9567        481        640: 100% ━━━━━━━━━━━━ 411/411 1.4it/s 4:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.3s\n",
            "                   all       7560     184090      0.932      0.919      0.961      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      21.3G     0.6832     0.5072      0.953        534        640: 100% ━━━━━━━━━━━━ 411/411 1.6it/s 4:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 34.6s\n",
            "                   all       7560     184090      0.695      0.565      0.645      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      22.3G     0.6758     0.4982     0.9513        415        640: 100% ━━━━━━━━━━━━ 411/411 2.3it/s 3:00\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 34.3s\n",
            "                   all       7560     184090      0.914      0.877      0.931       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      22.7G     0.6704     0.4885     0.9485        387        640: 100% ━━━━━━━━━━━━ 411/411 2.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.2it/s 37.5s\n",
            "                   all       7560     184090      0.647      0.478      0.547      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      20.8G      0.662     0.4805     0.9458        376        640: 100% ━━━━━━━━━━━━ 411/411 2.4it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.2s\n",
            "                   all       7560     184090      0.952       0.94      0.971      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      21.1G     0.6598     0.4757     0.9448        360        640: 100% ━━━━━━━━━━━━ 411/411 1.6it/s 4:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.1it/s 40.1s\n",
            "                   all       7560     184090      0.736      0.633      0.711      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      22.1G      0.656     0.4706      0.943        414        640: 100% ━━━━━━━━━━━━ 411/411 1.6it/s 4:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.9s\n",
            "                   all       7560     184090      0.956       0.95      0.977      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      21.3G     0.6518     0.4663      0.942        402        640: 100% ━━━━━━━━━━━━ 411/411 1.7it/s 3:60\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.6s\n",
            "                   all       7560     184090       0.96      0.949      0.978       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      20.8G      0.648       0.46     0.9397        554        640: 100% ━━━━━━━━━━━━ 411/411 1.7it/s 3:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.959      0.951      0.978       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      22.6G     0.6467     0.4601     0.9408        566        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 32.0s\n",
            "                   all       7560     184090      0.957      0.944      0.973      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      21.8G     0.6448     0.4554     0.9386        459        640: 100% ━━━━━━━━━━━━ 411/411 1.7it/s 3:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 30.9s\n",
            "                   all       7560     184090      0.961      0.952      0.978      0.862\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      21.6G     0.6421     0.4522     0.9379        420        640: 100% ━━━━━━━━━━━━ 411/411 1.6it/s 4:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.2it/s 35.5s\n",
            "                   all       7560     184090       0.76       0.67      0.745      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      22.1G     0.6398     0.4481     0.9369        435        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.5s\n",
            "                   all       7560     184090      0.963      0.954       0.98      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      21.1G     0.6383     0.4466     0.9358        537        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 32.7s\n",
            "                   all       7560     184090      0.962      0.954      0.979      0.858\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      21.2G     0.6355     0.4415     0.9354        500        640: 100% ━━━━━━━━━━━━ 411/411 2.0it/s 3:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 33.7s\n",
            "                   all       7560     184090      0.964      0.957      0.981      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      22.7G     0.6336     0.4407     0.9347        284        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 32.7s\n",
            "                   all       7560     184090      0.965      0.955       0.98       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      21.1G     0.6331     0.4401     0.9341        449        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 32.4s\n",
            "                   all       7560     184090      0.965      0.957      0.982      0.872\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100        22G       0.63     0.4363     0.9327        392        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.965      0.958      0.982      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      22.1G     0.6276     0.4337     0.9323        499        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 32.1s\n",
            "                   all       7560     184090      0.965      0.959      0.982      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      24.3G     0.6279     0.4332     0.9326        490        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.9s\n",
            "                   all       7560     184090      0.967      0.957       0.98      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100        21G      0.625     0.4306     0.9312        477        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.3it/s 32.9s\n",
            "                   all       7560     184090      0.965      0.957       0.98      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      21.3G     0.6249     0.4281     0.9306        544        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:43\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.4s\n",
            "                   all       7560     184090      0.967       0.96      0.983      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      21.4G     0.6227     0.4264     0.9299        495        640: 100% ━━━━━━━━━━━━ 411/411 2.0it/s 3:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 32.1s\n",
            "                   all       7560     184090      0.967       0.96      0.983      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      21.6G     0.6204     0.4257     0.9288        441        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.9s\n",
            "                   all       7560     184090      0.968       0.96      0.983       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      21.2G     0.6203     0.4236     0.9288        465        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090      0.968       0.96      0.983       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      20.9G     0.6203     0.4232     0.9299        386        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.4s\n",
            "                   all       7560     184090      0.968      0.961      0.983      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      21.5G     0.6187     0.4214     0.9289        392        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.9s\n",
            "                   all       7560     184090      0.967      0.958      0.982      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      21.6G     0.6165     0.4176     0.9266        446        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.5s\n",
            "                   all       7560     184090      0.968      0.961      0.983      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      21.5G      0.616     0.4194     0.9272        529        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.5s\n",
            "                   all       7560     184090      0.968      0.961      0.983      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      21.4G     0.6135     0.4145     0.9269        397        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.969      0.962      0.984      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      20.8G     0.6136      0.416     0.9265        440        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 30.9s\n",
            "                   all       7560     184090      0.969      0.962      0.984      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      20.8G      0.614     0.4153     0.9268        461        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.4s\n",
            "                   all       7560     184090      0.969      0.962      0.984      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      20.9G     0.6115     0.4126     0.9262        474        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.9s\n",
            "                   all       7560     184090      0.969      0.962      0.984      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      21.2G     0.6107     0.4125     0.9259        552        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.2s\n",
            "                   all       7560     184090      0.969      0.962      0.984      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      22.7G     0.6102     0.4112     0.9257        463        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090      0.968      0.963      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      21.1G     0.6096     0.4094     0.9247        336        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.0s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100        21G     0.6089     0.4091     0.9248        616        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.8s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      21.9G     0.6068     0.4068     0.9239        448        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.8s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      22.9G     0.6051     0.4061     0.9235        373        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 32.1s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      21.3G     0.6035     0.4046     0.9235        414        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.2s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100        21G     0.6024     0.4032     0.9229        302        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.969      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      21.5G     0.6002     0.4017     0.9219        320        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.5it/s 30.1s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100        22G     0.5988     0.4002     0.9226        447        640: 100% ━━━━━━━━━━━━ 411/411 1.7it/s 3:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.5it/s 30.3s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      21.7G     0.5984        0.4     0.9224        506        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:43\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.4s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      21.3G     0.5954     0.3984     0.9216        475        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100      21.1G     0.5979     0.3991     0.9216        342        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.2s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      21.1G     0.5946     0.3963     0.9209        526        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.8s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      22.4G     0.5931     0.3949       0.92        359        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      21.4G      0.592     0.3928     0.9195        451        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.2s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      21.5G     0.5917     0.3935     0.9195        452        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.5s\n",
            "                   all       7560     184090       0.97      0.963      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      23.7G     0.5908     0.3912     0.9188        349        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.4s\n",
            "                   all       7560     184090       0.97      0.964      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      22.6G      0.591     0.3919     0.9188        419        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090       0.97      0.964      0.984      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      21.8G     0.5885     0.3886     0.9179        495        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.6s\n",
            "                   all       7560     184090      0.971      0.963      0.985      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      22.6G     0.5863     0.3883     0.9185        489        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      21.4G     0.5868     0.3885     0.9183        393        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.7s\n",
            "                   all       7560     184090      0.971      0.963      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      21.5G     0.5875     0.3875     0.9183        374        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.2s\n",
            "                   all       7560     184090      0.971      0.963      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      21.9G     0.5838     0.3846      0.917        529        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      20.9G     0.5813      0.383     0.9159        415        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.3s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      22.1G     0.5815     0.3823     0.9163        429        640: 100% ━━━━━━━━━━━━ 411/411 2.0it/s 3:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.8s\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      20.7G     0.5806     0.3814     0.9156        514        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 30.4s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      22.4G      0.581     0.3806      0.916        412        640: 100% ━━━━━━━━━━━━ 411/411 1.8it/s 3:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.4it/s 31.6s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      22.8G     0.5785     0.3788     0.9145        500        640: 100% ━━━━━━━━━━━━ 411/411 1.9it/s 3:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 44/44 1.5it/s 30.3s\n",
            "                   all       7560     184090      0.971      0.964      0.985      0.887\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2953311075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0myolo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8s.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 중간 크기 모델\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m yolo_model.train(\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myolo_data_yaml\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# 데이터 YAML 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0;31m# 에폭 단축 (50 -> 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_recovery_attempts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_loss_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36msave_metrics\u001b[0;34m(self, metrics)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ensure parent directory exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s,\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%.6g,\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#코드 멈췄을 때 이어서\n",
        "\n",
        "# ===============================\n",
        "# YOLOv8: 이전 학습 이어서 실행\n",
        "# ===============================\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# 경로 설정 (기존 그대로)\n",
        "data_root = r\"/content/drive/MyDrive/Colab/T_V_T\"\n",
        "yolo_data_yaml = os.path.join(data_root, \"yolo_data.yaml\")\n",
        "\n",
        "# ✅ 저장된 가중치 경로 (last.pt 또는 best.pt)\n",
        "last_model_path = os.path.join(\n",
        "    data_root,\n",
        "    \"/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/last.pt\"\n",
        ")\n",
        "\n",
        "# ✅ 모델 불러오기\n",
        "yolo_model = YOLO(last_model_path)\n",
        "\n",
        "# ✅ 기존 조건 그대로 이어서 학습\n",
        "yolo_model.train(\n",
        "    data=yolo_data_yaml,\n",
        "    epochs=100,                # 원래 목표 Epoch 그대로\n",
        "    patience=5,\n",
        "    batch=-64,\n",
        "    imgsz=640,\n",
        "    resume=True,\n",
        "    project=os.path.join(data_root, \"YOLO_train\"),\n",
        "    name=\"yolo_TV_T_fast\",\n",
        "    exist_ok=True,\n",
        "    cache='disk'               # 기존 cache 옵션도 그대로\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A09NTEua90-o",
        "outputId": "ec9019e7-efdd-41f5-b1a9-8af4881f35fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.223 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-64, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Colab/T_V_T/yolo_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_TV_T_fast, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/Colab/T_V_T/YOLO_train, rect=False, resume=/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2141203  ultralytics.nn.modules.head.Detect           [65, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,160,755 parameters, 11,160,739 gradients, 28.8 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 42.9±23.7 MB/s, size: 76.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/train/labels/나무.cache... 35272 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 35272/35272 53.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA A100-SXM4-40GB) 39.56G total, 16.75G reserved, 11.53G allocated, 11.28G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "    11160755       28.78        26.370         26.16         21.31        (1, 3, 640, 640)                    list\n",
            "    11160755       57.57        26.386         21.64         23.45        (2, 3, 640, 640)                    list\n",
            "    11160755       115.1        26.644         20.67         22.79        (4, 3, 640, 640)                    list\n",
            "    11160755       230.3        27.601         25.93          25.5        (8, 3, 640, 640)                    list\n",
            "    11160755       460.6        29.815         34.47         40.62       (16, 3, 640, 640)                    list\n",
            "    11160755       921.1        33.598         39.05         63.97       (32, 3, 640, 640)                    list\n",
            "    11160755        1842        41.494         74.73         114.4       (64, 3, 640, 640)                    list\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mAutoBatch: \u001b[0mbatch=-78 outside safe range, using default batch-size 16.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 16 for CUDA:0 58.00G/39.56G (147%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 38.6±21.5 MB/s, size: 81.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/train/labels/나무.cache... 35272 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 35272/35272 43.6Mit/s 0.0s\n",
            "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0m242.2GB disk space required, with 50% safety margin but only 150.8/235.7GB free, not caching images to disk\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.1 ms, read: 8.6±6.3 MB/s, size: 73.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/val/labels/나무.cache... 7560 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7560/7560 8.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/Colab/T_V_T/val/images/남자사람/남자사람_12_남_07461.jpg: 1 duplicate labels removed\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (34.6GB Disk): 100% ━━━━━━━━━━━━ 7560/7560 2.7Kit/s 2.8s\n",
            "Plotting labels to /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Resuming training /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/last.pt from epoch 68 to 100 total epochs\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      16.1G     0.5911     0.3896     0.9209        174        640: 100% ━━━━━━━━━━━━ 2205/2205 9.1it/s 4:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      16.7G     0.5917     0.3921     0.9201        252        640: 100% ━━━━━━━━━━━━ 2205/2205 3.9it/s 9:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 3.0it/s 1:20\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      16.7G     0.5916     0.3926     0.9202        435        640: 100% ━━━━━━━━━━━━ 2205/2205 3.7it/s 9:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.9it/s 1:22\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      16.7G       0.59     0.3927     0.9206        233        640: 100% ━━━━━━━━━━━━ 2205/2205 3.9it/s 9:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.9it/s 1:22\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      16.7G     0.5891       0.39     0.9192        315        640: 100% ━━━━━━━━━━━━ 2205/2205 7.5it/s 4:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.8it/s 1:25\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      16.7G     0.5887     0.3894     0.9196        344        640: 100% ━━━━━━━━━━━━ 2205/2205 6.8it/s 5:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.9it/s 1:22\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      16.7G     0.5855     0.3876     0.9185        312        640: 100% ━━━━━━━━━━━━ 2205/2205 7.1it/s 5:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.9it/s 1:22\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      16.7G     0.5868     0.3867     0.9185        400        640: 100% ━━━━━━━━━━━━ 2205/2205 7.5it/s 4:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.8it/s 1:24\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      16.7G     0.5846     0.3851     0.9181        181        640: 100% ━━━━━━━━━━━━ 2205/2205 7.0it/s 5:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:28\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      16.7G     0.5837     0.3831     0.9174        296        640: 100% ━━━━━━━━━━━━ 2205/2205 6.6it/s 5:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:28\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100      16.7G     0.5805      0.381     0.9168        401        640: 100% ━━━━━━━━━━━━ 2205/2205 6.9it/s 5:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:32\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      16.7G     0.5821     0.3816     0.9163        240        640: 100% ━━━━━━━━━━━━ 2205/2205 7.0it/s 5:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      16.7G     0.5799     0.3788     0.9156        254        640: 100% ━━━━━━━━━━━━ 2205/2205 6.9it/s 5:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.964      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100      16.7G     0.5781     0.3772     0.9155        447        640: 100% ━━━━━━━━━━━━ 2205/2205 7.1it/s 5:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100      16.7G     0.5752     0.3749     0.9142        268        640: 100% ━━━━━━━━━━━━ 2205/2205 7.2it/s 5:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:33\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      16.7G     0.5759     0.3752     0.9154        269        640: 100% ━━━━━━━━━━━━ 2205/2205 7.2it/s 5:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      16.7G      0.574     0.3726     0.9144        352        640: 100% ━━━━━━━━━━━━ 2205/2205 7.2it/s 5:05\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      16.7G     0.5718     0.3709     0.9133        332        640: 100% ━━━━━━━━━━━━ 2205/2205 7.3it/s 5:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.4it/s 1:37\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100      16.7G      0.572     0.3702     0.9136        351        640: 100% ━━━━━━━━━━━━ 2205/2205 6.8it/s 5:26\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100      16.7G     0.5704     0.3672     0.9125        272        640: 100% ━━━━━━━━━━━━ 2205/2205 6.8it/s 5:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.5it/s 1:34\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100      16.7G      0.568     0.3652     0.9115        330        640: 100% ━━━━━━━━━━━━ 2205/2205 7.6it/s 4:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100      16.7G     0.5656     0.3633     0.9102        322        640: 100% ━━━━━━━━━━━━ 2205/2205 8.2it/s 4:30\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      16.7G     0.5651     0.3629      0.911        275        640: 100% ━━━━━━━━━━━━ 2205/2205 8.1it/s 4:32\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.5it/s 1:35\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.889\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      16.7G     0.5181      0.301     0.8742        190        640: 100% ━━━━━━━━━━━━ 2205/2205 8.2it/s 4:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:32\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      16.7G     0.5151     0.2971     0.8734        168        640: 100% ━━━━━━━━━━━━ 2205/2205 8.6it/s 4:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:28\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100      16.7G     0.5127     0.2941     0.8732        189        640: 100% ━━━━━━━━━━━━ 2205/2205 8.5it/s 4:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.965      0.985      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100      16.7G     0.5106     0.2924     0.8725        184        640: 100% ━━━━━━━━━━━━ 2205/2205 8.8it/s 4:11\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:28\n",
            "                   all       7560     184090      0.972      0.966      0.985      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      16.7G     0.5072     0.2888     0.8711        239        640: 100% ━━━━━━━━━━━━ 2205/2205 8.9it/s 4:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:30\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      16.7G     0.5059     0.2876     0.8705        205        640: 100% ━━━━━━━━━━━━ 2205/2205 8.4it/s 4:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:28\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      16.7G     0.5024     0.2841     0.8688        186        640: 100% ━━━━━━━━━━━━ 2205/2205 8.2it/s 4:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:29\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      16.7G     0.5006     0.2822     0.8686        189        640: 100% ━━━━━━━━━━━━ 2205/2205 8.7it/s 4:13\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:31\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100      16.7G      0.499     0.2805     0.8681        205        640: 100% ━━━━━━━━━━━━ 2205/2205 8.9it/s 4:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.6it/s 1:33\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100      16.7G     0.4966     0.2784     0.8681        170        640: 100% ━━━━━━━━━━━━ 2205/2205 8.6it/s 4:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.7it/s 1:29\n",
            "                   all       7560     184090      0.972      0.966      0.985       0.89\n",
            "\n",
            "33 epochs completed in 3.710 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast/weights/best.pt...\n",
            "Ultralytics 8.3.223 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 72 layers, 11,150,739 parameters, 0 gradients, 28.6 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 2.3it/s 1:43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48533 (\\N{HANGUL SYLLABLE BUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48317 (\\N{HANGUL SYLLABLE BYEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47928 (\\N{HANGUL SYLLABLE MUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52285 (\\N{HANGUL SYLLABLE CANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44404 (\\N{HANGUL SYLLABLE GUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46749 (\\N{HANGUL SYLLABLE DDUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47803 (\\N{HANGUL SYLLABLE MOS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44867 (\\N{HANGUL SYLLABLE GGOC}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51092 (\\N{HANGUL SYLLABLE JAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46181 (\\N{HANGUL SYLLABLE DUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49100 (\\N{HANGUL SYLLABLE BBU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47943 (\\N{HANGUL SYLLABLE MUS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51086 (\\N{HANGUL SYLLABLE IP}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50676 (\\N{HANGUL SYLLABLE YEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49352 (\\N{HANGUL SYLLABLE SAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46988 (\\N{HANGUL SYLLABLE RAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51536 (\\N{HANGUL SYLLABLE JWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44396 (\\N{HANGUL SYLLABLE GU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45804 (\\N{HANGUL SYLLABLE DAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47672 (\\N{HANGUL SYLLABLE MEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50620 (\\N{HANGUL SYLLABLE EOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45576 (\\N{HANGUL SYLLABLE NUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51077 (\\N{HANGUL SYLLABLE IB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46973 (\\N{HANGUL SYLLABLE RAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47785 (\\N{HANGUL SYLLABLE MOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45800 (\\N{HANGUL SYLLABLE DAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50868 (\\N{HANGUL SYLLABLE UN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50668 (\\N{HANGUL SYLLABLE YEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46160 (\\N{HANGUL SYLLABLE DU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48533 (\\N{HANGUL SYLLABLE BUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48317 (\\N{HANGUL SYLLABLE BYEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47928 (\\N{HANGUL SYLLABLE MUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52285 (\\N{HANGUL SYLLABLE CANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44404 (\\N{HANGUL SYLLABLE GUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46749 (\\N{HANGUL SYLLABLE DDUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47803 (\\N{HANGUL SYLLABLE MOS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44867 (\\N{HANGUL SYLLABLE GGOC}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51092 (\\N{HANGUL SYLLABLE JAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46181 (\\N{HANGUL SYLLABLE DUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49100 (\\N{HANGUL SYLLABLE BBU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47943 (\\N{HANGUL SYLLABLE MUS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51086 (\\N{HANGUL SYLLABLE IP}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50676 (\\N{HANGUL SYLLABLE YEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49352 (\\N{HANGUL SYLLABLE SAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46988 (\\N{HANGUL SYLLABLE RAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51536 (\\N{HANGUL SYLLABLE JWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44396 (\\N{HANGUL SYLLABLE GU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45804 (\\N{HANGUL SYLLABLE DAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47672 (\\N{HANGUL SYLLABLE MEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50620 (\\N{HANGUL SYLLABLE EOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45576 (\\N{HANGUL SYLLABLE NUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51077 (\\N{HANGUL SYLLABLE IB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46973 (\\N{HANGUL SYLLABLE RAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47785 (\\N{HANGUL SYLLABLE MOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45800 (\\N{HANGUL SYLLABLE DAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50868 (\\N{HANGUL SYLLABLE UN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50668 (\\N{HANGUL SYLLABLE YEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46160 (\\N{HANGUL SYLLABLE DU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       7560     184090      0.972      0.967      0.985       0.89\n",
            "                   집전체       1890       1890      0.996          1      0.995      0.983\n",
            "                    지붕       1890       1911      0.991      0.992      0.995      0.971\n",
            "                    집벽       1890       1907      0.988       0.99      0.994      0.973\n",
            "                     문       1890       1926      0.986      0.989      0.994      0.939\n",
            "                    창문       1890       3120      0.967      0.979      0.991      0.911\n",
            "                    굴뚝       1890       1904      0.979      0.982       0.99      0.939\n",
            "                    연기       1890       1904       0.97      0.975       0.99       0.91\n",
            "                   울타리       1890       2769      0.922      0.933      0.967      0.891\n",
            "                     길       1890       1962      0.928      0.935      0.974      0.911\n",
            "                    연못       1890       1907      0.977      0.988      0.993      0.969\n",
            "                     산       1890       2192      0.895      0.932      0.965      0.883\n",
            "                    나무       1890       2342      0.982      0.984      0.994      0.958\n",
            "                    잔디       1890       7520      0.919      0.895       0.94      0.752\n",
            "                    태양       1890       1896      0.981      0.989      0.994      0.956\n",
            "                  나무전체       1890       1890      0.991      0.998      0.994      0.961\n",
            "                    기둥       1890       1890      0.983      0.984      0.993      0.822\n",
            "                    수관       1890       2010      0.981      0.985      0.994      0.977\n",
            "                    가지       1890       2930      0.926      0.909      0.958      0.787\n",
            "                    뿌리       1890       1918      0.976      0.986      0.991      0.869\n",
            "                   나뭇잎       1890       5550      0.941      0.895      0.955      0.772\n",
            "                     꽃       3780       7674      0.975      0.965       0.99      0.897\n",
            "                    열매       1890       6323      0.946      0.915      0.969      0.798\n",
            "                    그네       1890       1908      0.987      0.992      0.994      0.949\n",
            "                     새       1890       2060      0.966      0.965      0.987      0.915\n",
            "                   다람쥐       1890       1930      0.964      0.976      0.991      0.923\n",
            "                    구름       1890       3467      0.982      0.983      0.994      0.943\n",
            "                     달       1890       1899      0.968      0.988      0.993      0.926\n",
            "                     별       1890       5868      0.985       0.99      0.993      0.847\n",
            "                  여자구두       1890       3784       0.95      0.922      0.978        0.9\n",
            "                  사람전체       3780       3780      0.999          1      0.995      0.991\n",
            "                    머리       3780       3780      0.999          1      0.995      0.981\n",
            "                    얼굴       3780       3780      0.999          1      0.995      0.966\n",
            "                     눈       3780       7559      0.975      0.916      0.974      0.774\n",
            "                     코       3780       3780      0.981      0.848      0.959      0.696\n",
            "                     입       3780       3781      0.993       0.95      0.992      0.828\n",
            "                     귀       3780       7523       0.99      0.984      0.994      0.798\n",
            "                  머리카락       3780       3781      0.986      0.993      0.993       0.95\n",
            "                     목       3780       3780      0.992      0.985      0.994      0.754\n",
            "                    상체       3780       3780       0.99      0.991      0.995      0.961\n",
            "                     팔       3780       7559      0.997      0.996      0.995       0.93\n",
            "                     손       3780       7539      0.991      0.989      0.994      0.851\n",
            "                    다리       3780       7557      0.973      0.977      0.992      0.935\n",
            "                     발       3780       7559       0.99      0.986      0.993      0.853\n",
            "                    단추       3780       3939      0.972      0.927      0.967      0.793\n",
            "                   주머니       3780       7012      0.979       0.97      0.987      0.779\n",
            "                   운동화       3780       7566      0.969      0.979      0.989      0.907\n",
            "                  남자구두       1890       3784      0.894      0.926      0.957      0.871\n",
            "Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f775d610320>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,     0.99736,     0.99736,           0],\n",
              "       [          1,           1,           1, ...,     0.84687,     0.69663,           0],\n",
              "       [          1,           1,           1, ...,     0.50815,     0.25408,           0],\n",
              "       ...,\n",
              "       [          1,           1,           1, ...,     0.15866,    0.079329,           0],\n",
              "       [          1,           1,           1, ...,     0.77303,     0.41457,           0],\n",
              "       [          1,           1,           1, ...,     0.40228,     0.24888,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94264,     0.94264,     0.96576, ...,           0,           0,           0],\n",
              "       [    0.84245,     0.84245,     0.89858, ...,           0,           0,           0],\n",
              "       [    0.79832,     0.79832,     0.87222, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.65277,     0.65277,     0.73012, ...,           0,           0,           0],\n",
              "       [    0.79241,     0.79241,     0.86044, ...,           0,           0,           0],\n",
              "       [    0.56527,     0.56527,     0.62281, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.89151,     0.89151,     0.93379, ...,           1,           1,           1],\n",
              "       [    0.72835,     0.72835,     0.81688, ...,           1,           1,           1],\n",
              "       [     0.6655,      0.6655,      0.7756, ...,           1,           1,           1],\n",
              "       ...,\n",
              "       [    0.48598,     0.48598,     0.57719, ...,           1,           1,           1],\n",
              "       [    0.65687,     0.65687,     0.75605, ...,           1,           1,           1],\n",
              "       [    0.39424,     0.39424,      0.4531, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],\n",
              "       [    0.99895,     0.99895,     0.99843, ...,           0,           0,           0],\n",
              "       [    0.99738,     0.99738,     0.99633, ...,           0,           0,           0],\n",
              "       ...,\n",
              "       [    0.99387,     0.99387,      0.9933, ...,           0,           0,           0],\n",
              "       [    0.99841,     0.99841,     0.99828, ...,           0,           0,           0],\n",
              "       [    0.99841,     0.99841,     0.99577, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.8904061161693185)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([     0.9828,     0.97107,     0.97311,     0.93878,     0.91131,     0.93919,     0.90953,     0.89072,     0.91063,     0.96857,     0.88343,     0.95767,     0.89041,     0.75235,      0.9556,     0.96094,     0.82195,     0.97748,     0.78731,     0.86865,     0.77194,     0.89656,     0.79847,     0.94891,\n",
              "           0.91501,      0.9234,     0.94345,     0.92608,     0.84697,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89041,     0.89978,      0.9906,\n",
              "           0.98081,     0.96618,     0.77382,     0.69577,      0.8279,      0.7981,     0.95006,     0.75445,      0.9611,     0.92972,     0.85118,     0.93527,     0.85253,     0.79284,      0.7788,     0.90716,     0.87112])\n",
              "names: {0: '집전체', 1: '지붕', 2: '집벽', 3: '문', 4: '창문', 5: '굴뚝', 6: '연기', 7: '울타리', 8: '길', 9: '연못', 10: '산', 11: '나무', 12: '꽃', 13: '잔디', 14: '태양', 15: '나무전체', 16: '기둥', 17: '수관', 18: '가지', 19: '뿌리', 20: '나뭇잎', 21: '꽃', 22: '열매', 23: '그네', 24: '새', 25: '다람쥐', 26: '구름', 27: '달', 28: '별', 29: '사람전체', 30: '머리', 31: '얼굴', 32: '눈', 33: '코', 34: '입', 35: '귀', 36: '머리카락', 37: '목', 38: '상체', 39: '팔', 40: '손', 41: '다리', 42: '발', 43: '단추', 44: '주머니', 45: '운동화', 46: '여자구두', 47: '사람전체', 48: '머리', 49: '얼굴', 50: '눈', 51: '코', 52: '입', 53: '귀', 54: '머리카락', 55: '목', 56: '상체', 57: '팔', 58: '손', 59: '다리', 60: '발', 61: '단추', 62: '주머니', 63: '운동화', 64: '남자구두'}\n",
              "nt_per_class: array([1890, 1911, 1907, 1926, 3120, 1904, 1904, 2769, 1962, 1907, 2192, 2342,    0, 7520, 1896, 1890, 1890, 2010, 2930, 1918, 5550, 7674, 6323, 1908, 2060, 1930, 3467, 1899, 5868,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3784, 3780, 3780, 3780, 7559, 3780,\n",
              "       3781, 7523, 3781, 3780, 3780, 7559, 7539, 7557, 7559, 3939, 7012, 7566, 3784])\n",
              "nt_per_image: array([1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890,    0, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 1890, 3780, 1890, 1890, 1890, 1890, 1890, 1890, 1890,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1890, 3780, 3780, 3780, 3780, 3780,\n",
              "       3780, 3780, 3780, 3780, 3780, 3780, 3780, 3780, 3780, 3780, 3780, 3780, 1890])\n",
              "results_dict: {'metrics/precision(B)': 0.9717593561651525, 'metrics/recall(B)': 0.9667198183710135, 'metrics/mAP50(B)': 0.9852574592074541, 'metrics/mAP50-95(B)': 0.8904061161693185, 'fitness': 0.8904061161693185}\n",
              "save_dir: PosixPath('/content/drive/MyDrive/Colab/T_V_T/YOLO_train/yolo_TV_T_fast')\n",
              "speed: {'preprocess': 0.13776629722092631, 'inference': 0.9477581455160232, 'loss': 0.00030772103884142807, 'postprocess': 1.1897152303000829}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# YOLOv8 테스트 + 검증 (하위 폴더 자동 탐색)\n",
        "# ===============================\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import glob\n",
        "import yaml\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 모델 로드\n",
        "# -------------------------------\n",
        "model_path = \"/content/drive/MyDrive/Colab/T_V_T/YOLO_train_100/yolo_TV_T_fast/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. 테스트 데이터 경로\n",
        "# -------------------------------\n",
        "test_root = \"/content/drive/MyDrive/Colab/T_V_T/test\"\n",
        "\n",
        "test_images = glob.glob(os.path.join(test_root, \"images\", \"**\", \"*.*\"), recursive=True)\n",
        "test_labels = glob.glob(os.path.join(test_root, \"labels\", \"**\", \"*.*\"), recursive=True)\n",
        "\n",
        "print(f\"✅ 총 {len(test_images)} 이미지, {len(test_labels)} 라벨 확인됨\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 테스트용 데이터 YAML 생성\n",
        "# -------------------------------\n",
        "test_yaml = os.path.join(test_root, \"yolo_test.yaml\")\n",
        "test_data = {\n",
        "    'train': \"\",  # 학습 필요 없음\n",
        "    'val': test_images,  # 이미지 리스트 직접 지정 가능\n",
        "    'nc': 65,\n",
        "    'names': [\n",
        "        '집전체','지붕','집벽','문','창문','굴뚝','연기','울타리','길','연못','산','나무','꽃','잔디','태양',\n",
        "        '나무전체','기둥','수관','가지','뿌리','나뭇잎','꽃','열매','그네','새','다람쥐','구름','달','별',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','여자구두',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','남자구두'\n",
        "    ]\n",
        "}\n",
        "with open(test_yaml, 'w') as f:\n",
        "    yaml.dump(test_data, f)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 테스트 (predict) 수행\n",
        "# -------------------------------\n",
        "results = model.predict(\n",
        "    source=test_images,      # 리스트 전달\n",
        "    imgsz=640,\n",
        "    conf=0.25,\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    project=os.path.join(test_root, \"/content/drive/MyDrive/Colab/T_V_T/test_results_100\"),\n",
        "    name=\"YOLO_test\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"✅ 테스트(예측) 완료: 이미지와 txt 저장됨\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 검증 (mAP, precision, recall 등)\n",
        "# -------------------------------\n",
        "metrics = model.val(\n",
        "    data=test_yaml,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    save_json=True  # COCO 형식 JSON 저장\n",
        ")\n",
        "\n",
        "print(\"✅ 검증 완료\")\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8g9ZYv9w5K1",
        "outputId": "01ed707a-4128-419c-ef93-769364a7cab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 총 7568 이미지, 7569 라벨 확인됨\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# YOLOv8 테스트 (진행률 표시 + 속도 최적화)\n",
        "# ===============================\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm  # 진행률 표시\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 모델 로드\n",
        "# -------------------------------\n",
        "model_path = \"/content/drive/MyDrive/Colab/T_V_T/YOLO_train_100/yolo_TV_T_fast/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. 테스트 이미지 불러오기\n",
        "# -------------------------------\n",
        "test_root = \"/content/drive/MyDrive/Colab/T_V_T/test/images\"\n",
        "test_images = glob.glob(os.path.join(test_root, \"**\", \"*.*\"), recursive=True)\n",
        "print(f\"✅ 총 {len(test_images)} 이미지 확인됨\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 배치 단위로 predict 수행\n",
        "# -------------------------------\n",
        "batch_size = 32  # GPU VRAM에 맞춰 조절\n",
        "results_all = []\n",
        "\n",
        "for i in tqdm(range(0, len(test_images), batch_size), desc=\"Predicting\"):\n",
        "    batch_imgs = test_images[i:i+batch_size]\n",
        "\n",
        "    results = model.predict(\n",
        "        source=batch_imgs,\n",
        "        imgsz=640,\n",
        "        conf=0.25,\n",
        "        save=False,      # 속도 확인용, 결과 저장 안함\n",
        "        save_txt=False,\n",
        "        verbose=False    # tqdm으로 진행률 표시\n",
        "    )\n",
        "    results_all.extend(results)\n",
        "\n",
        "print(\"✅ Predict 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IFpG0ylhToq1",
        "outputId": "aa0891ff-9ab1-49d2-edb0-b5eb5b928c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 총 7568 이미지 확인됨\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 237/237 [29:35<00:00,  7.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predict 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# ✅ 저장할 CSV 파일 경로\n",
        "save_path = \"/content/drive/MyDrive/Colab/T_V_T/output/test_results_100.csv\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# ✅ CSV 파일 생성 및 저장\n",
        "with open(save_path, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # CSV 컬럼 헤더\n",
        "    writer.writerow([\"image\", \"class_id\", \"confidence\", \"x1\", \"y1\", \"x2\", \"y2\"])\n",
        "\n",
        "    for result in results_all:\n",
        "        image_path = result.path  # 현재 이미지 경로\n",
        "        boxes = result.boxes\n",
        "\n",
        "        if boxes is None or len(boxes) == 0:\n",
        "            writer.writerow([image_path, \"None\", \"None\", \"\", \"\", \"\", \"\"])\n",
        "            continue\n",
        "\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls)              # 클래스 ID\n",
        "            conf = float(box.conf)          # confidence\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()  # 바운딩 박스 좌표\n",
        "            writer.writerow([image_path, cls, f\"{conf:.4f}\", x1, y1, x2, y2])\n",
        "\n",
        "print(f\"✅ CSV 저장 완료: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWx5KJc4923O",
        "outputId": "bf17f199-a870-47ad-866c-78d2451d1605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV 저장 완료: /content/drive/MyDrive/Colab/T_V_T/output/test_results_100.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# YOLOv8 검증 (한글 경로 안전 처리)\n",
        "# ===============================\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 테스트 이미지 루트\n",
        "# -------------------------------\n",
        "test_root = \"/content/drive/MyDrive/Colab/T_V_T/test\"\n",
        "\n",
        "# -------------------------------\n",
        "# 2. YOLOv8 모델 로드\n",
        "# -------------------------------\n",
        "model_path = \"/content/drive/MyDrive/Colab/T_V_T/YOLO_train_20/yolo_TV_T_fast/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 테스트용 YAML 생성 (한글 허용)\n",
        "# -------------------------------\n",
        "test_yaml = os.path.join(test_root, \"/content/drive/MyDrive/Colab/T_V_T/yolo_test.yaml\")\n",
        "test_data = {\n",
        "    'train': \"\",  # 학습 필요 없음\n",
        "    'val': os.path.join(test_root, \"images\"),  # 폴더 경로만 지정\n",
        "    'nc': 65,\n",
        "    'names': [\n",
        "        '집전체','지붕','집벽','문','창문','굴뚝','연기','울타리','길','연못','산','나무','꽃','잔디','태양',\n",
        "        '나무전체','기둥','수관','가지','뿌리','나뭇잎','꽃','열매','그네','새','다람쥐','구름','달','별',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','여자구두',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','남자구두'\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(test_yaml, 'w', encoding='utf-8') as f:\n",
        "    yaml.dump(test_data, f, allow_unicode=True)\n",
        "\n",
        "print(\"✅ YAML 생성 완료:\", test_yaml)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 검증 실행 (mAP, Precision, Recall 계산)\n",
        "# -------------------------------\n",
        "metrics = model.val(\n",
        "    data=test_yaml,\n",
        "    imgsz=640,\n",
        "    batch=32,          # 배치 크기 증가로 속도 향상\n",
        "    save_json=True,    # COCO 형식 JSON 저장\n",
        "    workers=4          # CPU 병렬 처리\n",
        ")\n",
        "\n",
        "print(\"✅ 검증 완료\")\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAPnGesDTpft",
        "outputId": "1166fb6e-6680-4aae-8894-04219f6b5731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ YAML 생성 완료: /content/drive/MyDrive/Colab/T_V_T/yolo_test.yaml\n",
            "Ultralytics 8.3.223 🚀 Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "Model summary (fused): 92 layers, 25,877,395 parameters, 0 gradients, 78.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 44.1±23.1 MB/s, size: 62.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab/T_V_T/test/labels/나무.cache... 7568 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7568/7568 9.4Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 237/237 3.4it/s 1:09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48533 (\\N{HANGUL SYLLABLE BUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48317 (\\N{HANGUL SYLLABLE BYEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47928 (\\N{HANGUL SYLLABLE MUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52285 (\\N{HANGUL SYLLABLE CANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44404 (\\N{HANGUL SYLLABLE GUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46749 (\\N{HANGUL SYLLABLE DDUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47803 (\\N{HANGUL SYLLABLE MOS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44867 (\\N{HANGUL SYLLABLE GGOC}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51092 (\\N{HANGUL SYLLABLE JAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46181 (\\N{HANGUL SYLLABLE DUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49100 (\\N{HANGUL SYLLABLE BBU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47943 (\\N{HANGUL SYLLABLE MUS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51086 (\\N{HANGUL SYLLABLE IP}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50676 (\\N{HANGUL SYLLABLE YEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49352 (\\N{HANGUL SYLLABLE SAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46988 (\\N{HANGUL SYLLABLE RAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51536 (\\N{HANGUL SYLLABLE JWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44396 (\\N{HANGUL SYLLABLE GU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45804 (\\N{HANGUL SYLLABLE DAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47672 (\\N{HANGUL SYLLABLE MEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50620 (\\N{HANGUL SYLLABLE EOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45576 (\\N{HANGUL SYLLABLE NUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51077 (\\N{HANGUL SYLLABLE IB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46973 (\\N{HANGUL SYLLABLE RAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47785 (\\N{HANGUL SYLLABLE MOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45800 (\\N{HANGUL SYLLABLE DAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50868 (\\N{HANGUL SYLLABLE UN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50668 (\\N{HANGUL SYLLABLE YEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46160 (\\N{HANGUL SYLLABLE DU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51665 (\\N{HANGUL SYLLABLE JIB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52404 (\\N{HANGUL SYLLABLE CE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48533 (\\N{HANGUL SYLLABLE BUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48317 (\\N{HANGUL SYLLABLE BYEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47928 (\\N{HANGUL SYLLABLE MUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52285 (\\N{HANGUL SYLLABLE CANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44404 (\\N{HANGUL SYLLABLE GUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46749 (\\N{HANGUL SYLLABLE DDUG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50872 (\\N{HANGUL SYLLABLE UL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44600 (\\N{HANGUL SYLLABLE GIL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47803 (\\N{HANGUL SYLLABLE MOS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49328 (\\N{HANGUL SYLLABLE SAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47924 (\\N{HANGUL SYLLABLE MU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44867 (\\N{HANGUL SYLLABLE GGOC}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51092 (\\N{HANGUL SYLLABLE JAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50577 (\\N{HANGUL SYLLABLE YANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46181 (\\N{HANGUL SYLLABLE DUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49100 (\\N{HANGUL SYLLABLE BBU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47943 (\\N{HANGUL SYLLABLE MUS}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51086 (\\N{HANGUL SYLLABLE IP}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50676 (\\N{HANGUL SYLLABLE YEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45348 (\\N{HANGUL SYLLABLE NE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49352 (\\N{HANGUL SYLLABLE SAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46988 (\\N{HANGUL SYLLABLE RAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51536 (\\N{HANGUL SYLLABLE JWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44396 (\\N{HANGUL SYLLABLE GU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47492 (\\N{HANGUL SYLLABLE REUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45804 (\\N{HANGUL SYLLABLE DAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48324 (\\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47672 (\\N{HANGUL SYLLABLE MEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50620 (\\N{HANGUL SYLLABLE EOL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45576 (\\N{HANGUL SYLLABLE NUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51077 (\\N{HANGUL SYLLABLE IB}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 44480 (\\N{HANGUL SYLLABLE GWI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52852 (\\N{HANGUL SYLLABLE KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46973 (\\N{HANGUL SYLLABLE RAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 47785 (\\N{HANGUL SYLLABLE MOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 48156 (\\N{HANGUL SYLLABLE BAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45800 (\\N{HANGUL SYLLABLE DAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50868 (\\N{HANGUL SYLLABLE UN}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 50668 (\\N{HANGUL SYLLABLE YEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 46160 (\\N{HANGUL SYLLABLE DU}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:582: UserWarning: Glyph 45224 (\\N{HANGUL SYLLABLE NAM}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(plot_fname, dpi=250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       7568     184107      0.975      0.968      0.986      0.895\n",
            "                   집전체       1892       1892      0.995      0.999      0.995      0.984\n",
            "                    지붕       1892       1909      0.992      0.996      0.994      0.972\n",
            "                    집벽       1892       1916      0.991      0.989      0.995      0.973\n",
            "                     문       1892       1935      0.992      0.985      0.994      0.939\n",
            "                    창문       1892       3182      0.974      0.973      0.991      0.908\n",
            "                    굴뚝       1892       1895      0.982      0.985      0.992      0.952\n",
            "                    연기       1892       1895      0.971      0.979       0.99      0.917\n",
            "                   울타리       1892       2814       0.93      0.924      0.964      0.895\n",
            "                     길       1892       1972      0.943      0.945      0.977      0.931\n",
            "                    연못       1892       1906      0.975      0.992      0.993       0.97\n",
            "                     산       1892       2203      0.916      0.946      0.971      0.911\n",
            "                    나무       1892       2315      0.985      0.988      0.994       0.96\n",
            "                    잔디       1892       7736      0.925      0.891      0.948      0.753\n",
            "                    태양       1892       1893      0.984      0.991      0.994      0.961\n",
            "                  나무전체       1892       1892      0.996      0.998      0.995      0.977\n",
            "                    기둥       1892       1893      0.984      0.985      0.993      0.832\n",
            "                    수관       1892       1996      0.986      0.976      0.993      0.976\n",
            "                    가지       1892       2899      0.929      0.886      0.951      0.793\n",
            "                    뿌리       1892       1913      0.976      0.981      0.992      0.869\n",
            "                   나뭇잎       1892       5441      0.946      0.909      0.963      0.782\n",
            "                     꽃       3784       7750      0.971      0.971      0.991      0.902\n",
            "                    열매       1892       6295      0.947       0.91      0.968        0.8\n",
            "                    그네       1892       1910      0.983      0.987      0.991      0.947\n",
            "                     새       1892       2043      0.962      0.972      0.991      0.921\n",
            "                   다람쥐       1892       1916      0.967      0.981       0.99      0.926\n",
            "                    구름       1892       3417      0.982      0.986      0.994      0.946\n",
            "                     달       1892       1905      0.981      0.988      0.994      0.928\n",
            "                     별       1892       5656      0.982       0.99      0.993      0.847\n",
            "                  여자구두       1892       3784      0.957      0.956      0.986       0.91\n",
            "                  사람전체       3784       3784          1          1      0.995      0.991\n",
            "                    머리       3784       3784      0.999      0.999      0.995      0.981\n",
            "                    얼굴       3784       3784      0.999          1      0.995      0.973\n",
            "                     눈       3784       7567      0.974      0.914      0.973      0.771\n",
            "                     코       3784       3784      0.983      0.847      0.956      0.694\n",
            "                     입       3784       3784      0.992      0.955      0.993      0.833\n",
            "                     귀       3784       7524      0.993      0.988      0.994      0.805\n",
            "                  머리카락       3784       3784       0.99      0.995      0.994      0.951\n",
            "                     목       3784       3784      0.995      0.984      0.995      0.758\n",
            "                    상체       3784       3784      0.993      0.994      0.995      0.966\n",
            "                     팔       3784       7569      0.997      0.997      0.995      0.932\n",
            "                     손       3784       7546      0.993      0.985      0.994      0.852\n",
            "                    다리       3784       7563       0.97      0.976      0.992      0.937\n",
            "                     발       3784       7570      0.989      0.986      0.993      0.853\n",
            "                    단추       3784       3935      0.972      0.927      0.967      0.806\n",
            "                   주머니       3784       7034      0.982      0.977      0.989      0.785\n",
            "                   운동화       3784       7570      0.965      0.977      0.989      0.903\n",
            "                  남자구두       1892       3784      0.927      0.927      0.968      0.876\n",
            "Speed: 0.7ms preprocess, 2.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Saving /content/runs/detect/val5/predictions.json...\n",
            "Results saved to \u001b[1m/content/runs/detect/val5\u001b[0m\n",
            "✅ 검증 완료\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e9112c75010>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,     0.99841,     0.99736,           0],\n",
            "       [          1,           1,           1, ...,     0.95491,     0.82135,           0],\n",
            "       [          1,           1,           1, ...,      0.8431,     0.38159,           0],\n",
            "       ...,\n",
            "       [          1,           1,           1, ...,     0.23538,     0.11769,           0],\n",
            "       [          1,           1,           1, ...,      0.7779,     0.51046,           0],\n",
            "       [          1,           1,           1, ...,     0.31674,     0.15837,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92904,     0.92904,      0.9577, ...,           0,           0,           0],\n",
            "       [    0.77116,     0.77116,      0.8546, ...,           0,           0,           0],\n",
            "       [    0.74712,     0.74712,     0.83079, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.68159,     0.68162,     0.75468, ...,           0,           0,           0],\n",
            "       [    0.75455,      0.7547,     0.83009, ...,           0,           0,           0],\n",
            "       [    0.54647,     0.54649,     0.61327, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.86749,     0.86749,     0.91884, ...,           1,           1,           1],\n",
            "       [    0.62755,     0.62755,     0.74611, ...,           1,           1,           1],\n",
            "       [    0.59688,     0.59688,     0.71135, ...,           1,           1,           1],\n",
            "       ...,\n",
            "       [    0.51817,      0.5182,     0.60775, ...,           1,           1,           1],\n",
            "       [    0.60629,     0.60648,     0.71027, ...,           1,           1,           1],\n",
            "       [     0.3763,     0.37632,     0.44297, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],\n",
            "       [          1,           1,           1, ...,           0,           0,           0],\n",
            "       [    0.99843,     0.99843,     0.99843, ...,           0,           0,           0],\n",
            "       ...,\n",
            "       [    0.99559,     0.99559,     0.99531, ...,           0,           0,           0],\n",
            "       [    0.99881,     0.99881,     0.99855, ...,           0,           0,           0],\n",
            "       [    0.99762,     0.99762,      0.9963, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.894562771568529)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([    0.98412,     0.97235,     0.97289,     0.93888,     0.90757,     0.95183,     0.91667,     0.89467,     0.93075,      0.9704,     0.91136,     0.95992,     0.89456,     0.75329,     0.96092,     0.97658,     0.83172,     0.97631,     0.79281,     0.86871,     0.78157,     0.90179,     0.79979,     0.94705,\n",
            "           0.92078,     0.92554,     0.94626,      0.9281,     0.84702,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.89456,     0.91008,     0.99141,\n",
            "           0.98098,     0.97277,     0.77087,      0.6939,     0.83268,     0.80457,     0.95083,     0.75789,     0.96621,     0.93162,     0.85213,     0.93662,     0.85266,      0.8057,     0.78512,     0.90257,     0.87617])\n",
            "names: {0: '집전체', 1: '지붕', 2: '집벽', 3: '문', 4: '창문', 5: '굴뚝', 6: '연기', 7: '울타리', 8: '길', 9: '연못', 10: '산', 11: '나무', 12: '꽃', 13: '잔디', 14: '태양', 15: '나무전체', 16: '기둥', 17: '수관', 18: '가지', 19: '뿌리', 20: '나뭇잎', 21: '꽃', 22: '열매', 23: '그네', 24: '새', 25: '다람쥐', 26: '구름', 27: '달', 28: '별', 29: '사람전체', 30: '머리', 31: '얼굴', 32: '눈', 33: '코', 34: '입', 35: '귀', 36: '머리카락', 37: '목', 38: '상체', 39: '팔', 40: '손', 41: '다리', 42: '발', 43: '단추', 44: '주머니', 45: '운동화', 46: '여자구두', 47: '사람전체', 48: '머리', 49: '얼굴', 50: '눈', 51: '코', 52: '입', 53: '귀', 54: '머리카락', 55: '목', 56: '상체', 57: '팔', 58: '손', 59: '다리', 60: '발', 61: '단추', 62: '주머니', 63: '운동화', 64: '남자구두'}\n",
            "nt_per_class: array([1892, 1909, 1916, 1935, 3182, 1895, 1895, 2814, 1972, 1906, 2203, 2315,    0, 7736, 1893, 1892, 1893, 1996, 2899, 1913, 5441, 7750, 6295, 1910, 2043, 1916, 3417, 1905, 5656,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 3784, 3784, 3784, 3784, 7567, 3784,\n",
            "       3784, 7524, 3784, 3784, 3784, 7569, 7546, 7563, 7570, 3935, 7034, 7570, 3784])\n",
            "nt_per_image: array([1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892,    0, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 3784, 1892, 1892, 1892, 1892, 1892, 1892, 1892,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1892, 3784, 3784, 3784, 3784, 3784,\n",
            "       3784, 3784, 3784, 3784, 3784, 3784, 3784, 3784, 3784, 3784, 3784, 3784, 1892])\n",
            "results_dict: {'metrics/precision(B)': 0.9748150593882439, 'metrics/recall(B)': 0.9678517779149759, 'metrics/mAP50(B)': 0.9861569750899789, 'metrics/mAP50-95(B)': 0.894562771568529, 'fitness': 0.894562771568529}\n",
            "save_dir: PosixPath('/content/runs/detect/val5')\n",
            "speed: {'preprocess': 0.6751620883997175, 'inference': 2.352102275768874, 'loss': 0.0002676812908798321, 'postprocess': 0.8104628582194571}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Detectron2 학습 + 지표 저장 + CSV 출력 (하위 폴더 지원, JSON 필터링)\n",
        "# ===============================\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from glob import glob\n",
        "import json\n",
        "\n",
        "# -------------------------------\n",
        "# 0. 기존 등록 데이터셋 제거\n",
        "# -------------------------------\n",
        "for d in [\"TVT_train\", \"TVT_val\"]:\n",
        "    if d in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(d)\n",
        "    if d in MetadataCatalog.list():\n",
        "        MetadataCatalog.remove(d)\n",
        "# ===============================\n",
        "# Detectron2용 COCO JSON 필터링 + 하위폴더 경로 반영\n",
        "# ===============================\n",
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "data_root = r\"/content/drive/MyDrive/Colab/T_V_T\"\n",
        "\n",
        "def filter_coco_json(coco_json_path, img_root, output_json_path):\n",
        "    \"\"\"\n",
        "    COCO JSON에서 실제 존재하는 이미지에 해당하는 annotation만 남기고\n",
        "    file_name을 실제 하위 폴더 경로로 수정\n",
        "    \"\"\"\n",
        "    with open(coco_json_path, \"r\") as f:\n",
        "        coco = json.load(f)\n",
        "\n",
        "    # 실제 존재하는 모든 이미지 경로 수집 (하위 폴더 포함)\n",
        "    valid_images = glob(os.path.join(img_root, \"**/*.jpg\"), recursive=True)\n",
        "    valid_images += glob(os.path.join(img_root, \"**/*.png\"), recursive=True)\n",
        "    # 파일명만 아니라 COCO JSON 기준 상대 경로 필요\n",
        "    valid_relpaths = {os.path.relpath(p, img_root).replace(\"\\\\\", \"/\"): p for p in valid_images}\n",
        "\n",
        "    # 기존 이미지와 annotations 필터링\n",
        "    filtered_images = []\n",
        "    filtered_annotations = []\n",
        "    valid_image_ids = set()\n",
        "\n",
        "    for img in coco[\"images\"]:\n",
        "        fn = img[\"file_name\"]\n",
        "        # 하위폴더까지 포함된 실제 경로 찾기\n",
        "        matched_paths = [k for k in valid_relpaths if k.endswith(fn)]\n",
        "        if matched_paths:\n",
        "            # file_name을 실제 하위 폴더 경로로 교체\n",
        "            img[\"file_name\"] = matched_paths[0]\n",
        "            filtered_images.append(img)\n",
        "            valid_image_ids.add(img[\"id\"])\n",
        "\n",
        "    for ann in coco[\"annotations\"]:\n",
        "        if ann[\"image_id\"] in valid_image_ids:\n",
        "            filtered_annotations.append(ann)\n",
        "\n",
        "    coco[\"images\"] = filtered_images\n",
        "    coco[\"annotations\"] = filtered_annotations\n",
        "\n",
        "    with open(output_json_path, \"w\") as f:\n",
        "        json.dump(coco, f, indent=2)\n",
        "\n",
        "    print(f\"✅ {len(filtered_images)} images, {len(filtered_annotations)} annotations saved to {output_json_path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 트레인/밸리 필터링\n",
        "# -------------------------------\n",
        "train_json = os.path.join(data_root, \"train/labels/coco_train.json\")\n",
        "val_json   = os.path.join(data_root, \"val/labels/coco_val.json\")\n",
        "\n",
        "train_img_root = os.path.join(data_root, \"train/images\")\n",
        "val_img_root   = os.path.join(data_root, \"val/images\")\n",
        "\n",
        "train_out_json = os.path.join(data_root, \"train/labels/coco_train_filtered.json\")\n",
        "val_out_json   = os.path.join(data_root, \"val/labels/coco_val_filtered.json\")\n",
        "\n",
        "filter_coco_json(train_json, train_img_root, train_out_json)\n",
        "filter_coco_json(val_json, val_img_root, val_out_json)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Detectron2에 등록\n",
        "# -------------------------------\n",
        "register_coco_instances(\"TVT_train\", {}, filtered_train_json, train_img_root)\n",
        "register_coco_instances(\"TVT_val\",   {}, filtered_val_json,   val_img_root)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Detectron2 설정\n",
        "# -------------------------------\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"TVT_train\",)\n",
        "cfg.DATASETS.TEST  = (\"TVT_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (640,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 1280\n",
        "cfg.INPUT.MIN_SIZE_TEST = 640\n",
        "cfg.INPUT.MAX_SIZE_TEST = 1280\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 65\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.SOLVER.IMS_PER_BATCH = 32\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 2500\n",
        "cfg.SOLVER.AMP.ENABLED = True\n",
        "cfg.OUTPUT_DIR = os.path.join(data_root, \"Detectron2_train\")\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "metrics_json_path = os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")\n",
        "metrics_csv_path  = os.path.join(cfg.OUTPUT_DIR, \"metrics.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 얼리 스탑핑 Trainer 정의\n",
        "# -------------------------------\n",
        "class EarlyStoppingTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg, patience=5):\n",
        "        super().__init__(cfg)\n",
        "        self.best_metric = 0.0\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.metrics_history = []\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
        "\n",
        "    def after_step(self):\n",
        "        super().after_step()\n",
        "        iteration = self.iter + 1\n",
        "\n",
        "        if iteration % 500 == 0 or iteration == cfg.SOLVER.MAX_ITER:\n",
        "            evaluator = self.build_evaluator(cfg, cfg.DATASETS.TEST[0])\n",
        "            val_results = self.test(cfg, self.model, evaluators=[evaluator])\n",
        "            map_50 = val_results[\"bbox\"][\"AP50\"]\n",
        "            map_5095 = val_results[\"bbox\"][\"AP\"]\n",
        "\n",
        "            print(f\"📊 [Iteration {iteration}] mAP50: {map_50:.4f}, mAP50-95: {map_5095:.4f}\")\n",
        "\n",
        "            self.metrics_history.append({\n",
        "                \"iteration\": iteration,\n",
        "                \"mAP50\": map_50,\n",
        "                \"mAP50-95\": map_5095\n",
        "            })\n",
        "            with open(metrics_json_path, \"w\") as f:\n",
        "                json.dump(self.metrics_history, f, indent=2)\n",
        "            pd.DataFrame(self.metrics_history).to_csv(metrics_csv_path, index=False)\n",
        "\n",
        "            if map_50 > self.best_metric:\n",
        "                self.best_metric = map_50\n",
        "                self.counter = 0\n",
        "                torch.save(self.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                print(f\"✅ [Iteration {iteration}] mAP50 개선: {map_50:.4f}\")\n",
        "            else:\n",
        "                self.counter += 1\n",
        "                print(f\"⚠️ [Iteration {iteration}] 개선 없음 ({self.counter}/{self.patience})\")\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"🛑 얼리 스탑핑 발동 - 학습 중단\")\n",
        "                raise SystemExit\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 학습 실행\n",
        "# -------------------------------\n",
        "trainer = EarlyStoppingTrainer(cfg, patience=5)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tPDASvmU-Glo",
        "outputId": "6edf158c-e01c-4f0d-e92d-eb775ddd9249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 0 images, 0 annotations saved to /content/drive/MyDrive/Colab/T_V_T/train/labels/coco_train_filtered.json\n",
            "✅ 0 images, 0 annotations saved to /content/drive/MyDrive/Colab/T_V_T/val/labels/coco_val_filtered.json\n",
            "[11/02 15:57:24 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=66, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=260, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [11/02 15:57:24 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[11/02 15:57:24 d2.data.datasets.coco]: Loaded 0 images in COCO format from /content/drive/MyDrive/Colab/T_V_T/train/labels/coco_train_filtered.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Dataset 'TVT_train' is empty!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3184845251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# 6. 학습 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStoppingTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3184845251.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, patience)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEarlyStoppingTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ddp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_buffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_train_loader\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_detection_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/config/config.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_called_with_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                     \u001b[0mexplicit_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexplicit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/config/config.py\u001b[0m in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_arg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_config_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;31m# forward the other arguments to __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36m_train_loader_from_config\u001b[0;34m(cfg, mapper, dataset, sampler)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_train_loader_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         dataset = get_detection_dataset_dicts(\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mfilter_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILTER_EMPTY_ANNOTATIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2/detectron2/data/build.py\u001b[0m in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(names, filter_empty, min_keypoints, proposal_files, check_consistency)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproposal_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Dataset 'TVT_train' is empty!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ===============================\n",
        "# 0. (선택) Drive → 로컬 복사 설정\n",
        "# ===============================\n",
        "COPY_TO_LOCAL = True  # True면 /content/drive/... -> /content/dataset 로 복사 (권장: I/O 개선)\n",
        "DATA_ROOT_DRIVE = r\"/content/drive/MyDrive/Colab/T_V_T\"\n",
        "DATA_ROOT_LOCAL = r\"/content/dataset/T_V_T\"\n",
        "\n",
        "if COPY_TO_LOCAL:\n",
        "    import os\n",
        "    import shutil\n",
        "    if not os.path.exists(DATA_ROOT_LOCAL):\n",
        "        print(\"복사 시작: Drive -> 로컬 (이 작업은 시간이 걸릴 수 있지만 I/O를 크게 개선합니다)...\")\n",
        "        # cp -r 가 더 안정적일 때가 있어 shell 사용\n",
        "        os.system(f\"cp -r '{DATA_ROOT_DRIVE}' '/content/dataset/'\")\n",
        "        # 간단한 존재 확인\n",
        "        if os.path.exists(DATA_ROOT_LOCAL):\n",
        "            print(\"복사 완료:\", DATA_ROOT_LOCAL)\n",
        "        else:\n",
        "            print(\"복사 실패: 로컬 경로가 만들어지지 않았습니다. Drive 경로를 사용합니다.\")\n",
        "            COPY_TO_LOCAL = False\n",
        "    else:\n",
        "        print(\"로컬 데이터 이미 존재:\", DATA_ROOT_LOCAL)\n",
        "        COPY_TO_LOCAL = True\n",
        "\n",
        "# ===============================\n",
        "# 1. 환경 세팅 (패키지 import)\n",
        "# ===============================\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "\n",
        "# Detectron2 imports (이미 설치되어 있다는 가정)\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "import torch\n",
        "\n",
        "# ===============================\n",
        "# 2. 데이터 경로 (로컬 우선)\n",
        "# ===============================\n",
        "data_root = DATA_ROOT_LOCAL if COPY_TO_LOCAL else DATA_ROOT_DRIVE\n",
        "yolo_train = os.path.join(data_root, \"train/images\")\n",
        "yolo_val   = os.path.join(data_root, \"val/images\")\n",
        "\n",
        "coco_train_json = os.path.join(data_root, \"train/labels/Detectron2/coco_train.json\")\n",
        "coco_val_json   = os.path.join(data_root, \"val/labels/Detectron2/coco_val.json\")\n",
        "coco_test_json  = os.path.join(data_root, \"test/labels/Detectron2/coco_test.json\")\n",
        "\n",
        "# 존재 체크\n",
        "for p in [yolo_train, yolo_val, coco_train_json, coco_val_json]:\n",
        "    if not os.path.exists(p):\n",
        "        print(\"경고: 경로가 없습니다:\", p)\n",
        "\n",
        "# ===============================\n",
        "# 2-1. YOLOv8용 데이터 YAML 생성 (변경 없음)\n",
        "# ===============================\n",
        "yolo_data_yaml = os.path.join(data_root, \"yolo_data.yaml\")\n",
        "yolo_data = {\n",
        "    'train': yolo_train,\n",
        "    'val': yolo_val,\n",
        "    'nc': 65,  # 클래스 개수\n",
        "    'names': [\n",
        "        '집전체','지붕','집벽','문','창문','굴뚝','연기','울타리','길','연못','산','나무','꽃','잔디','태양',\n",
        "        '나무전체','기둥','수관','가지','뿌리','나뭇잎','꽃','열매','그네','새','다람쥐','구름','달','별',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','여자구두',\n",
        "        '사람전체','머리','얼굴','눈','코','입','귀','머리카락','목','상체','팔','손','다리','발','단추','주머니','운동화','남자구두'\n",
        "    ]\n",
        "}\n",
        "with open(yolo_data_yaml, 'w') as f:\n",
        "    yaml.dump(yolo_data, f)\n",
        "\n",
        "# ===============================\n",
        "# 3. YOLOv8 학습 (속도 최적화 적용)\n",
        "# ===============================\n",
        "# 권장: yolov8s로 속도/정확도 균형 맞춤. 원하면 yolov8m으로 교체 가능.\n",
        "yolo_model = YOLO('yolov8s.pt')\n",
        "\n",
        "yolo_project = os.path.join(data_root,\"YOLO_train\")\n",
        "os.makedirs(yolo_project, exist_ok=True)\n",
        "\n",
        "yolo_model.train(\n",
        "    data=yolo_data_yaml,      # 데이터 YAML 경로\n",
        "    epochs=100,                # epochs 축소 (예: 50)\n",
        "    patience=5,               # 조기 종료 민감도 감소\n",
        "    batch=64,                 # 수동 배치 사이즈 (auto 대신 명시)\n",
        "    imgsz=640,                # 640 → 512로 축소\n",
        "    project=yolo_project,\n",
        "    name=\"yolo_TV_T_fast\",\n",
        "    exist_ok=True,\n",
        "    cache='disk',              # disk -> ram으로 변경 (가능하면 속도 크게 향상)\n",
        "    workers=16,               # dataloader workers 증가\n",
        "    val_period=5,             # 5 epoch 마다 validation (검증 시간 절약)\n",
        "    device=0,                 # GPU id (Colab A100)\n",
        "    plots=True,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 4. Detectron2 학습 (A100 최적화 + 얼리 스탑핑)\n",
        "# ===============================\n",
        "# COCO 데이터셋 등록 (Detectron2 사용)\n",
        "register_coco_instances(\"TVT_train\", {}, coco_train_json, os.path.join(data_root, \"train/images\"))\n",
        "register_coco_instances(\"TVT_val\", {}, coco_val_json, os.path.join(data_root, \"val/images\"))\n",
        "\n",
        "cfg = get_cfg()\n",
        "# model_zoo 사용 — 로컬 detectron2 소스가 없어도 작동\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "# 데이터셋\n",
        "cfg.DATASETS.TRAIN = (\"TVT_train\",)\n",
        "cfg.DATASETS.TEST = (\"TVT_val\",)\n",
        "\n",
        "# 데이터 로딩\n",
        "cfg.DATALOADER.NUM_WORKERS = 16\n",
        "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
        "\n",
        "# 이미지 리사이징 (필요 시 더 낮출 수 있음)\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (640,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 1280\n",
        "cfg.INPUT.MIN_SIZE_TEST = 640\n",
        "cfg.INPUT.MAX_SIZE_TEST = 1280\n",
        "\n",
        "# 모델 설정\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 65\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # per-image proposals\n",
        "\n",
        "# 학습 하이퍼파라미터 (A100 40GB 기준으로 조정)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 32   # 전체 배치 사이즈 (GPU 메모리에 맞춰 조정)\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 2500\n",
        "cfg.SOLVER.AMP.ENABLED = True\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "\n",
        "# 출력 경로 (경로 중복 문제 수정)\n",
        "cfg.OUTPUT_DIR = os.path.join(data_root, \"Detectron2_train\")\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 얼리 스탑핑 Trainer 정의\n",
        "# ===============================\n",
        "class EarlyStoppingTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg, patience=5):\n",
        "        super().__init__(cfg)\n",
        "        self.best_metric = 0.0\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"eval\")\n",
        "        return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
        "\n",
        "    def after_step(self):\n",
        "        super().after_step()\n",
        "        iteration = self.iter + 1\n",
        "\n",
        "        # validation 빈도 조정: checkpoint 주기(CHECKPOINT_PERIOD)와 동일하게 체크\n",
        "        if iteration % cfg.SOLVER.CHECKPOINT_PERIOD == 0 or iteration == cfg.SOLVER.MAX_ITER:\n",
        "            evaluator = self.build_evaluator(cfg, cfg.DATASETS.TEST[0])\n",
        "            val_results = self.test(cfg, self.model, evaluators=[evaluator])\n",
        "\n",
        "            # COCO mAP50 읽기: 결과의 nested key는 detectron2 버전에 따라 다를 수 있음\n",
        "            try:\n",
        "                map_50 = val_results[\"bbox\"][\"AP50\"]\n",
        "            except Exception as e:\n",
        "                # 안전 fallback: 총 mAP가 dict로 있을 수 있음\n",
        "                map_50 = val_results.get(\"bbox\", {}).get(\"AP50\", 0.0)\n",
        "\n",
        "            if map_50 > self.best_metric:\n",
        "                self.best_metric = map_50\n",
        "                self.counter = 0\n",
        "                torch.save(self.model.state_dict(), os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\"))\n",
        "                print(f\"✅ [Iteration {iteration}] mAP50 개선: {map_50:.4f}\")\n",
        "            else:\n",
        "                self.counter += 1\n",
        "                print(f\"⚠️ [Iteration {iteration}] 개선 없음 ({self.counter}/{self.patience})\")\n",
        "\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"🛑 얼리 스탑핑 발동 - 학습 중단\")\n",
        "                raise SystemExit\n",
        "\n",
        "# ===============================\n",
        "# 5. Detectron2 학습 실행\n",
        "# ===============================\n",
        "trainer = EarlyStoppingTrainer(cfg, patience=5)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "C9qQLUG3AHQH",
        "outputId": "247a2515-27b2-4662-a127-9818d3c4d223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "복사 시작: Drive -> 로컬 (이 작업은 시간이 걸릴 수 있지만 I/O를 크게 개선합니다)...\n",
            "복사 실패: 로컬 경로가 만들어지지 않았습니다. Drive 경로를 사용합니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    }
  ]
}