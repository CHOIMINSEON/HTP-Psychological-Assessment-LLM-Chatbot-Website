# ğŸ¨ HTP ì‹¬ë¦¬ê²€ì‚¬ AI í”„ë¡œì íŠ¸

> **HTP (House-Tree-Person)** ê·¸ë¦¼ ì‹¬ë¦¬ê²€ì‚¬ë¥¼ ìœ„í•œ AI ê¸°ë°˜ ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë° ì‹¬ë¦¬í•™ì  í•´ì„ ì‹œìŠ¤í…œ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow.svg)](https://huggingface.co/transformers/)

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” HTP(ì§‘-ë‚˜ë¬´-ì‚¬ëŒ) ê·¸ë¦¼ ì‹¬ë¦¬ê²€ì‚¬ë¥¼ AIë¡œ ìë™í™”í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 
1. **ì´ë¯¸ì§€ ìº¡ì…”ë‹**: ê·¸ë¦¼ì„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…
2. **ì‹¬ë¦¬í•™ì  í•´ì„**: ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ì‹¬ë¦¬ ë¶„ì„ ì œê³µ
3. **ëŒ€í™”í˜• RAG**: ë©€í‹°í„´ ëŒ€í™”ë¥¼ í†µí•œ ì‹¬ì¸µ ìƒë‹´

---

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
models/
â”œâ”€â”€ ğŸ“¸ captioning/                    # ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ë“¤
â”‚   â”œâ”€â”€ model_blip.ipynb             # BLIP ëª¨ë¸
â”‚   â”œâ”€â”€ model_llava.ipynb            # LLaVA ëª¨ë¸
â”‚   â”œâ”€â”€ model_qwen.ipynb             # Qwen-VL ëª¨ë¸ â­ ì„ íƒ
â”‚   â””â”€â”€ image_captions_*.json        # ìƒì„±ëœ ìº¡ì…˜ ê²°ê³¼ë“¤
â”‚
â”œâ”€â”€ ğŸ”§ LoRa/                          # LoRA íŒŒì¸íŠœë‹
â”‚   â”œâ”€â”€ LoRa.ipynb                   # LoRA í•™ìŠµ ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ HTP_data.jsonl               # í•™ìŠµ ë°ì´í„° (1,453ê°œ)
â”‚   â””â”€â”€ htp_lora_model/              # í•™ìŠµëœ LoRA ëª¨ë¸
â”‚       â”œâ”€â”€ adapter_model.safetensors
â”‚       â””â”€â”€ adapter_config.json
â”‚
â”œâ”€â”€ â„ï¸ layer_freezing/                # Layer Freezing íŒŒì¸íŠœë‹
â”‚   â”œâ”€â”€ final_htp_model.ipynb        # Layer Freezing í•™ìŠµ
â”‚   â”œâ”€â”€ test_htp_model.py            # ì „ì²´ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ interactive_test.py          # ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ qwen2.5-htp-layer-freeze-final/  # í•™ìŠµëœ ëª¨ë¸
â”‚       â”œâ”€â”€ model.safetensors        # ì•½ 3GB
â”‚       â”œâ”€â”€ config.json
â”‚       â””â”€â”€ training_curves.png
â”‚
â”œâ”€â”€ ğŸ¤– combined/                      # RAG í†µí•© ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ rag_model_combined.ipynb     # ê¸°ë³¸ RAG
â”‚   â”œâ”€â”€ cleaned_ë©€í‹°í„´_ë©€í‹°ì¿¼ë¦¬_history_RAG.ipynb  # ë©€í‹°í„´ ëŒ€í™” RAG
â”‚   â”œâ”€â”€ chroma_store/                # ë²¡í„° DB
â”‚   â””â”€â”€ conversational_rag_history_*.json  # ëŒ€í™” íˆìŠ¤í† ë¦¬
â”‚
â”œâ”€â”€ ğŸ“Š test_results/                  # í…ŒìŠ¤íŠ¸ ê²°ê³¼
â”‚   â”œâ”€â”€ base_model_test_results.json
â”‚   â””â”€â”€ lora_test_results.json
â”‚
â”œâ”€â”€ ğŸ“ˆ Data_generation.ipynb          # ë°ì´í„° ìƒì„± ë„êµ¬
â”œâ”€â”€ ğŸ§ª test_base_model.ipynb          # ë² ì´ìŠ¤ ëª¨ë¸ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ merge_results.py                  # ê²°ê³¼ ë³‘í•© ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ model_comparison_results.csv      # ëª¨ë¸ ë¹„êµ ê²°ê³¼
```

---

## ğŸš€ í•µì‹¬ ê¸°ëŠ¥

### 1. ğŸ¨ ì´ë¯¸ì§€ ìº¡ì…”ë‹
HTP ê·¸ë¦¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” 3ê°€ì§€ ëª¨ë¸ ë¹„êµ:

| ëª¨ë¸ | íŠ¹ì§• | ì„±ëŠ¥ |
|------|------|------|
| **BLIP** | ë¹ ë¥´ê³  ê°€ë²¼ì›€ | ê¸°ë³¸ì ì¸ ì„¤ëª… ìƒì„± |
| **LLaVA** | ìƒì„¸í•œ ì„¤ëª… | ì¤‘ê°„ ìˆ˜ì¤€ |
| **Qwen-VL** â­ | ê°€ì¥ ì •í™•í•˜ê³  ìƒì„¸ | **ìµœì¢… ì„ íƒ** |

**ì˜ˆì‹œ ì¶œë ¥** (Qwen-VL):
```
ì…ë ¥: [ë‚˜ë¬´ ê·¸ë¦¼ ì´ë¯¸ì§€]
ì¶œë ¥: "The tree is dominant and tall with many branches extending 
       outward. The trunk is thick and sturdy, with deep roots 
       visible at the base."
```

### 2. ğŸ§  ì‹¬ë¦¬í•™ì  í•´ì„ (íŒŒì¸íŠœë‹)

#### ğŸ¯ íŒŒì¸íŠœë‹ì˜ í•„ìš”ì„±

**ë² ì´ìŠ¤ ëª¨ë¸ì˜ ë¬¸ì œì **:
- âŒ HTP ê²€ì‚¬ì˜ ì •ì˜ë¥¼ ë‚˜ì—´í•˜ëŠ” ë“± ë¶ˆí•„ìš”í•œ ì„œìˆ ë¡œ ì¶œë ¥ì´ ê¸¸ì–´ì§
- âŒ ì‹¤ì œ í•´ì„ë³´ë‹¤ëŠ” ì´ë¡ ì  ì„¤ëª…ì— ì¹˜ìš°ì¹¨
- âŒ ì¶œë ¥ í˜•ì‹ì´ ì¼ì •í•˜ì§€ ì•Šì•„ ì„œë¹„ìŠ¤ ì ìš©ì´ ì–´ë ¤ì›€

**íŒŒì¸íŠœë‹ ëª©í‘œ**:
- âœ… í†µì¼ì„± ìˆê³  ê¹”ë”í•œ í•´ì„ ì¶œë ¥
- âœ… ìµœì‹  HTP ë°ì´í„° ê¸°ë°˜ í•™ìŠµ (1,453ê°œ ìƒ˜í”Œ)
- âœ… ì„œë¹„ìŠ¤ ê°€ëŠ¥í•œ ì¼ê´€ëœ í¬ë§·

#### ğŸ”¬ ë‘ ê°€ì§€ íŒŒì¸íŠœë‹ ë°©ì‹

##### A. LoRA (Low-Rank Adaptation)
- **ë² ì´ìŠ¤ ëª¨ë¸**: Qwen/Qwen2.5-1.5B-Instruct
- **í•µì‹¬ ì›ë¦¬**: ëª¨ë¸ ì „ë°˜ì˜ ë ˆì´ì–´ì— ì–´ëŒ‘í„°ë¥¼ ì¶”ê°€í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
- **ë¹„ìœ **: íŠ¹ì§• ì¶”ì¶œë¶€í„° íŒë‹¨ê¹Œì§€ **ì „ ê³¼ì •ì— ê±¸ì³ ì¡°ê¸ˆì”© ë³€í™”**ë¥¼ ì£¼ëŠ” ë°©ì‹
- **ì¥ì **: 
  - ë¹ ë¥¸ í•™ìŠµ, ì ì€ ë©”ëª¨ë¦¬ (8GB GPU ê°€ëŠ¥)
  - ëª¨ë¸ ì „ì²´ì— ì˜í–¥ì„ ì£¼ì–´ ì„¬ì„¸í•œ ì¡°ì • ê°€ëŠ¥
- **íŒŒë¼ë¯¸í„°**: LoRA rank=8, alpha=32
- **í•™ìŠµ íŒŒë¼ë¯¸í„°**: 0.79M (ì „ì²´ì˜ 0.05%)

##### B. Layer Freezing â­ **ìµœì¢… ì„ íƒ**
- **ë² ì´ìŠ¤ ëª¨ë¸**: Qwen/Qwen2.5-1.5B-Instruct
- **í•µì‹¬ ì›ë¦¬**: ì•ë‹¨ ë ˆì´ì–´(26ê°œ)ëŠ” ê³ ì •, ë§ˆì§€ë§‰ ë ˆì´ì–´(2ê°œ)ë§Œ ì—…ë°ì´íŠ¸
- **ë¹„ìœ **: íŠ¹ì§• ì¶”ì¶œ ê¸°ì¤€ì€ ìœ ì§€í•˜ë˜, **ìµœì¢… íŒë‹¨ ê¸°ì¤€ë§Œ ë³€ê²½**í•˜ëŠ” ë°©ì‹
- **ì¥ì **: 
  - ë² ì´ìŠ¤ ëª¨ë¸ì˜ ê¸°ì¡´ ì§€ì‹ ë³´ì¡´ (Catastrophic Forgetting ë°©ì§€)
  - ê³¼ì í•© ë°©ì§€
  - ë” ì•ˆì •ì ì¸ ì¶œë ¥
- **ì„±ëŠ¥**: Training Loss 0.280 (67% ê°œì„ )
- **í•™ìŠµ íŒŒë¼ë¯¸í„°**: ~150M (ì „ì²´ì˜ 7-10%)

#### ğŸ“Š ìµœì¢… ëª¨ë¸ ì„ ì • ê¸°ì¤€: **ë² ì´ìŠ¤ ëª¨ë¸ê³¼ì˜ ìœ ì‚¬ë„**

HTP ê²€ì‚¬ëŠ” ì—­ì‚¬ê°€ ê¹Šì€ ê²€ì‚¬ë²•ìœ¼ë¡œ, ë² ì´ìŠ¤ ëª¨ë¸ì´ ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ ì´ë¯¸ ì¶©ë¶„í•œ ë°°ê²½ì§€ì‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ:

**ì„ ì • ì² í•™**:
> ëª¨ë¸ì´ ê°€ì§„ ê¸°ì¡´ ì§€ì‹ì„ ì™œê³¡í•˜ì§€ ì•Šìœ¼ë©´ì„œ,  
> ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë‹¤ë“¬ëŠ” ê²ƒì´ ëª©í‘œ

**í‰ê°€ ë°©ë²•**:
- **ì½”ì‚¬ì¸ ìœ ì‚¬ë„(Cosine Similarity)** ì¸¡ì •
- íŒŒì¸íŠœë‹ ì „ ëª¨ë¸(ë² ì´ìŠ¤)ê³¼ íŒŒì¸íŠœë‹ í›„ ëª¨ë¸ì˜ ì¶œë ¥ ë¹„êµ
- **ìœ ì‚¬ë„ê°€ ë†’ì„ìˆ˜ë¡** = ê¸°ì¡´ ì§€ì‹ì„ ì˜ ë³´ì¡´ = ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸

**ê²°ê³¼**: Layer Freezingì´ ë² ì´ìŠ¤ ëª¨ë¸ì˜ ì§€ì‹ì„ ë” ì˜ ë³´ì¡´í•˜ë©´ì„œë„ ì•ˆì •ì ì´ê³  ì •ì œëœ í•´ì„ì„ ì¶œë ¥í•˜ì—¬ ìµœì¢… ì„ íƒ

**ì¶œë ¥ ë¹„êµ ì˜ˆì‹œ**:
```
ì…ë ¥: "The tree is dominant and tall"

[ë² ì´ìŠ¤ ëª¨ë¸ - ë¬¸ì œì ]
"The HTP test is a projective psychological assessment tool...
[ë¶ˆí•„ìš”í•œ ì •ì˜ ë‚˜ì—´]
In general, trees represent growth and development...
[ì´ë¡ ì  ì„¤ëª…ë§Œ ë‚˜ì—´, í˜•ì‹ ë¶ˆì•ˆì •]"

[íŒŒì¸íŠœë‹ ëª¨ë¸ - ê°œì„ ë¨ âœ¨]
"This suggests a strong, assertive personality with a desire 
for control and leadership. The individual might be perceived 
as confident and possibly even domineering..."
[ê°„ê²°í•˜ê³  ì§ì ‘ì ì¸ í•´ì„, ì¼ê´€ëœ í˜•ì‹]
```

### 3. ğŸ’¬ ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ
ë©€í‹°í„´ ëŒ€í™”ë¥¼ í†µí•œ ì‹¬ì¸µ ìƒë‹´:

```
ì‚¬ìš©ì: ë‚˜ë¬´ë¥¼ í¬ê²Œ ê·¸ë ¸ì–´ìš”
AI: í° ë‚˜ë¬´ëŠ” ìì‹ ê°ê³¼ ì„±ì¥ ìš•êµ¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê°€ì§€ëŠ” ì–´ë–»ê²Œ ê·¸ë¦¬ì…¨ë‚˜ìš”?

ì‚¬ìš©ì: ê°€ì§€ê°€ ì•„ë˜ë¡œ ì²˜ì ¸ìˆì–´ìš”
AI: ì²˜ì§„ ê°€ì§€ëŠ” ìš°ìš¸ê°ì´ë‚˜ ì—ë„ˆì§€ ì €í•˜ë¥¼ ì‹œì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...
```

**ê¸°ëŠ¥**:
- âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ìœ ì§€
- âœ… ë©€í‹° ì¿¼ë¦¬ ìƒì„± (5ê°€ì§€ ê´€ì )
- âœ… Chroma DB ë²¡í„° ê²€ìƒ‰
- âœ… ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€

---

## ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

### íŒŒì¸íŠœë‹ ë°©ë²• ë¹„êµ

| í•­ëª© | LoRA | Layer Freezing â­ |
|------|------|------------------|
| **í•µì‹¬ ì›ë¦¬** | ì „ì²´ ë ˆì´ì–´ì— ì–´ëŒ‘í„° ì¶”ê°€ | ì•ë‹¨ ë™ê²°, ë§ˆì§€ë§‰ë§Œ í•™ìŠµ |
| **ë¹„ìœ ** | ì „ ê³¼ì • ì¡°ê¸ˆì”© ë³€í™” | íŒë‹¨ ê¸°ì¤€ë§Œ ë³€ê²½ |
| **í•™ìŠµ íŒŒë¼ë¯¸í„°** | 0.79M (0.05%) | ~150M (7-10%) |
| **í•™ìŠµ ì‹œê°„** | ~30ë¶„ | ~39ë¶„ |
| **ìµœì¢… Loss** | ~0.35 | **0.280** |
| **GPU ë©”ëª¨ë¦¬** | 6GB | 7GB |
| **ë² ì´ìŠ¤ ëª¨ë¸ ìœ ì‚¬ë„** | ë‚®ìŒ | **ë†’ìŒ (ì§€ì‹ ë³´ì¡´)** |
| **ì¶œë ¥ ì•ˆì •ì„±** | ì¢‹ìŒ | **ë§¤ìš° ì¢‹ìŒ** |
| **Catastrophic Forgetting** | ë°œìƒ ê°€ëŠ¥ì„± ìˆìŒ | **ë°©ì§€ë¨** |

### ë² ì´ìŠ¤ ëª¨ë¸ vs íŒŒì¸íŠœë‹ ë¹„êµ

#### ì‹¤ì œ ì¶œë ¥ ë¹„êµ

```
Input: "The tree is large with many branches"

âŒ Base Model (íŒŒì¸íŠœë‹ ì „):
"The House-Tree-Person (HTP) test is a projective psychological 
assessment tool that uses drawings to gain insights into an 
individual's personality, emotions, and psychological state.

In the context of HTP analysis, a large tree with many branches 
can be interpreted in several ways:

1. Growth and Development: Trees are often seen as symbols of 
growth, development, and maturity...
[ë¶ˆí•„ìš”í•œ ì •ì˜ì™€ ì´ë¡  ë‚˜ì—´, ì¶œë ¥ì´ ê³¼ë„í•˜ê²Œ ê¹€, í˜•ì‹ ë¶ˆì•ˆì •]"

âœ… Fine-tuned Model (íŒŒì¸íŠœë‹ í›„):
"This suggests a strong, assertive personality with a desire for 
control and leadership. The extensive branching indicates a complex 
personality with multiple interests and a tendency to spread oneself 
across various activities. The individual might be perceived as 
confident and possibly even domineering..."
[ê°„ê²°í•˜ê³  ì§ì ‘ì ì¸ í•´ì„, ì¼ê´€ëœ í˜•ì‹, ì„œë¹„ìŠ¤ ì ìš© ê°€ëŠ¥]
```

**ê°œì„  í¬ì¸íŠ¸**:
- âœ… ë¶ˆí•„ìš”í•œ ì •ì˜ ì œê±°
- âœ… í•µì‹¬ í•´ì„ì— ì§‘ì¤‘
- âœ… í†µì¼ëœ ì¶œë ¥ í˜•ì‹
- âœ… ì ì ˆí•œ ê¸¸ì´ ìœ ì§€

---

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. í™˜ê²½ ì„¤ì •

```bash
# Python 3.8+ í•„ìš”
pip install torch torchvision transformers
pip install datasets peft bitsandbytes accelerate
pip install chromadb langchain sentence-transformers
pip install pillow matplotlib jupyter
```

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

#### LoRA ëª¨ë¸
```bash
# Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
git lfs install
git clone https://huggingface.co/helena29/Qwen2.5_LoRA_for_HTP
```

#### Layer Freezing ëª¨ë¸
```bash
# ì´ë¯¸ í”„ë¡œì íŠ¸ì— í¬í•¨ë¨
ls layer_freezing/qwen2.5-htp-layer-freeze-final/
```

### 3. ë¹ ë¥¸ ì‹œì‘

#### A. ì´ë¯¸ì§€ ìº¡ì…”ë‹
```python
# captioning/model_qwen.ipynb ì‹¤í–‰
jupyter notebook captioning/model_qwen.ipynb
```

#### B. ì‹¬ë¦¬í•™ì  í•´ì„ (ëŒ€í™”í˜•)
```bash
# Layer Freezing ëª¨ë¸ ì‚¬ìš©
cd layer_freezing
python interactive_test.py
```

#### C. RAG ì‹œìŠ¤í…œ
```python
# combined/cleaned_ë©€í‹°í„´_ë©€í‹°ì¿¼ë¦¬_history_RAG.ipynb ì‹¤í–‰
jupyter notebook combined/cleaned_ë©€í‹°í„´_ë©€í‹°ì¿¼ë¦¬_history_RAG.ipynb
```

---

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### 1. Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‚¬ìš©

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# ëª¨ë¸ ë¡œë“œ
model_path = "./layer_freezing/qwen2.5-htp-layer-freeze-final"
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map="auto",
    torch_dtype=torch.float16
)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# í”„ë¡¬í”„íŠ¸ ìƒì„±
prompt = """<|im_start|>system
You are an expert psychologist specialized in HTP test interpretation.<|im_end|>
<|im_start|>user
Please interpret: The tree is very tall with dense branches<|im_end|>
<|im_start|>assistant
"""

# ìƒì„±
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.8)
interpretation = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(interpretation)
```

### 2. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸

```bash
cd layer_freezing
python interactive_test.py
```

```
ğŸ–¼ï¸  ì´ë¯¸ì§€ ìº¡ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”: The house has no windows

ğŸ¤– AI ì‹¬ë¦¬í•™ìê°€ ë¶„ì„ ì¤‘...

ğŸ“‹ ì‹¬ë¦¬í•™ì  í•´ì„:
A house without windows suggests a tendency towards isolation and 
emotional withdrawal. This may indicate difficulty in opening up to 
others or a protective mechanism to avoid vulnerability...

ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n):
```

---

## ğŸ“ ë°ì´í„° êµ¬ì¡°

### í•™ìŠµ ë°ì´í„° í˜•ì‹ (HTP_data.jsonl)

```jsonl
{
  "instruction": "Please provide a psychological interpretation of the following HTP test image caption",
  "input": "The tree is dominant and tall.",
  "output": "This suggests a strong, assertive personality with a desire for control and leadership...",
  "category": "tree"
}
```

- **ì´ ë°ì´í„°**: 1,453ê°œ
- **ì¹´í…Œê³ ë¦¬**: house, tree, person
- **ë¶„í• **: í•™ìŠµ 90% (1,307ê°œ), ê²€ì¦ 10% (146ê°œ)

### ìº¡ì…˜ ë°ì´í„° í˜•ì‹ (image_captions_qwen.json)

```json
{
  "image_001.jpg": {
    "caption": "The tree is large with many branches...",
    "model": "Qwen-VL",
    "timestamp": "2025-11-15"
  }
}
```

---

## ğŸ”¬ ì—°êµ¬ ë° ì‹¤í—˜

### ìº¡ì…”ë‹ ëª¨ë¸ ë¹„êµ

ì‹¤í—˜ ê²°ê³¼ëŠ” `model_comparison_results.csv` ì°¸ì¡°:

```bash
python merge_results.py
```

### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¶„ì„ (ìµœì¢… ëª¨ë¸ ì„ ì • ê¸°ì¤€)

**ëª©ì **: íŒŒì¸íŠœë‹ í›„ì—ë„ ë² ì´ìŠ¤ ëª¨ë¸ì˜ ê¸°ì¡´ ì§€ì‹ì´ ì˜ ë³´ì¡´ë˜ì—ˆëŠ”ì§€ í‰ê°€

```bash
# Qwen ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
cat cosine_similarity_qwen_embedding.csv
```

**ë¶„ì„ ë°©ë²•**:
1. ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ ë² ì´ìŠ¤ ëª¨ë¸ê³¼ íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì¶œë ¥ ìƒì„±
2. ë‘ ì¶œë ¥ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë²”ìœ„: 0~1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)

**ê²°ê³¼ í•´ì„**:
- **ë†’ì€ ìœ ì‚¬ë„** â†’ ë² ì´ìŠ¤ ëª¨ë¸ì˜ HTP ì§€ì‹ ë³´ì¡´ â†’ ì‹ ë¢°ë„ ë†’ìŒ
- **ë‚®ì€ ìœ ì‚¬ë„** â†’ ê³¼ë„í•œ ë³€í™” â†’ Catastrophic Forgetting ìš°ë ¤

**ìµœì¢… ì„ ì •**: Layer Freezing ë°©ì‹ì´ ë” ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë³´ì—¬ ìµœì¢… ëª¨ë¸ë¡œ ì„ íƒ

---

## ğŸ¯ ëª¨ë¸ í‰ê°€

### Layer Freezing ëª¨ë¸ ì „ì²´ í…ŒìŠ¤íŠ¸

```bash
cd layer_freezing
python test_htp_model.py
```

**ì¶œë ¥**:
- `test_results/test_results_YYYYMMDD_HHMMSS.json` (ìƒì„¸)
- `test_results/test_report_YYYYMMDD_HHMMSS.txt` (ìš”ì•½)

**í‰ê°€ í•­ëª©**:
- âœ… ê³ ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (5ê°œ)
- âœ… ëœë¤ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ (10ê°œ)
- âœ… ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ (house/tree/person)
- âœ… ìƒì„± í’ˆì§ˆ í‰ê°€

---

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

### Layer Freezing í•™ìŠµ ì„¤ì •

```python
TrainingArguments(
    num_train_epochs=10,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=4,  # ì‹¤ì§ˆ ë°°ì¹˜: 8
    learning_rate=5e-4,
    warmup_ratio=0.03,
    fp16=True,  # Mixed precision
    gradient_checkpointing=True,
    optim="adamw_torch",
    weight_decay=0.01,
)
```

### ìƒì„± íŒŒë¼ë¯¸í„°

```python
generate(
    max_new_tokens=256,
    temperature=0.8,        # ì°½ì˜ì„±
    top_p=0.95,            # Nucleus sampling
    top_k=40,              # Top-K sampling
    repetition_penalty=1.2, # ë°˜ë³µ ë°©ì§€
    no_repeat_ngram_size=3  # 3-gram ë°˜ë³µ ì°¨ë‹¨
)
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. CUDA Out of Memory

```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
per_device_train_batch_size=1
gradient_accumulation_steps=8

# ë˜ëŠ” max_tokens ì¤„ì´ê¸°
max_new_tokens=128  # ê¸°ë³¸ 256
```

### 2. ë°˜ë³µì ì¸ ì¶œë ¥ (ì˜ˆ: "system system...")

```python
# ì´ë¯¸ í•´ê²°ë¨!
repetition_penalty=1.2
no_repeat_ngram_size=3
```

### 3. ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

```bash
# ê²½ë¡œ í™•ì¸
ls layer_freezing/qwen2.5-htp-layer-freeze-final/

# íŒŒì¼ ê¶Œí•œ í™•ì¸ (Linux/Mac)
chmod -R 755 layer_freezing/qwen2.5-htp-layer-freeze-final/
```

### 4. Tokenizer ê²½ê³ 

```python
# pad_token ì„¤ì •
tokenizer.pad_token = tokenizer.eos_token
```

---

## ğŸ“š ê¸°ìˆ  ìŠ¤íƒ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  |
|----------|------|
| **ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬** | PyTorch 2.0+ |
| **ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬** | ğŸ¤— Transformers, PEFT |
| **ë¹„ì „ ëª¨ë¸** | BLIP, LLaVA, Qwen-VL |
| **ì–¸ì–´ ëª¨ë¸** | Qwen2.5-1.5B-Instruct |
| **ë²¡í„° DB** | ChromaDB |
| **ì„ë² ë”©** | Sentence-Transformers |
| **ê°œë°œ í™˜ê²½** | Jupyter Notebook, Python 3.8+ |

---

## ğŸ” ì£¼ìš” íŒŒì¼ ì„¤ëª…

### í•™ìŠµ ê´€ë ¨
- `layer_freezing/final_htp_model.ipynb`: Layer Freezing í•™ìŠµ ì „ì²´ ê³¼ì •
- `LoRa/LoRa.ipynb`: LoRA í•™ìŠµ ë° Hugging Face ì—…ë¡œë“œ
- `Data_generation.ipynb`: í•™ìŠµ ë°ì´í„° ìƒì„± ë„êµ¬

### ì¶”ë¡  ë° í…ŒìŠ¤íŠ¸
- `layer_freezing/test_htp_model.py`: ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- `layer_freezing/interactive_test.py`: ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤
- `test_base_model.ipynb`: ë² ì´ìŠ¤ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### RAG ì‹œìŠ¤í…œ
- `combined/rag_model_combined.ipynb`: ê¸°ë³¸ RAG êµ¬í˜„
- `combined/cleaned_ë©€í‹°í„´_ë©€í‹°ì¿¼ë¦¬_history_RAG.ipynb`: ê³ ê¸‰ ëŒ€í™”í˜• RAG

### ìœ í‹¸ë¦¬í‹°
- `merge_results.py`: ëª¨ë¸ ë¹„êµ ê²°ê³¼ ë³‘í•©
- `model_comparison_results.csv`: ëª¨ë¸ ì„±ëŠ¥ ë¹„êµí‘œ

---

## ğŸ“ˆ ë¡œë“œë§µ

### âœ… ì™„ë£Œ
- [x] 3ê°€ì§€ ìº¡ì…”ë‹ ëª¨ë¸ ë¹„êµ (BLIP, LLaVA, Qwen-VL)
- [x] LoRA íŒŒì¸íŠœë‹ êµ¬í˜„
- [x] Layer Freezing íŒŒì¸íŠœë‹ êµ¬í˜„
- [x] RAG ì‹œìŠ¤í…œ í†µí•©
- [x] ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ

---

## ğŸ“– ì°¸ê³  ìë£Œ

### HTP ê²€ì‚¬
- [HTP Test Wikipedia](https://en.wikipedia.org/wiki/House-tree-person_test)
- íˆ¬ì‚¬ì  ì‹¬ë¦¬ê²€ì‚¬ ê¸°ë²•ì˜ ì¼ì¢…
- ë¬´ì˜ì‹ì  ê°ì •ê³¼ ì„±ê²© íŠ¹ì„± ë¶„ì„

### ëª¨ë¸ ì•„í‚¤í…ì²˜
- [Qwen2.5 Technical Report](https://huggingface.co/Qwen)
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)
- [Instruction Tuning](https://arxiv.org/abs/2109.01652)

---

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” KT Cloud Tech Up í”„ë¡œê·¸ë¨ì˜ ì¼í™˜ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

---

## ğŸ“§ ë¬¸ì˜

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. GitHub Issuesì— ë“±ë¡
2. ë¡œê·¸ íŒŒì¼ ì²¨ë¶€
3. í™˜ê²½ ì •ë³´ í¬í•¨ (GPU, Python ë²„ì „ ë“±)

---

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.

---

## ğŸ™ ê°ì‚¬ì˜ ë§

- **Qwen Team**: ë² ì´ìŠ¤ ëª¨ë¸ ì œê³µ
- **Hugging Face**: ëª¨ë¸ í˜¸ìŠ¤íŒ… ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- **KT Cloud**: í”„ë¡œì íŠ¸ ì§€ì›

---

**ê°œë°œ ê¸°ê°„**: 2025.11 - 2025.12  
**ë²„ì „**: 1.0.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-12-01
