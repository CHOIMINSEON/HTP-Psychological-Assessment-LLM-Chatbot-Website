{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4e48ce",
   "metadata": {},
   "source": [
    "# Qwen2-VL-7B ì´ë¯¸ì§€ ìº¡ì…”ë‹\n",
    "\n",
    "Qwen2-VL-7B ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ìì„¸í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "ê° ì´ë¯¸ì§€ì˜ íŠ¹ì§•(í¬ê¸°, êµ¬ì¡°, ì„¸ë¶€ì‚¬í•­)ì„ ì„¤ëª…í•˜ëŠ” ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ccfeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb394e2",
   "metadata": {},
   "source": [
    "## GPU í™˜ê²½ í™•ì¸\n",
    "\n",
    "GPUê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ê³  ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” GPU í™˜ê²½ ì§„ë‹¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€\n",
    "print(f\"\\nâœ“ CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # GPU ì •ë³´\n",
    "    print(f\"âœ“ GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    print(f\"âœ“ í˜„ì¬ GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"âœ“ GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë³´\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    allocated_memory = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved_memory = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    free_memory = total_memory - reserved_memory\n",
    "    \n",
    "    print(f\"\\nğŸ“Š GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "    print(f\"   - ì „ì²´: {total_memory:.2f} GB\")\n",
    "    print(f\"   - í• ë‹¹ë¨: {allocated_memory:.2f} GB\")\n",
    "    print(f\"   - ì˜ˆì•½ë¨: {reserved_memory:.2f} GB\")\n",
    "    print(f\"   - ì‚¬ìš© ê°€ëŠ¥: {free_memory:.2f} GB\")\n",
    "    \n",
    "    # GPU ì‚¬ìš©ë¥  (ëŒ€ëµì )\n",
    "    usage_percent = (reserved_memory / total_memory) * 100\n",
    "    print(f\"   - ì‚¬ìš©ë¥ : {usage_percent:.1f}%\")\n",
    "    \n",
    "    # PyTorch ë²„ì „\n",
    "    print(f\"\\nâœ“ PyTorch ë²„ì „: {torch.__version__}\")\n",
    "    print(f\"âœ“ CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "    \n",
    "    # í…ì„œ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "    print(f\"\\nğŸ§ª GPU ì—°ì‚° í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "    test_tensor = torch.randn(1000, 1000).cuda()\n",
    "    result = test_tensor @ test_tensor.T\n",
    "    print(f\"âœ… GPU ì—°ì‚° ì •ìƒ ì‘ë™!\")\n",
    "    \n",
    "    del test_tensor, result\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸  CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(\"   CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ë§¤ìš° ëŠë¦¼)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a37aa",
   "metadata": {},
   "source": [
    "## 1. Qwen2-VL-7B ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "Qwen2-VL-7B-Instruct ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1f8eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Qwen2-VL-7B ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
      "âš ï¸  ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (~14GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbad7dbf085044ce8bfbe7d6a9b8ee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: cuda:0)\n",
      "âœ… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: 4.88 GB\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì„¤ì •\n",
    "model_name = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "print(\"ğŸ”„ Qwen2-VL-7B ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "print(\"âš ï¸  ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (~14GB)\")\n",
    "\n",
    "# í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {device})\")\n",
    "print(f\"âœ… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82a68e",
   "metadata": {},
   "source": [
    "## 2. ì´ë¯¸ì§€ ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dab9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def generate_detailed_caption(image_path, max_size=512):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        max_size: ì´ë¯¸ì§€ ìµœëŒ€ í¬ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "        \n",
    "    Returns:\n",
    "        ìƒì„±ëœ ìº¡ì…˜ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ (PIL Image ê°ì²´ë¡œ)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• (í° ì´ë¯¸ì§€ëŠ” ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\n",
    "        width, height = image.size\n",
    "        if max(width, height) > max_size:\n",
    "            ratio = max_size / max(width, height)\n",
    "            new_width = int(width * ratio)\n",
    "            new_height = int(height * ratio)\n",
    "            image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "            print(f\"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}\")\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ì„¤ì • - ì¹´í…Œê³ ë¦¬ + 5ê°€ì§€ íŠ¹ì„± ì„¤ëª…\n",
    "        prompt = \"\"\"Analyze this drawing and provide:\n",
    "\n",
    "CATEGORY: Identify if this is a drawing of a HOUSE, PERSON, or TREE. Write only one word.\n",
    "\n",
    "DESCRIPTION: Provide exactly 5 different descriptive sentences, each focusing on a distinct characteristic:\n",
    "1. Size and scale of objects (e.g., \"The tree is large with many branches\")\n",
    "2. Line quality and depth (e.g., \"deeply drawn roots\")\n",
    "3. Spatial composition and placement\n",
    "4. Detail level and complexity\n",
    "5. Overall impression or mood\n",
    "\n",
    "Format:\n",
    "CATEGORY: [HOUSE/PERSON/TREE]\n",
    "1. [First sentence]\n",
    "2. [Second sentence]\n",
    "3. [Third sentence]\n",
    "4. [Fourth sentence]\n",
    "5. [Fifth sentence]\"\"\"\n",
    "        \n",
    "        # ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": image,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # í”„ë¡œì„¸ì„œë¡œ ì…ë ¥ ì¤€ë¹„\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        print(f\"   â³ ì…ë ¥ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ë§Œ ì¶”ì¶œ (PIL Image ê°ì²´)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=[image],\n",
    "            videos=None,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        print(f\"   ğŸ¤– ìº¡ì…˜ ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ìº¡ì…˜ ìƒì„± (5ê°œ ë¬¸ì¥ì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=200,  # 5ê°œ ë¬¸ì¥ì„ ìœ„í•´ ì¦ê°€\n",
    "                min_new_tokens=50,\n",
    "                do_sample=False,  # Greedy decoding\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            )\n",
    "        \n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        caption = processor.batch_decode(\n",
    "            generated_ids_trimmed,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )[0]\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.1f}ì´ˆ\")\n",
    "        \n",
    "        return caption.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ ({image_path}): {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee29fc7",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ë¡œë”© í›„ GPU í™•ì¸\n",
    "\n",
    "ëª¨ë¸ì´ ì‹¤ì œë¡œ GPUì— ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f26daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” ëª¨ë¸ GPU ë°°ì¹˜ í™•ì¸\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ëª¨ë¸ì˜ ê° ë ˆì´ì–´ê°€ ì–´ë””ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "device_map = {}\n",
    "for name, param in model.named_parameters():\n",
    "    device = str(param.device)\n",
    "    if device not in device_map:\n",
    "        device_map[device] = 0\n",
    "    device_map[device] += 1\n",
    "\n",
    "print(f\"\\nğŸ“ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë°°ì¹˜:\")\n",
    "for device, count in device_map.items():\n",
    "    print(f\"   {device}: {count}ê°œ íŒŒë¼ë¯¸í„°\")\n",
    "\n",
    "# í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    print(f\"\\nğŸ“Š ëª¨ë¸ ë¡œë“œ í›„ GPU ë©”ëª¨ë¦¬:\")\n",
    "    print(f\"   í• ë‹¹ë¨: {allocated:.2f} GB\")\n",
    "    print(f\"   ì˜ˆì•½ë¨: {reserved:.2f} GB\")\n",
    "    \n",
    "    if allocated < 1.0:\n",
    "        print(f\"\\nâš ï¸  ê²½ê³ : GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤ ({allocated:.2f} GB)\")\n",
    "        print(f\"   ëª¨ë¸ì´ CPUì— ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… ëª¨ë¸ì´ GPUì— ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b289fce",
   "metadata": {},
   "source": [
    "## 3. ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì²˜ë¦¬\n",
    "\n",
    "test í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af14fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: C:\\Users\\helen\\Desktop\\kt cloud tech up\\basic_project\\test\n",
      "ğŸ–¼ï¸  ë°œê²¬ëœ ì´ë¯¸ì§€: 4ê°œ\n",
      "\n",
      "   - test_ë‚˜ë¬´.JPG\n",
      "   - test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   - test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   - test_ì§‘.JPG\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "image_dir = r\"C:\\Users\\helen\\Desktop\\kt cloud tech up\\basic_project\\test\"\n",
    "output_file = \"image_captions_with_category.json\"\n",
    "\n",
    "# ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(Path(image_dir).glob(f'*{ext}'))\n",
    "    image_files.extend(Path(image_dir).glob(f'*{ext.upper()}'))\n",
    "\n",
    "image_files = sorted(set(image_files))\n",
    "\n",
    "print(f\"ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {image_dir}\")\n",
    "print(f\"ğŸ–¼ï¸  ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ\\n\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    for img in image_files:\n",
    "        print(f\"   - {img.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de531a11",
   "metadata": {},
   "source": [
    "## 4. ìº¡ì…˜ ìƒì„± ì‹¤í–‰\n",
    "\n",
    "ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ìº¡ì…˜ì„ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3854f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¨ ìº¡ì…˜ ìƒì„± ì‹œì‘\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/4] ì²˜ë¦¬ ì¤‘: test_ë‚˜ë¬´.JPG\n",
      "   â³ ì…ë ¥ ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ¤– ìº¡ì…˜ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 632.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "ğŸ“ ìº¡ì…˜: CATEGORY: TREE\n",
      "1. The tree is large with many branches.\n",
      "2. The lines are deeply drawn, especially in the roots.\n",
      "3. The tree is centrally placed with a clear sky background.\n",
      "4. The detail level is moderate, with flowers and leaves.\n",
      "5. The overall impression is serene and natural.\n",
      "\n",
      "[2/4] ì²˜ë¦¬ ì¤‘: test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   â³ ì…ë ¥ ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¤– ìº¡ì…˜ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 681.0ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "ğŸ“ ìº¡ì…˜: CATEGORY: PERSON\n",
      "1. The drawing is small in size, focusing on a single figure.\n",
      "2. The lines are simple and unshaded, indicating a basic outline.\n",
      "3. The figure is centrally placed, with no additional background elements.\n",
      "4. There is minimal detail, with no facial features or clothing textures.\n",
      "5. The overall impression is minimalistic and abstract.\n",
      "\n",
      "[3/4] ì²˜ë¦¬ ì¤‘: test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   â³ ì…ë ¥ ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¤– ìº¡ì…˜ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 802.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "ğŸ“ ìº¡ì…˜: CATEGORY: PERSON\n",
      "1. The figure is small in size, suggesting it is a child or a toy.\n",
      "2. The lines are simple and unrefined, indicating a child's drawing.\n",
      "3. The figure is centered in the image, with arms and legs spread out.\n",
      "4. There is minimal detail, with no facial features or clothing details.\n",
      "5. The overall impression is playful and innocent, evoking a sense of childhood.\n",
      "\n",
      "[4/4] ì²˜ë¦¬ ì¤‘: test_ì§‘.JPG\n",
      "   â³ ì…ë ¥ ì²˜ë¦¬ ì¤‘...\n",
      "   ğŸ¤– ìº¡ì…˜ ìƒì„± ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 754.0ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "ğŸ“ ìº¡ì…˜: CATEGORY: HOUSE\n",
      "1. The drawing is small in size, depicting a simple structure.\n",
      "2. The lines are thin and simple, lacking depth or shading.\n",
      "3. The house is centrally placed on the page with a clear roof and door.\n",
      "4. The drawing is minimalistic with few details, focusing on the basic shape.\n",
      "5. The overall impression is of a basic, childlike representation of a house.\n",
      "\n",
      "======================================================================\n",
      "âœ¨ ì´ 4ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: 2869.4ì´ˆ (í‰ê· : 717.3ì´ˆ/ì´ë¯¸ì§€)\n",
      "======================================================================\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 754.0ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "ğŸ“ ìº¡ì…˜: CATEGORY: HOUSE\n",
      "1. The drawing is small in size, depicting a simple structure.\n",
      "2. The lines are thin and simple, lacking depth or shading.\n",
      "3. The house is centrally placed on the page with a clear roof and door.\n",
      "4. The drawing is minimalistic with few details, focusing on the basic shape.\n",
      "5. The overall impression is of a basic, childlike representation of a house.\n",
      "\n",
      "======================================================================\n",
      "âœ¨ ì´ 4ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: 2869.4ì´ˆ (í‰ê· : 717.3ì´ˆ/ì´ë¯¸ì§€)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ìº¡ì…˜ ìƒì„±\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¨ ìº¡ì…˜ ìƒì„± ì‹œì‘\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, image_path in enumerate(image_files, 1):\n",
    "    print(f\"\\n[{i}/{len(image_files)}] ì²˜ë¦¬ ì¤‘: {image_path.name}\")\n",
    "    \n",
    "    caption = generate_detailed_caption(str(image_path))\n",
    "    \n",
    "    if caption:\n",
    "        # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (CATEGORY: ë‹¤ìŒì— ì˜¤ëŠ” ë‹¨ì–´)\n",
    "        category = \"UNKNOWN\"\n",
    "        if \"CATEGORY:\" in caption:\n",
    "            try:\n",
    "                category_line = caption.split(\"CATEGORY:\")[1].split(\"\\n\")[0].strip()\n",
    "                category = category_line.upper()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        results[image_path.name] = {\n",
    "            \"path\": str(image_path),\n",
    "            \"category\": category,\n",
    "            \"caption\": caption\n",
    "        }\n",
    "        print(f\"âœ… ì™„ë£Œ\")\n",
    "        print(f\"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "        print(f\"ğŸ“ ìº¡ì…˜: {caption}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ¨ ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ (í‰ê· : {total_elapsed/len(image_files):.1f}ì´ˆ/ì´ë¯¸ì§€)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071497f",
   "metadata": {},
   "source": [
    "## 5. ê²°ê³¼ ì €ì¥\n",
    "\n",
    "ìƒì„±ëœ ìº¡ì…˜ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65bea1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: image_captions_with_category.json\n",
      "ğŸ“Š ì´ 4ê°œ ì´ë¯¸ì§€ ìº¡ì…˜ ì €ì¥ë¨\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ ìƒì„±ëœ ìº¡ì…˜ ìš”ì•½\n",
      "======================================================================\n",
      "\n",
      "ğŸ–¼ï¸  test_ë‚˜ë¬´.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "   ğŸ“ ìº¡ì…˜: CATEGORY: TREE\n",
      "1. The tree is large with many branches.\n",
      "2. The lines are deeply drawn, especially in...\n",
      "\n",
      "ğŸ–¼ï¸  test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "   ğŸ“ ìº¡ì…˜: CATEGORY: PERSON\n",
      "1. The drawing is small in size, focusing on a single figure.\n",
      "2. The lines are simp...\n",
      "\n",
      "ğŸ–¼ï¸  test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "   ğŸ“ ìº¡ì…˜: CATEGORY: PERSON\n",
      "1. The figure is small in size, suggesting it is a child or a toy.\n",
      "2. The lines are...\n",
      "\n",
      "ğŸ–¼ï¸  test_ì§‘.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "   ğŸ“ ìº¡ì…˜: CATEGORY: HOUSE\n",
      "1. The drawing is small in size, depicting a simple structure.\n",
      "2. The lines are thin...\n"
     ]
    }
   ],
   "source": [
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "print(f\"ğŸ“Š ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ìº¡ì…˜ ì €ì¥ë¨\\n\")\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“‹ ìƒì„±ëœ ìº¡ì…˜ ìš”ì•½\")\n",
    "print(\"=\" * 70)\n",
    "for filename, data in results.items():\n",
    "    print(f\"\\nğŸ–¼ï¸  {filename}\")\n",
    "    print(f\"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {data.get('category', 'UNKNOWN')}\")\n",
    "    print(f\"   ğŸ“ ìº¡ì…˜: {data['caption'][:100]}{'...' if len(data['caption']) > 100 else ''}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
