{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e836e762",
   "metadata": {},
   "source": [
    "## âš ï¸ ë©”ëª¨ë¦¬ ì ˆì•½ íŒ\n",
    "\n",
    "8GB GPUì—ì„œ í¬ë˜ì‹œê°€ ë°œìƒí•˜ë©´:\n",
    "1. ë‹¤ë¥¸ GPU ì‚¬ìš© í”„ë¡œê·¸ë¨ ì¢…ë£Œ\n",
    "2. ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰: `nvidia-smi` ë¡œ GPU ë©”ëª¨ë¦¬ í™•ì¸\n",
    "3. ì—¬ì „íˆ í¬ë˜ì‹œ ì‹œ â†’ **ë” ê°€ë²¼ìš´ BLIP-1 ì‚¬ìš© ì¶”ì²œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f8d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import torch\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c36f3",
   "metadata": {},
   "source": [
    "## 1. GPU í™˜ê²½ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26bfc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ” GPU í™˜ê²½ ì§„ë‹¨\n",
      "======================================================================\n",
      "\n",
      "âœ“ CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
      "âœ“ GPU ì´ë¦„: NVIDIA GeForce RTX 4060\n",
      "âœ“ GPU ë©”ëª¨ë¦¬: 8.00 GB\n",
      "âœ“ PyTorch ë²„ì „: 2.9.1+cu128\n",
      "âœ“ CUDA ë²„ì „: 12.8\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” GPU í™˜ê²½ ì§„ë‹¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nâœ“ CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"âœ“ GPU ë©”ëª¨ë¦¬: {total_memory:.2f} GB\")\n",
    "    print(f\"âœ“ PyTorch ë²„ì „: {torch.__version__}\")\n",
    "    print(f\"âœ“ CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤! CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ë§¤ìš° ëŠë¦¼)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eebc92",
   "metadata": {},
   "source": [
    "## 2. BLIP-2 ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "BLIP-2-OPT-2.7B ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (Qwen2-VLë³´ë‹¤ í›¨ì”¬ ê°€ë²¼ì›€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ecd960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ BLIP-2 ëª¨ë¸ ë¡œë“œ ì¤‘...\n",
      "âš ï¸  ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (~5GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 6: invalid start byte\n",
      "Exception in thread Thread-6 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\subprocess.py\", line 1515, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"c:\\Users\\helen\\anaconda3\\envs\\LLMenv\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 6: invalid start byte\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea95756282704e95b8a008f86ca49dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: cuda)\n",
      "âœ… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: 3.92 GB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Salesforce/blip2-opt-2.7b\"\n",
    "\n",
    "print(\"ğŸ”„ BLIP-2 ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "print(\"âš ï¸  ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (~5GB)\")\n",
    "\n",
    "# í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (8bit ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True  # ë©”ëª¨ë¦¬ ì ˆì•½\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {device})\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"âœ… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: {allocated:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f48d1",
   "metadata": {},
   "source": [
    "## 3. ì´ë¯¸ì§€ ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034282c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def generate_detailed_caption(image_path, max_size=512):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "        max_size: ì´ë¯¸ì§€ ìµœëŒ€ í¬ê¸°\n",
    "        \n",
    "    Returns:\n",
    "        dict: categoryì™€ captionì„ í¬í•¨í•œ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•\n",
    "        width, height = image.size\n",
    "        if max(width, height) > max_size:\n",
    "            ratio = max_size / max(width, height)\n",
    "            new_width = int(width * ratio)\n",
    "            new_height = int(height * ratio)\n",
    "            image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "            print(f\"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}\")\n",
    "        \n",
    "        # 1ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\n",
    "        print(f\"   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\")\n",
    "        category_prompt = \"a photo of\"\n",
    "        \n",
    "        inputs = processor(image, text=category_prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            category_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=20,\n",
    "                min_new_tokens=1,\n",
    "            )\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ì œê±°í•˜ê³  ë‹µë³€ë§Œ ì¶”ì¶œ\n",
    "        category_text = processor.decode(category_ids[0], skip_special_tokens=True)\n",
    "        category_text = category_text.replace(category_prompt, \"\").strip().upper()\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ ì •ê·œí™”\n",
    "        if \"HOUSE\" in category_text or \"HOME\" in category_text or \"BUILDING\" in category_text:\n",
    "            category = \"HOUSE\"\n",
    "        elif \"PERSON\" in category_text or \"PEOPLE\" in category_text or \"MAN\" in category_text or \"WOMAN\" in category_text or \"HUMAN\" in category_text:\n",
    "            category = \"PERSON\"\n",
    "        elif \"TREE\" in category_text or \"PLANT\" in category_text:\n",
    "            category = \"TREE\"\n",
    "        else:\n",
    "            category = \"UNKNOWN\"\n",
    "        \n",
    "        print(f\"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "        \n",
    "        # 2ë‹¨ê³„: 5ê°€ì§€ íŠ¹ì„± ì„¤ëª… ìƒì„±\n",
    "        print(f\"   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # BLIP-2ëŠ” ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ê°€ ë” íš¨ê³¼ì \n",
    "        description_prompt = f\"Describe this {category.lower()} drawing in detail:\"\n",
    "        \n",
    "        inputs = processor(image, text=description_prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            caption_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=120,\n",
    "                min_new_tokens=40,\n",
    "                do_sample=True,  # ìƒ˜í”Œë§ í™œì„±í™”\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.5,  # ë°˜ë³µ ë°©ì§€ (ì¤‘ìš”!)\n",
    "                no_repeat_ngram_size=3,  # 3ë‹¨ì–´ ì´ìƒ ë°˜ë³µ ë°©ì§€\n",
    "            )\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ ì œê±°í•˜ê³  ë‹µë³€ë§Œ ì¶”ì¶œ\n",
    "        caption = processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "        caption = caption.replace(description_prompt, \"\").strip()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.1f}ì´ˆ\")\n",
    "        \n",
    "        return {\n",
    "            \"category\": category,\n",
    "            \"caption\": caption\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ ({image_path}): {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ìº¡ì…”ë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b3209",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50063d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: C:\\Users\\helen\\Desktop\\kt cloud tech up\\basic_project\\test\n",
      "ğŸ–¼ï¸  ë°œê²¬ëœ ì´ë¯¸ì§€: 4ê°œ\n",
      "\n",
      "   - test_ë‚˜ë¬´.JPG\n",
      "   - test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   - test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   - test_ì§‘.JPG\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "image_dir = r\"C:\\Users\\helen\\Desktop\\kt cloud tech up\\basic_project\\test\"\n",
    "output_file = \"image_captions_blip.json\"\n",
    "\n",
    "# ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(Path(image_dir).glob(f'*{ext}'))\n",
    "    image_files.extend(Path(image_dir).glob(f'*{ext.upper()}'))\n",
    "\n",
    "image_files = sorted(set(image_files))\n",
    "\n",
    "print(f\"ğŸ“ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {image_dir}\")\n",
    "print(f\"ğŸ–¼ï¸  ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ\\n\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    for img in image_files:\n",
    "        print(f\"   - {img.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1b8c5",
   "metadata": {},
   "source": [
    "## 5. ìº¡ì…˜ ìƒì„± ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f44a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¨ ìº¡ì…˜ ìƒì„± ì‹œì‘\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[1/4] ì²˜ë¦¬ ì¤‘: test_ë‚˜ë¬´.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.7ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "ğŸ“ ìº¡ì…˜: trees, springtime and leaves are drawn with a simple line tool the whole sketch is shown on one page by two lines that have been moved from each other...\n",
      "\n",
      "[2/4] ì²˜ë¦¬ ì¤‘: test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.7ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "ğŸ“ ìº¡ì…˜: trees, springtime and leaves are drawn with a simple line tool the whole sketch is shown on one page by two lines that have been moved from each other...\n",
      "\n",
      "[2/4] ì²˜ë¦¬ ì¤‘: test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 8.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "ğŸ“ ìº¡ì…˜: what is he wearing? where did the picture come from and how was it created using only a pencil or pen for example, do you know which colour of graphit...\n",
      "\n",
      "[3/4] ì²˜ë¦¬ ì¤‘: test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 8.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "ğŸ“ ìº¡ì…˜: what is he wearing? where did the picture come from and how was it created using only a pencil or pen for example, do you know which colour of graphit...\n",
      "\n",
      "[3/4] ì²˜ë¦¬ ì¤‘: test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: UNKNOWN\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: UNKNOWN\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: UNKNOWN\n",
      "ğŸ“ ìº¡ì…˜: a person standing with arms outstretched, looking towards the sky and raising their hands to stretch them up into an upward position. The image is of ...\n",
      "\n",
      "[4/4] ì²˜ë¦¬ ì¤‘: test_ì§‘.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: UNKNOWN\n",
      "ğŸ“ ìº¡ì…˜: a person standing with arms outstretched, looking towards the sky and raising their hands to stretch them up into an upward position. The image is of ...\n",
      "\n",
      "[4/4] ì²˜ë¦¬ ì¤‘: test_ì§‘.JPG\n",
      "   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "   ğŸ“ ìƒì„¸ ì„¤ëª… ìƒì„± ì¤‘...\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "ğŸ“ ìº¡ì…˜: the roof, entrance and windows of a large building with an attached garage door person's sketchbook page 1 p.4 note on writing for kids pencil sketche...\n",
      "\n",
      "======================================================================\n",
      "âœ¨ ì´ 4ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: 39.0ì´ˆ (í‰ê· : 9.8ì´ˆ/ì´ë¯¸ì§€)\n",
      "======================================================================\n",
      "   â±ï¸  ì²˜ë¦¬ ì‹œê°„: 10.1ì´ˆ\n",
      "âœ… ì™„ë£Œ\n",
      "ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "ğŸ“ ìº¡ì…˜: the roof, entrance and windows of a large building with an attached garage door person's sketchbook page 1 p.4 note on writing for kids pencil sketche...\n",
      "\n",
      "======================================================================\n",
      "âœ¨ ì´ 4ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: 39.0ì´ˆ (í‰ê· : 9.8ì´ˆ/ì´ë¯¸ì§€)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ìº¡ì…˜ ìƒì„±\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ¨ ìº¡ì…˜ ìƒì„± ì‹œì‘\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, image_path in enumerate(image_files, 1):\n",
    "    print(f\"\\n[{i}/{len(image_files)}] ì²˜ë¦¬ ì¤‘: {image_path.name}\")\n",
    "    \n",
    "    result = generate_detailed_caption(str(image_path))\n",
    "    \n",
    "    if result:\n",
    "        results[image_path.name] = {\n",
    "            \"path\": str(image_path),\n",
    "            \"category\": result[\"category\"],\n",
    "            \"caption\": result[\"caption\"]\n",
    "        }\n",
    "        print(f\"âœ… ì™„ë£Œ\")\n",
    "        print(f\"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {result['category']}\")\n",
    "        print(f\"ğŸ“ ìº¡ì…˜: {result['caption'][:150]}{'...' if len(result['caption']) > 150 else ''}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨\")\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ¨ ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"â±ï¸  ì „ì²´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ (í‰ê· : {total_elapsed/len(image_files):.1f}ì´ˆ/ì´ë¯¸ì§€)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58631cee",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7cd19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: image_captions_blip.json\n",
      "ğŸ“Š ì´ 4ê°œ ì´ë¯¸ì§€ ìº¡ì…˜ ì €ì¥ë¨\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ ìƒì„±ëœ ìº¡ì…˜ ìš”ì•½\n",
      "======================================================================\n",
      "\n",
      "ğŸ–¼ï¸  test_ë‚˜ë¬´.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: TREE\n",
      "   ğŸ“ ìº¡ì…˜: trees, springtime and leaves are drawn with a simple line tool the whole sketch is shown on one page...\n",
      "\n",
      "ğŸ–¼ï¸  test_ë‚¨ìì‚¬ëŒ.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: PERSON\n",
      "   ğŸ“ ìº¡ì…˜: what is he wearing? where did the picture come from and how was it created using only a pencil or pe...\n",
      "\n",
      "ğŸ–¼ï¸  test_ì—¬ìì‚¬ëŒ.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: UNKNOWN\n",
      "   ğŸ“ ìº¡ì…˜: a person standing with arms outstretched, looking towards the sky and raising their hands to stretch...\n",
      "\n",
      "ğŸ–¼ï¸  test_ì§‘.JPG\n",
      "   ğŸ“‚ ì¹´í…Œê³ ë¦¬: HOUSE\n",
      "   ğŸ“ ìº¡ì…˜: the roof, entrance and windows of a large building with an attached garage door person's sketchbook ...\n"
     ]
    }
   ],
   "source": [
    "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "print(f\"ğŸ“Š ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ìº¡ì…˜ ì €ì¥ë¨\\n\")\n",
    "\n",
    "# ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“‹ ìƒì„±ëœ ìº¡ì…˜ ìš”ì•½\")\n",
    "print(\"=\" * 70)\n",
    "for filename, data in results.items():\n",
    "    print(f\"\\nğŸ–¼ï¸  {filename}\")\n",
    "    print(f\"   ğŸ“‚ ì¹´í…Œê³ ë¦¬: {data.get('category', 'UNKNOWN')}\")\n",
    "    print(f\"   ğŸ“ ìº¡ì…˜: {data['caption'][:100]}{'...' if len(data['caption']) > 100 else ''}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
