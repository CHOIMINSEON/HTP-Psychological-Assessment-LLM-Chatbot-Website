{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ce1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Optional, Callable\n",
    "import re\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# 간단한 progress reporter (콘솔 출력용)\n",
    "def simple_progress_reporter(stage: str, status: str, details: Optional[Dict] = None):\n",
    "    from datetime import datetime\n",
    "    ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    details = details or {}\n",
    "    print(f\"[{ts}] {stage.upper():8} | {status.upper():7} | {details}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ea0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. 문서 로더 및 전처리\n",
    "# ============================================================================\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"다양한 형식의 문서를 읽고 청킹하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap # 청크 1000자, 겹침 200자\n",
    "    \n",
    "    def load_documents(self, file_paths: List[str]) -> List[Dict[str, str]]:\n",
    "        \"\"\"여러 형식의 문서 로드\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if file_path.endswith('.txt'):\n",
    "                content = self._load_txt(file_path)\n",
    "            elif file_path.endswith('.md'):\n",
    "                content = self._load_markdown(file_path)\n",
    "            elif file_path.endswith('.pdf'):\n",
    "                content = self._load_pdf(file_path)\n",
    "            elif file_path.endswith('.json'):\n",
    "                content = self._load_json(file_path)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if content:\n",
    "                documents.append({\n",
    "                    'source': file_path,\n",
    "                    'content': content,\n",
    "                    'type': file_path.split('.')[-1] #txt, md, pdf, json 등\n",
    "                })\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _load_txt(self, file_path: str) -> str:\n",
    "        \"\"\"텍스트 파일 로드\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _load_markdown(self, file_path: str) -> str:\n",
    "        \"\"\"마크다운 파일 로드\"\"\"\n",
    "        return self._load_txt(file_path)\n",
    "    \n",
    "    def _load_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"PDF 파일 로드 (PyPDF2 필요)\"\"\"\n",
    "        try:\n",
    "            import PyPDF2\n",
    "            with open(file_path, 'rb') as f:\n",
    "                pdf_reader = PyPDF2.PdfReader(f)\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "                return text #text=전체 PDF 텍스트\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading PDF {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _load_json(self, file_path: str) -> str:\n",
    "        \"\"\"JSON 파일 로드 (텍스트 추출)\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # JSON 데이터를 문자열로 변환\n",
    "                if isinstance(data, list):\n",
    "                    return \"\\n\".join(str(item) for item in data)\n",
    "                elif isinstance(data, dict):\n",
    "                    return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "                else:\n",
    "                    return str(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading JSON {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def chunk_text(self, text: str) -> List[str]:\n",
    "        \"\"\"텍스트를 청크로 분할\"\"\"\n",
    "        chunks = []\n",
    "        step = self.chunk_size - self.chunk_overlap\n",
    "        \n",
    "        for i in range(0, len(text), step):\n",
    "            chunk = text[i:i + self.chunk_size]\n",
    "            if len(chunk) > 100:  # 너무 짧은 청크 제외\n",
    "                chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def preprocess_documents(self, documents: List[Dict]) -> List[str]:\n",
    "        \"\"\"문서 전처리 및 청킹\"\"\"\n",
    "        all_chunks = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            # 불필요한 공백 제거\n",
    "            content = re.sub(r'\\s+', ' ', doc['content'])\n",
    "            # 청킹\n",
    "            chunks = self.chunk_text(content)\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        print(f\"총 {len(all_chunks)}개 청크 생성\")\n",
    "        return all_chunks#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601f1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. LLM 기반 자동 생성 (Ollama 또는 API 사용)\n",
    "# ============================================================================\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class CaptionDataGeneratorKor:\n",
    "    \"\"\"LLM을 사용하여 caption-interpretation 쌍 자동 생성\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"mistral\", use_local: bool = True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - model_name: 사용할 LLM 모델명\n",
    "        - use_local: Ollama 같은 로컬 모델 사용 여부\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_local = use_local\n",
    "        self.llm = None\n",
    "        self._init_llm()\n",
    "    \n",
    "    def _init_llm(self):\n",
    "        \"\"\"LLM 초기화\"\"\"\n",
    "        if self.use_local:\n",
    "            try:\n",
    "                self.llm = OllamaLLM(\n",
    "                    model=self.model_name,\n",
    "                    temperature=0.7,\n",
    "                    num_ctx=2048,\n",
    "                )\n",
    "                print(f\"✓ Ollama 모델 로드: {self.model_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Ollama 로드 실패: {e}\")\n",
    "                print(\"  대안: OpenAI API 사용\")\n",
    "        else:\n",
    "            try:\n",
    "                from langchain.llms import OpenAI\n",
    "                self.llm = OpenAI(\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=500\n",
    "                )\n",
    "                print(\"✓ OpenAI 모델 로드\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ OpenAI 로드 실패: {e}\")\n",
    "    \n",
    "    def generate_qa_pairs(self, chunk: str, num_pairs: int = 2) -> List[Dict[str, str]]:\n",
    "        \"\"\"문서 청크로부터 QA 쌍 생성\"\"\"\n",
    "        \n",
    "        if not self.llm:\n",
    "            print(\"✗ LLM이 초기화되지 않았습니다\")\n",
    "            return []\n",
    "        \n",
    "        prompt = f\"\"\"다음 문서 내용을 읽고, HTP 검사 해석과 관련하여 최대{num_pairs}개의 캡션-해석 쌍을 생성해주세요.\n",
    "\n",
    "문서 내용:\n",
    "{chunk}\n",
    "\n",
    "요구사항:\n",
    "1. 각 쌍은 실제 HTP 검사에서 나올 수 있는 HTP 그림 관련 캡션과 심리학적 해석\n",
    "2. JSON 배열 형식으로 반환\n",
    "3. 형식: {{\"caption\": \"캡션\", \"interpretation\": \"해석\"}}\n",
    "4. 캡션은 간결하게, 해석은 충분히 상세하게\n",
    "5. 총 {num_pairs}개\n",
    "6. 문서를 참고해서 제작이 불가능할 경우 빈 배열 반환\n",
    "예시) {{\"caption\": \"집의 크기가 크다\", \"interpretation\": \"대상자가 상상력이 풍부하거나 책임감이 강하다고 해석할 수 있다.\"}}\n",
    "\n",
    "JSON 배열만 반환 (설명 없음):\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # 안전하게 중괄호를 이스케이프하여 llm wrapper 내부에서 .format이 사용되더라도 에러가 나지 않게 함\n",
    "            safe_prompt = prompt.replace('{', '{{').replace('}', '}}')\n",
    "            response = self.llm.invoke(safe_prompt)\n",
    "            # JSON 파싱\n",
    "            pairs = self._parse_json_response(response)\n",
    "            return pairs\n",
    "        except Exception as e:\n",
    "            print(f\"✗ 생성 중 오류: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _parse_json_response(self, response: str) -> List[Dict]:\n",
    "        \"\"\"응답에서 JSON 추출\"\"\"\n",
    "        try:\n",
    "            # 응답에서 JSON 배열 찾기\n",
    "            json_start = response.find('[')\n",
    "            json_end = response.rfind(']') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response[json_start:json_end]\n",
    "                return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"✗ JSON 파싱 실패\")\n",
    "            print(response)\n",
    "            return []\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    def batch_generate(self, chunks: List[str], num_pairs_per_chunk: int = 2) -> List[Dict]:\n",
    "        \"\"\"여러 청크로부터 일괄 생성\"\"\"\n",
    "        all_pairs = []\n",
    "        \n",
    "        print(f\"\\n[자동 생성 시작] 총 {len(chunks)}개 청크 처리 중...\")\n",
    "        \n",
    "        # tqdm으로 진행바 표시\n",
    "        for chunk in tqdm(chunks, desc='Generating', unit='chunk'):\n",
    "            pairs = self.generate_qa_pairs(chunk, num_pairs_per_chunk)\n",
    "            all_pairs.extend(pairs)\n",
    "        \n",
    "        print(f\"✓ 총 {len(all_pairs)}개 쌍 생성 완료\\n\")\n",
    "        return all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8c3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. LLM 기반 자동 생성 (Ollama 또는 API 사용)\n",
    "# ============================================================================\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class CaptionDataGeneratorEng:\n",
    "    \"\"\"LLM을 사용하여 caption-interpretation 쌍 자동 생성\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"mistral\", use_local: bool = True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - model_name: 사용할 LLM 모델명\n",
    "        - use_local: Ollama 같은 로컬 모델 사용 여부\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.use_local = use_local\n",
    "        self.llm = None\n",
    "        self._init_llm()\n",
    "    \n",
    "    def _init_llm(self):\n",
    "        \"\"\"LLM 초기화\"\"\"\n",
    "        if self.use_local:\n",
    "            try:\n",
    "                self.llm = OllamaLLM(\n",
    "                    model=self.model_name,\n",
    "                    temperature=0.7,\n",
    "                    num_ctx=2048,\n",
    "                )\n",
    "                print(f\"✓ Ollama 모델 로드: {self.model_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Ollama 로드 실패: {e}\")\n",
    "                print(\"  대안: OpenAI API 사용\")\n",
    "        else:\n",
    "            try:\n",
    "                from langchain.llms import OpenAI\n",
    "                self.llm = OpenAI(\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=500\n",
    "                )\n",
    "                print(\"✓ OpenAI 모델 로드\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ OpenAI 로드 실패: {e}\")\n",
    "    \n",
    "    def generate_qa_pairs(self, chunk: str, num_pairs: int = 2) -> List[Dict[str, str]]:\n",
    "        \"\"\"문서 청크로부터 QA 쌍 생성\"\"\"\n",
    "        \n",
    "        if not self.llm:\n",
    "            print(\"✗ LLM이 초기화되지 않았습니다\")\n",
    "            return []\n",
    "        \n",
    "        prompt = f\"\"\"Read the following document content and generate up to {num_pairs} caption-interpretation pairs related to HTP (House-Tree-Person) test interpretation.\n",
    "\n",
    "\n",
    "Document Content:\n",
    "{chunk}\n",
    "\n",
    "\n",
    "Requirements:\n",
    "1. Each pair consists of an HTP drawing-related caption and psychological interpretation that could occur in an actual HTP assessment\n",
    "2. Return in JSON array format\n",
    "3. Format: {{\"caption\": \"caption text\", \"interpretation\": \"interpretation text\"}}\n",
    "4. Keep captions concise; provide detailed interpretations\n",
    "5. Total of {num_pairs} pairs\n",
    "6. If it's impossible to generate pairs based on the document, return an empty array\n",
    "Example) {{\"caption\": \"The house size is large\", \"interpretation\": \"The subject may be interpreted as having a rich imagination or strong sense of responsibility.\"}}\n",
    "\n",
    "Return only JSON array (no additional explanation):\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # 안전하게 중괄호 이스케이프\n",
    "            safe_prompt = prompt.replace('{', '{{').replace('}', '}}')\n",
    "            response = self.llm.invoke(safe_prompt)\n",
    "            # JSON 파싱\n",
    "            pairs = self._parse_json_response(response)\n",
    "            return pairs\n",
    "        except Exception as e:\n",
    "            print(f\"✗ 생성 중 오류: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _parse_json_response(self, response: str) -> List[Dict]:\n",
    "        \"\"\"응답에서 JSON 추출\"\"\"\n",
    "        try:\n",
    "            # 응답에서 JSON 배열 찾기\n",
    "            json_start = response.find('[')\n",
    "            json_end = response.rfind(']') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_str = response[json_start:json_end]\n",
    "                return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"✗ JSON 파싱 실패\")\n",
    "            print(response)\n",
    "            return []\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    def batch_generate(self, chunks: List[str], num_pairs_per_chunk: int = 2) -> List[Dict]:\n",
    "        \"\"\"여러 청크로부터 일괄 생성\"\"\"\n",
    "        all_pairs = []\n",
    "        \n",
    "        print(f\"\\n[자동 생성 시작] 총 {len(chunks)}개 청크 처리 중...\")\n",
    "        \n",
    "        # tqdm으로 진행바 표시\n",
    "        for chunk in tqdm(chunks, desc='Generating', unit='chunk'):\n",
    "            pairs = self.generate_qa_pairs(chunk, num_pairs_per_chunk)\n",
    "            all_pairs.extend(pairs)\n",
    "        \n",
    "        print(f\"✓ 총 {len(all_pairs)}개 쌍 생성 완료\\n\")\n",
    "        return all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9aa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. 품질 검증 및 중복 제거\n",
    "# ============================================================================\n",
    "\n",
    "class DataQualityChecker:\n",
    "    \"\"\"생성된 데이터의 품질 검증\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_pair(pair: Dict) -> bool:\n",
    "        \"\"\"단일 쌍 검증\"\"\"\n",
    "        if not isinstance(pair, dict):\n",
    "            return False\n",
    "        \n",
    "        if 'caption' not in pair or 'interpretation' not in pair:\n",
    "            return False\n",
    "        \n",
    "        caption = str(pair['caption']).strip()\n",
    "        interpretation = str(pair['interpretation']).strip()\n",
    "        \n",
    "        # 최소 길이 확인 캡션과 해석의 길이가 기준 미만인 경우 탈락\n",
    "        if len(caption) < 5 or len(interpretation) < 20:\n",
    "            return False\n",
    "        \n",
    "        # 반복 문자 확인\n",
    "        if DataQualityChecker._has_repetition(caption) or DataQualityChecker._has_repetition(interpretation):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def _has_repetition(text: str, threshold: float = 0.5) -> bool:\n",
    "        \"\"\"반복된 문자 검사\"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) < 3:\n",
    "            return False\n",
    "        \n",
    "        unique_ratio = len(set(words)) / len(words)#문장에 한번만 나타나는 단어의 비율이 낮은 경우 탈락\n",
    "        return unique_ratio < threshold\n",
    "    \n",
    "    @staticmethod\n",
    "    def remove_duplicates(pairs: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"중복 제거 (캡션 기준)\"\"\"\n",
    "        seen = set()\n",
    "        unique_pairs = []\n",
    "        \n",
    "        for pair in pairs:\n",
    "            caption = pair.get('caption', '').lower().strip()\n",
    "            if caption not in seen and DataQualityChecker.validate_pair(pair):\n",
    "                seen.add(caption)\n",
    "                unique_pairs.append(pair)#캡션이 동일한데 해석이 다른 경우 탈락 시킴\n",
    "        \n",
    "        return unique_pairs\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_pairs(pairs: List[Dict]) -> Tuple[List[Dict], int]:\n",
    "        \"\"\"품질 검증 및 필터링\"\"\"\n",
    "        valid_pairs = [p for p in pairs if DataQualityChecker.validate_pair(p)]\n",
    "        invalid_count = len(pairs) - len(valid_pairs)\n",
    "        \n",
    "        if invalid_count > 0:\n",
    "            print(f\"⚠️ {invalid_count}개 쌍 제외 (품질 미흡)\")\n",
    "        \n",
    "        return valid_pairs, invalid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a172021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. 데이터셋 저장\n",
    "# ============================================================================\n",
    "\n",
    "class DatasetSaver:\n",
    "    \"\"\"생성된 데이터셋을 다양한 형식으로 저장\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_csv(pairs: List[Dict], filename: str = \"htp_training_data.csv\"):\n",
    "        \"\"\"CSV 형식으로 저장\"\"\"\n",
    "        import csv\n",
    "        \n",
    "        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['C_ID', 'T_ID', 'Text', 'Completion'])\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for c_id, pair in enumerate(pairs):\n",
    "                writer.writerow({\n",
    "                    'C_ID': c_id,\n",
    "                    'T_ID': 0,\n",
    "                    'Text': f\"HTP 검사 이미지 캡션: {pair['caption']}\",\n",
    "                    'Completion': pair['interpretation']\n",
    "                })\n",
    "        \n",
    "        print(f\"✓ CSV 저장: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_jsonl(pairs: List[Dict], filename: str = \"htp_training_data.jsonl\"):\n",
    "        \"\"\"JSONL 형식으로 저장\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for c_id, pair in enumerate(pairs):\n",
    "                data = {\n",
    "                    'C_ID': c_id,\n",
    "                    'T_ID': 0,\n",
    "                    'Text': f\"HTP 검사 이미지 캡션: {pair['caption']}\",\n",
    "                    'Completion': pair['interpretation']\n",
    "                }\n",
    "                f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        print(f\"✓ JSONL 저장: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_alpaca_format(pairs: List[Dict], filename: str = \"htp_alpaca_format.json\"):\n",
    "        \"\"\"Alpaca 형식으로 저장\"\"\"\n",
    "        alpaca_data = []\n",
    "        \n",
    "        for pair in pairs:\n",
    "            alpaca_data.append({\n",
    "                \"instruction\": \"다음 HTP 검사 이미지 캡션을 심리학적으로 해석해주세요\",\n",
    "                \"input\": pair['caption'],\n",
    "                \"output\": pair['interpretation']\n",
    "            })\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(alpaca_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"✓ Alpaca 형식 저장: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_raw_json(pairs: List[Dict], filename: str = \"htp_raw_pairs.json\"):\n",
    "        \"\"\"원본 쌍을 JSON으로 저장\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(pairs, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"✓ 원본 쌍 저장: {filename}\")\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c49a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. 전체 파이프라인\n",
    "# ============================================================================\n",
    "\n",
    "class FullPipeline:\n",
    "    \"\"\"문서 입력부터 데이터셋 생성까지 완전한 파이프라인\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"mistral\", use_local: bool = True,language='kor'):\n",
    "        self.doc_processor = DocumentProcessor()\n",
    "        if language=='kor':\n",
    "            self.data_generator = CaptionDataGeneratorKor(model_name, use_local)\n",
    "        else:\n",
    "            self.data_generator=CaptionDataGeneratorEng(model_name,use_local)\n",
    "        self.quality_checker = DataQualityChecker()\n",
    "        self.saver = DatasetSaver()\n",
    "    \n",
    "    def run(self, \n",
    "            file_paths: List[str],\n",
    "            num_pairs_per_chunk: int = 2,\n",
    "            output_dir: str = \"./output\",\n",
    "            progress_callback: Optional[Callable[[str,str,Optional[Dict]], None]] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        전체 파이프라인 실행\n",
    "        \n",
    "        Parameters:\n",
    "        - file_paths: 입력 문서 경로 리스트\n",
    "        - num_pairs_per_chunk: 청크당 생성할 쌍의 수\n",
    "        - output_dir: 출력 디렉토리\n",
    "        - progress_callback: (stage, status, details) 형식의 콜백 함수\n",
    "        \n",
    "        Returns:\n",
    "        - 결과 정보 딕셔너리\n",
    "        \"\"\"\n",
    "        \n",
    "        def _report(stage: str, status: str, details: Optional[Dict] = None):\n",
    "            if progress_callback:\n",
    "                try:\n",
    "                    progress_callback(stage, status, details)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] progress_callback raised an exception: {e}\")\n",
    "\n",
    "        # 디렉토리 생성\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"HTP 캡션-해석 쌍 자동 생성 파이프라인\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        # 1단계: 문서 로드\n",
    "        _report('load', 'start', {'file_paths': file_paths})\n",
    "        print(\"[1단계] 문서 로드\")\n",
    "        print(\"-\" * 80)\n",
    "        documents = self.doc_processor.load_documents(file_paths)\n",
    "        print(f\"✓ {len(documents)}개 문서 로드됨\\n\")\n",
    "        if not documents:\n",
    "            _report('load', 'failure', {'file_paths': file_paths})\n",
    "            raise RuntimeError(f\"[오류] 문서 로드 실패: 제공된 경로에서 문서를 불러오지 못했습니다. file_paths={file_paths}\")\n",
    "        _report('load', 'success', {'documents': len(documents)})\n",
    "        \n",
    "        # 2단계: 문서 청킹\n",
    "        _report('chunk', 'start', {'documents': len(documents)})\n",
    "        print(\"[2단계] 문서 청킹\")\n",
    "        print(\"-\" * 80)\n",
    "        chunks = self.doc_processor.preprocess_documents(documents)\n",
    "        print(f\"✓ 청킹 완료\\n\")\n",
    "        if not chunks:\n",
    "            _report('chunk', 'failure', {'documents': len(documents)})\n",
    "            raise RuntimeError(\"[오류] 청킹 실패: 문서로부터 유의미한 청크를 생성하지 못했습니다. 문서 내용 혹은 전처리 설정(chunk_size/chunk_overlap)을 확인하세요.\")\n",
    "        _report('chunk', 'success', {'chunks': len(chunks)})\n",
    "        \n",
    "        # 3단계: 데이터 생성\n",
    "        _report('generate', 'start', {'chunks': len(chunks)})\n",
    "        print(\"[3단계] LLM 기반 데이터 생성\")\n",
    "        print(\"-\" * 80)\n",
    "        raw_pairs = self.data_generator.batch_generate(chunks, num_pairs_per_chunk)\n",
    "        if not raw_pairs:\n",
    "            _report('generate', 'failure', {'chunks': len(chunks)})\n",
    "            raise RuntimeError(\"[오류] 데이터 생성 실패: LLM이 유효한 캡션-해석 쌍을 생성하지 못했습니다. LLM 설정 및 입력 청크를 확인하세요.\")\n",
    "        _report('generate', 'success', {'raw_pairs': len(raw_pairs)})\n",
    "        \n",
    "        # 4단계: 품질 검증\n",
    "        _report('validate', 'start', {'raw_pairs': len(raw_pairs)})\n",
    "        print(\"[4단계] 품질 검증\")\n",
    "        print(\"-\" * 80)\n",
    "        valid_pairs, invalid_count = self.quality_checker.filter_pairs(raw_pairs)\n",
    "        print(f\"✓ 유효한 쌍: {len(valid_pairs)}개\\n\")\n",
    "        if len(valid_pairs) == 0:\n",
    "            _report('validate', 'failure', {'raw_pairs': len(raw_pairs), 'invalid_count': invalid_count})\n",
    "            raise RuntimeError(\"[오류] 품질 검증 결과 유효한 쌍이 없습니다. 필터 기준(DataQualityChecker)을 완화하거나 LLM 출력을 확인하세요.\")\n",
    "        _report('validate', 'success', {'valid_pairs': len(valid_pairs), 'invalid_count': invalid_count})\n",
    "        \n",
    "        # 5단계: 중복 제거\n",
    "        _report('dedupe', 'start', {'valid_pairs': len(valid_pairs)})\n",
    "        print(\"[5단계] 중복 제거\")\n",
    "        print(\"-\" * 80)\n",
    "        unique_pairs = self.quality_checker.remove_duplicates(valid_pairs)\n",
    "        duplicate_count = len(valid_pairs) - len(unique_pairs)\n",
    "        if duplicate_count > 0:\n",
    "            print(f\"⚠️ {duplicate_count}개 중복 제거\")\n",
    "        print(f\"✓ 최종 쌍: {len(unique_pairs)}개\\n\")\n",
    "        if len(unique_pairs) == 0:\n",
    "            _report('dedupe', 'failure', {'valid_pairs': len(valid_pairs)})\n",
    "            raise RuntimeError(\"[오류] 중복 제거 후 유효한 쌍이 없습니다. 생성된 쌍을 확인하세요.\")\n",
    "        _report('dedupe', 'success', {'unique_pairs': len(unique_pairs), 'duplicate_count': duplicate_count})\n",
    "        \n",
    "        # 6단계: 데이터 저장\n",
    "        _report('save', 'start', {'unique_pairs': len(unique_pairs), 'output_dir': output_dir})\n",
    "        print(\"[6단계] 데이터 저장\")\n",
    "        print(\"-\" * 80)\n",
    "        try:\n",
    "            csv_path = self.saver.save_csv(unique_pairs, f\"{output_dir}/htp_training_data.csv\")\n",
    "            jsonl_path = self.saver.save_jsonl(unique_pairs, f\"{output_dir}/htp_training_data.jsonl\")\n",
    "            alpaca_path = self.saver.save_alpaca_format(unique_pairs, f\"{output_dir}/htp_alpaca_format.json\")\n",
    "            raw_path = self.saver.save_raw_json(unique_pairs, f\"{output_dir}/htp_raw_pairs.json\")\n",
    "        except Exception as e:\n",
    "            _report('save', 'failure', {'error': str(e)})\n",
    "            raise RuntimeError(f\"[오류] 데이터 저장 실패: {e}\")\n",
    "\n",
    "        # 저장 확인\n",
    "        missing = []\n",
    "        for p in (csv_path, jsonl_path, alpaca_path, raw_path):\n",
    "            try:\n",
    "                if not Path(p).exists():\n",
    "                    missing.append(p)\n",
    "            except Exception:\n",
    "                missing.append(p)\n",
    "        if missing:\n",
    "            _report('save', 'failure', {'missing': missing})\n",
    "            raise RuntimeError(f\"[오류] 데이터 저장은 완료되었으나 다음 파일을 찾을 수 없습니다: {missing}\")\n",
    "        _report('save', 'success', {'paths': [csv_path, jsonl_path, alpaca_path, raw_path]})\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"✓ 완료!\")\n",
    "        print(\"=\" * 80)\n",
    "        _report('complete', 'success', {'unique_pairs': len(unique_pairs)})\n",
    "        \n",
    "        return {\n",
    "            'total_documents': len(documents),\n",
    "            'total_chunks': len(chunks),\n",
    "            'raw_pairs': len(raw_pairs),\n",
    "            'valid_pairs': len(valid_pairs),\n",
    "            'unique_pairs': len(unique_pairs),\n",
    "            'output_dir': output_dir\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c40727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTP_DATA\\\\000002419228_20251111110826.pdf',\n",
       " 'HTP_DATA\\\\200000215097_20251111110528.pdf',\n",
       " 'HTP_DATA\\\\buck1948.pdf',\n",
       " 'HTP_DATA\\\\finetunning_data.txt',\n",
       " 'HTP_DATA\\\\fpsyt-13-1041770.pdf',\n",
       " 'HTP_DATA\\\\HTP_Drawing_Test.txt',\n",
       " 'HTP_DATA\\\\HTP_Test_Interpertation_kor.txt',\n",
       " 'HTP_DATA\\\\ilide.info-the-h-t-p-technique-a-qualitative-and-quantitative-scoring-john-n-buck-journal-o-pr_090eb8a4e23407a52ca8c7d1ace3827a.pdf',\n",
       " 'HTP_DATA\\\\KCI_FI003005286.pdf',\n",
       " 'HTP_DATA\\\\KCI_FI003198543.pdf',\n",
       " 'HTP_DATA\\\\munevveriremhatipoglu.pdf',\n",
       " 'HTP_DATA\\\\sampe_interpretation_of_house_tree_person_test.txt',\n",
       " 'HTP_DATA\\\\브런치 집_나무_사람 해석 수정본 (1).txt',\n",
       " 'HTP_DATA\\\\표 형태의 논문 해석.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 사용할 문서 경로\n",
    "folder_path = \"HTP_DATA\"\n",
    "file_paths=[os.path.join(folder_path, f) for f in os.listdir(folder_path)]\n",
    "    \n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835ff5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama 모델 로드: gemma3:latest\n",
      "================================================================================\n",
      "HTP 캡션-해석 쌍 자동 생성 파이프라인\n",
      "================================================================================\n",
      "\n",
      "[1단계] 문서 로드\n",
      "--------------------------------------------------------------------------------\n",
      "Error loading HTP_DATA\\finetunning_data.txt: 'utf-8' codec can't decode byte 0xc1 in position 14: invalid start byte\n",
      "Error loading HTP_DATA\\finetunning_data.txt: 'utf-8' codec can't decode byte 0xc1 in position 14: invalid start byte\n",
      "✓ 13개 문서 로드됨\n",
      "\n",
      "[2단계] 문서 청킹\n",
      "--------------------------------------------------------------------------------\n",
      "총 1354개 청크 생성\n",
      "✓ 청킹 완료\n",
      "\n",
      "[3단계] LLM 기반 데이터 생성\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[자동 생성 시작] 총 1354개 청크 처리 중...\n",
      "✓ 13개 문서 로드됨\n",
      "\n",
      "[2단계] 문서 청킹\n",
      "--------------------------------------------------------------------------------\n",
      "총 1354개 청크 생성\n",
      "✓ 청킹 완료\n",
      "\n",
      "[3단계] LLM 기반 데이터 생성\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[자동 생성 시작] 총 1354개 청크 처리 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717c4a2820fd442eb80b4ad762cb19b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/1354 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"HTP 검사 결과표의 Net Weighted Score 계산\",\n",
      "    \"interpretation\": \"Net Weighted Score는 ‘good’ score와 ‘flaw’ score의 차이로 계산되며, 이는 대상자의 검사 결과가 ‘good’ score에 대한 ‘flaw’ score의 영향력을 얼마나 상쇄했는지를 나타냅니다.  Net Weighted Score의 값은 대상자의 검사 결과가 ‘good’ score에 대한 ‘flaw’ score의 영향을 얼마나 상쇄했는지를 보여주므로,  정량적인 비교를 위해 중요합니다.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"Means Table 활용 및 층위별 평균 추정\",\n",
      "    \"interpretation\": \"Means Table는 HTP 검사 결과를 다양한 지능 및 요인 수준별 평균 값과 비교하여 대상자의 총 raw score를 추정하는 데 사용됩니다.  \"+\" 기호는 평균보다 약간 높은 값을, \"-\" 기호는 평균보다 약간 낮은 값을 나타내므로,  각 지능 및 요인 수준에 대한 보다 정확한 평가를 제공합니다.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "✓ 총 2706개 쌍 생성 완료\n",
      "\n",
      "[4단계] 품질 검증\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 2개 쌍 제외 (품질 미흡)\n",
      "✓ 유효한 쌍: 2704개\n",
      "\n",
      "[5단계] 중복 제거\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 23개 중복 제거\n",
      "✓ 최종 쌍: 2681개\n",
      "\n",
      "[6단계] 데이터 저장\n",
      "--------------------------------------------------------------------------------\n",
      "✓ CSV 저장: ./htp_output1_kor/htp_training_data.csv\n",
      "✓ JSONL 저장: ./htp_output1_kor/htp_training_data.jsonl\n",
      "✓ Alpaca 형식 저장: ./htp_output1_kor/htp_alpaca_format.json\n",
      "✓ 원본 쌍 저장: ./htp_output1_kor/htp_raw_pairs.json\n",
      "\n",
      "================================================================================\n",
      "✓ 완료!\n",
      "================================================================================\n",
      "\n",
      "[최종 통계]\n",
      "total_documents: 13\n",
      "total_chunks: 1354\n",
      "raw_pairs: 2706\n",
      "valid_pairs: 2704\n",
      "unique_pairs: 2681\n",
      "output_dir: ./htp_output1_kor\n",
      "✓ 총 2706개 쌍 생성 완료\n",
      "\n",
      "[4단계] 품질 검증\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 2개 쌍 제외 (품질 미흡)\n",
      "✓ 유효한 쌍: 2704개\n",
      "\n",
      "[5단계] 중복 제거\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 23개 중복 제거\n",
      "✓ 최종 쌍: 2681개\n",
      "\n",
      "[6단계] 데이터 저장\n",
      "--------------------------------------------------------------------------------\n",
      "✓ CSV 저장: ./htp_output1_kor/htp_training_data.csv\n",
      "✓ JSONL 저장: ./htp_output1_kor/htp_training_data.jsonl\n",
      "✓ Alpaca 형식 저장: ./htp_output1_kor/htp_alpaca_format.json\n",
      "✓ 원본 쌍 저장: ./htp_output1_kor/htp_raw_pairs.json\n",
      "\n",
      "================================================================================\n",
      "✓ 완료!\n",
      "================================================================================\n",
      "\n",
      "[최종 통계]\n",
      "total_documents: 13\n",
      "total_chunks: 1354\n",
      "raw_pairs: 2706\n",
      "valid_pairs: 2704\n",
      "unique_pairs: 2681\n",
      "output_dir: ./htp_output1_kor\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 실행\n",
    "pipeline = FullPipeline(model_name=\"gemma3:latest\", use_local=True,language='kor')\n",
    "\n",
    "results = pipeline.run(\n",
    "    file_paths=file_paths,\n",
    "    num_pairs_per_chunk=2,\n",
    "    output_dir=\"./htp_output1_kor\"\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n[최종 통계]\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98933ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama 모델 로드: gemma3:latest\n",
      "================================================================================\n",
      "HTP 캡션-해석 쌍 자동 생성 파이프라인\n",
      "================================================================================\n",
      "\n",
      "[1단계] 문서 로드\n",
      "--------------------------------------------------------------------------------\n",
      "Error loading HTP_DATA\\finetunning_data.txt: 'utf-8' codec can't decode byte 0xc1 in position 14: invalid start byte\n",
      "Error loading HTP_DATA\\finetunning_data.txt: 'utf-8' codec can't decode byte 0xc1 in position 14: invalid start byte\n",
      "✓ 13개 문서 로드됨\n",
      "\n",
      "[2단계] 문서 청킹\n",
      "--------------------------------------------------------------------------------\n",
      "총 1354개 청크 생성\n",
      "✓ 청킹 완료\n",
      "\n",
      "[3단계] LLM 기반 데이터 생성\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[자동 생성 시작] 총 1354개 청크 처리 중...\n",
      "✓ 13개 문서 로드됨\n",
      "\n",
      "[2단계] 문서 청킹\n",
      "--------------------------------------------------------------------------------\n",
      "총 1354개 청크 생성\n",
      "✓ 청킹 완료\n",
      "\n",
      "[3단계] LLM 기반 데이터 생성\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[자동 생성 시작] 총 1354개 청크 처리 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b45b714a9c4ff481741df80d477ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/1354 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The tree's branches are numerous and the house is expansive.\",\n",
      "    \"interpretation\": \"This HTP suggests a potential for over-extroversion, a desire for numerous social connections, and possibly a feeling of being overwhelmed by possibilities, potentially indicating heightened anxiety or a need for control within social situations.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The house is small, and the tree’s branches are sparse.\",\n",
      "    \"interpretation\": \"The interpretation suggests a diminished sense of self-efficacy, a feeling of vulnerability, and possibly a history of trauma or neglect, particularly in childhood. The lack of robust support (the sparse branches) coupled with the small house indicates a possible struggle with self-esteem and a heightened fear of external threats or abandonment.”}\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The tree has many branches and leaves.\",\n",
      "    \"interpretation\": \"The excessive number of branches and leaves in the tree suggests a highly active and perhaps overwhelmed emotional state, potentially indicating difficulty regulating emotions and a heightened sensitivity to external stimuli, as evidenced by the document’s description of ‘anxiety and defensive behavior.’”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The person is depicted with a small, delicate house.\",\n",
      "    \"interpretation\": \"The small house size, combined with the thin lines and layering in the drawing, suggests a fragile sense of self-esteem and a potential for withdrawal or avoidance. The document’s interpretation of ‘self-esteem atrophy’ aligns with this, indicating a difficulty in asserting oneself and a tendency to seek reassurance from others, potentially stemming from a history of traumatic experiences reflected in the ‘tree’s fissures’.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The tree has many branches and leaves.\",\n",
      "    \"interpretation\": \"The excessive number of branches and leaves in the tree suggests a highly active and perhaps overwhelmed emotional state, potentially indicating difficulty regulating emotions and a heightened sensitivity to external stimuli, as evidenced by the document’s description of ‘anxiety and defensive behavior.’”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The person is depicted with a small, delicate house.\",\n",
      "    \"interpretation\": \"The small house size, combined with the thin lines and layering in the drawing, suggests a fragile sense of self-esteem and a potential for withdrawal or avoidance. The document’s interpretation of ‘self-esteem atrophy’ aligns with this, indicating a difficulty in asserting oneself and a tendency to seek reassurance from others, potentially stemming from a history of traumatic experiences reflected in the ‘tree’s fissures’.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"A large house with a prominent figure and a bright sun.\",\n",
      "    \"interpretation\": \"This drawing suggests a child experiencing significant internal conflict and a need for stability. The oversized house and figure, combined with the intensely focused sun, could indicate a struggle with self-esteem, a desire for control, and potentially overwhelming anxieties or a need for external validation.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The child is depicted dancing with a detailed focus on the clothing.\",\n",
      "    \"interpretation\": \"The child’s intense focus on the clothing and the act of dancing suggests a desire for self-expression and perhaps a feeling of being constrained or unable to fully express their true self. The depiction of the 12-year-old self, combined with the impulsive and potentially chaotic depiction of the figure, could point to a need for greater self-acceptance and a reduced sense of internal conflict.”}\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"A large house with a prominent figure and a bright sun.\",\n",
      "    \"interpretation\": \"This drawing suggests a child experiencing significant internal conflict and a need for stability. The oversized house and figure, combined with the intensely focused sun, could indicate a struggle with self-esteem, a desire for control, and potentially overwhelming anxieties or a need for external validation.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The child is depicted dancing with a detailed focus on the clothing.\",\n",
      "    \"interpretation\": \"The child’s intense focus on the clothing and the act of dancing suggests a desire for self-expression and perhaps a feeling of being constrained or unable to fully express their true self. The depiction of the 12-year-old self, combined with the impulsive and potentially chaotic depiction of the figure, could point to a need for greater self-acceptance and a reduced sense of internal conflict.”}\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The child draws a figure with a long neck and missing hands and feet.\",\n",
      "    \"interpretation\": \"This HTP drawing suggests a high level of social anxiety and a detached self-image. The elongated neck and absent limbs could represent a feeling of being overwhelmed by external demands, a difficulty in asserting oneself, and a reluctance to engage actively with the world.  The lack of detail, particularly the missing hands and feet, further indicates a possible struggle with self-efficacy and a fear of vulnerability in interpersonal relationships.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The house in the drawing is small and the person is positioned at the top.\",\n",
      "    \"interpretation\": \"The depiction of the individual at the top of the house, coupled with a small house size, likely reflects a preoccupation with self-esteem and a tendency towards self-focused thinking. This suggests a potentially fragile sense of self-worth, possibly stemming from feelings of inadequacy or a need for external validation. The lack of detail in the figure and the surrounding environment could indicate a detachment from reality and an avoidance of practical concerns, reinforcing the impression of a self-centered and potentially insecure individual.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The child draws a figure with a long neck and missing hands and feet.\",\n",
      "    \"interpretation\": \"This HTP drawing suggests a high level of social anxiety and a detached self-image. The elongated neck and absent limbs could represent a feeling of being overwhelmed by external demands, a difficulty in asserting oneself, and a reluctance to engage actively with the world.  The lack of detail, particularly the missing hands and feet, further indicates a possible struggle with self-efficacy and a fear of vulnerability in interpersonal relationships.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The house in the drawing is small and the person is positioned at the top.\",\n",
      "    \"interpretation\": \"The depiction of the individual at the top of the house, coupled with a small house size, likely reflects a preoccupation with self-esteem and a tendency towards self-focused thinking. This suggests a potentially fragile sense of self-worth, possibly stemming from feelings of inadequacy or a need for external validation. The lack of detail in the figure and the surrounding environment could indicate a detachment from reality and an avoidance of practical concerns, reinforcing the impression of a self-centered and potentially insecure individual.\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"A large, imposing house dominates the drawing.\",\n",
      "    \"interpretation\": \"This suggests a strong, potentially rigid, sense of self-structure and control in the subject's personality. The size of the house indicates a need for order and perhaps a difficulty in accepting ambiguity or change.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"A person is depicted with a translucent wall surrounding the house.\",\n",
      "    \"interpretation\": \"The wall transparency indicates a significant lack of critical judgment and a diminished ability to engage with the situation fully. This suggests underlying emotional or organic disturbance impacting the subject’s capacity for rational thought and decision-making.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"A large, imposing house dominates the drawing.\",\n",
      "    \"interpretation\": \"This suggests a strong, potentially rigid, sense of self-structure and control in the subject's personality. The size of the house indicates a need for order and perhaps a difficulty in accepting ambiguity or change.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"A person is depicted with a translucent wall surrounding the house.\",\n",
      "    \"interpretation\": \"The wall transparency indicates a significant lack of critical judgment and a diminished ability to engage with the situation fully. This suggests underlying emotional or organic disturbance impacting the subject’s capacity for rational thought and decision-making.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The person is depicted as actively building the house.\",\n",
      "    \"interpretation\": \"This suggests a proactive and engaged individual, potentially indicating a willingness to take initiative and a positive attitude towards problem-solving, aligning with a 'reasonably willing acceptance' as described in the document.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is shown with gnarled branches and a decaying appearance.\",\n",
      "    \"interpretation\": \"This could signify resistance or a pessimistic outlook, potentially interpreted as ‘defeatism and abandonism.’ The document highlights that marked deviation from willingness is ‘suspicious,’ suggesting underlying anxieties or a lack of confidence in the task’s feasibility.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The person is depicted as actively building the house.\",\n",
      "    \"interpretation\": \"This suggests a proactive and engaged individual, potentially indicating a willingness to take initiative and a positive attitude towards problem-solving, aligning with a 'reasonably willing acceptance' as described in the document.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is shown with gnarled branches and a decaying appearance.\",\n",
      "    \"interpretation\": \"This could signify resistance or a pessimistic outlook, potentially interpreted as ‘defeatism and abandonism.’ The document highlights that marked deviation from willingness is ‘suspicious,’ suggesting underlying anxieties or a lack of confidence in the task’s feasibility.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The house is disproportionately large.\",\n",
      "    \"interpretation\": \"This indicates a potential overemphasis on material possessions, security, or a need for control within the subject's psychological landscape. The subject’s preoccupation with the expansive ‘home’ suggests an attempt to create a stable and satisfying environment, possibly stemming from underlying anxieties or a desire to shield herself from perceived threats.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is depicted as being cut at the top.\",\n",
      "    \"interpretation\": \"The paper-chopped tree signifies a disrupted future orientation and a tendency to seek gratification through fantasy rather than realistic planning. This suggests a subject who may be avoiding difficult realities and relying on idealized scenarios to manage feelings of insecurity or dissatisfaction, potentially impacting her ability to cope with present challenges.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The house is disproportionately large.\",\n",
      "    \"interpretation\": \"This indicates a potential overemphasis on material possessions, security, or a need for control within the subject's psychological landscape. The subject’s preoccupation with the expansive ‘home’ suggests an attempt to create a stable and satisfying environment, possibly stemming from underlying anxieties or a desire to shield herself from perceived threats.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is depicted as being cut at the top.\",\n",
      "    \"interpretation\": \"The paper-chopped tree signifies a disrupted future orientation and a tendency to seek gratification through fantasy rather than realistic planning. This suggests a subject who may be avoiding difficult realities and relying on idealized scenarios to manage feelings of insecurity or dissatisfaction, potentially impacting her ability to cope with present challenges.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The person is ambiguous, stating ‘Now I don’t know whether to make a man or a woman’\",\n",
      "    \"interpretation\": \"This indicates a significant confusion regarding gender identity, potentially stemming from castration anxiety and a lack of clear role definition within the subject’s life. The inability to definitively draw a man or woman reflects a core conflict in their sense of self.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is described as ‘good or rotten’\",\n",
      "    \"interpretation\": \"The subject’s response regarding the tree’s health suggests a feeling of internal dis-ease and a lack of stability. The inability to determine its state reflects a difficulty in assessing their own well-being and a fear of self-destruction or vulnerability.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The person is ambiguous, stating ‘Now I don’t know whether to make a man or a woman’\",\n",
      "    \"interpretation\": \"This indicates a significant confusion regarding gender identity, potentially stemming from castration anxiety and a lack of clear role definition within the subject’s life. The inability to definitively draw a man or woman reflects a core conflict in their sense of self.\"\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The tree is described as ‘good or rotten’\",\n",
      "    \"interpretation\": \"The subject’s response regarding the tree’s health suggests a feeling of internal dis-ease and a lack of stability. The inability to determine its state reflects a difficulty in assessing their own well-being and a fear of self-destruction or vulnerability.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The child drew a house with a chimney.\",\n",
      "    \"interpretation\": \"This indicates a potential for heightened anxiety or emotional reactivity, as evidenced by the increased scores in ‘externalization’, ‘other problems’, and ‘somatic symptoms’ within the K-CBCL assessment. The parent’s assessment of ‘externalization’ is also elevated, suggesting a difficulty in regulating emotions and relating to others.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The child’s house has no fence.\",\n",
      "    \"interpretation\": \"The absence of a fence in the house drawing correlates with higher scores in ‘punishment’ and ‘inconsistency’ within the PAT assessment, potentially reflecting a disrupted or insecure attachment style and difficulties in establishing boundaries. This suggests possible behavioral issues and difficulties in forming stable relationships.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The child drew a house with a chimney.\",\n",
      "    \"interpretation\": \"This indicates a potential for heightened anxiety or emotional reactivity, as evidenced by the increased scores in ‘externalization’, ‘other problems’, and ‘somatic symptoms’ within the K-CBCL assessment. The parent’s assessment of ‘externalization’ is also elevated, suggesting a difficulty in regulating emotions and relating to others.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The child’s house has no fence.\",\n",
      "    \"interpretation\": \"The absence of a fence in the house drawing correlates with higher scores in ‘punishment’ and ‘inconsistency’ within the PAT assessment, potentially reflecting a disrupted or insecure attachment style and difficulties in establishing boundaries. This suggests possible behavioral issues and difficulties in forming stable relationships.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The house is significantly larger than the person.\",\n",
      "    \"interpretation\": \"This indicates a potential overemphasis on structure, rules, or external authority figures in the subject’s life. It may also reflect a need for control or a feeling of being overwhelmed by responsibilities.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The person is drawn in a peripheral position with little overlap with the tree.\",\n",
      "    \"interpretation\": \"This suggests a withdrawn or isolated individual who may struggle with interpersonal relationships. The lack of interaction with the tree (representing stability and grounding) indicates a potential difficulty in establishing secure connections or a desire to remain emotionally distant.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✗ JSON 파싱 실패\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"caption\": \"The house is significantly larger than the person.\",\n",
      "    \"interpretation\": \"This indicates a potential overemphasis on structure, rules, or external authority figures in the subject’s life. It may also reflect a need for control or a feeling of being overwhelmed by responsibilities.”\n",
      "  },\n",
      "  {\n",
      "    \"caption\": \"The person is drawn in a peripheral position with little overlap with the tree.\",\n",
      "    \"interpretation\": \"This suggests a withdrawn or isolated individual who may struggle with interpersonal relationships. The lack of interaction with the tree (representing stability and grounding) indicates a potential difficulty in establishing secure connections or a desire to remain emotionally distant.”\n",
      "  }\n",
      "]\n",
      "```\n",
      "✓ 총 2688개 쌍 생성 완료\n",
      "\n",
      "[4단계] 품질 검증\n",
      "--------------------------------------------------------------------------------\n",
      "✓ 유효한 쌍: 2688개\n",
      "\n",
      "[5단계] 중복 제거\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 431개 중복 제거\n",
      "✓ 최종 쌍: 2257개\n",
      "\n",
      "[6단계] 데이터 저장\n",
      "--------------------------------------------------------------------------------\n",
      "✓ CSV 저장: ./htp_output1_eng/htp_training_data.csv\n",
      "✓ JSONL 저장: ./htp_output1_eng/htp_training_data.jsonl\n",
      "✓ Alpaca 형식 저장: ./htp_output1_eng/htp_alpaca_format.json\n",
      "✓ 원본 쌍 저장: ./htp_output1_eng/htp_raw_pairs.json\n",
      "\n",
      "================================================================================\n",
      "✓ 완료!\n",
      "================================================================================\n",
      "\n",
      "[최종 통계]\n",
      "total_documents: 13\n",
      "total_chunks: 1354\n",
      "raw_pairs: 2688\n",
      "valid_pairs: 2688\n",
      "unique_pairs: 2257\n",
      "output_dir: ./htp_output1_eng\n",
      "✓ 총 2688개 쌍 생성 완료\n",
      "\n",
      "[4단계] 품질 검증\n",
      "--------------------------------------------------------------------------------\n",
      "✓ 유효한 쌍: 2688개\n",
      "\n",
      "[5단계] 중복 제거\n",
      "--------------------------------------------------------------------------------\n",
      "⚠️ 431개 중복 제거\n",
      "✓ 최종 쌍: 2257개\n",
      "\n",
      "[6단계] 데이터 저장\n",
      "--------------------------------------------------------------------------------\n",
      "✓ CSV 저장: ./htp_output1_eng/htp_training_data.csv\n",
      "✓ JSONL 저장: ./htp_output1_eng/htp_training_data.jsonl\n",
      "✓ Alpaca 형식 저장: ./htp_output1_eng/htp_alpaca_format.json\n",
      "✓ 원본 쌍 저장: ./htp_output1_eng/htp_raw_pairs.json\n",
      "\n",
      "================================================================================\n",
      "✓ 완료!\n",
      "================================================================================\n",
      "\n",
      "[최종 통계]\n",
      "total_documents: 13\n",
      "total_chunks: 1354\n",
      "raw_pairs: 2688\n",
      "valid_pairs: 2688\n",
      "unique_pairs: 2257\n",
      "output_dir: ./htp_output1_eng\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 실행\n",
    "pipeline = FullPipeline(model_name=\"gemma3:latest\", use_local=True,language='eng')\n",
    "\n",
    "results = pipeline.run(\n",
    "    file_paths=file_paths,\n",
    "    num_pairs_per_chunk=2,\n",
    "    output_dir=\"./htp_output1_eng\"\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n[최종 통계]\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3975e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HTP 데이터 처리 스크립트\n",
    "- Instruction 영어 변환\n",
    "- Category 자동 추출\n",
    "- 데이터 검증 및 통계\n",
    "- 여러 형식 저장\n",
    "\n",
    "사용법:\n",
    "    python htp_processor.py --input raw_data.json --output processed/\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class HTPDataProcessor:\n",
    "    \"\"\"\n",
    "    HTP 데이터 처리 클래스\n",
    "    - 대규모 데이터 처리 지원\n",
    "    - 데이터 검증\n",
    "    - 여러 출력 포맷 지원\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, custom_categories: Optional[Dict[str, str]] = None):\n",
    "        \"\"\"\n",
    "        초기화\n",
    "        \n",
    "        Args:\n",
    "            custom_categories: 커스텀 카테고리 추가 가능\n",
    "        \"\"\"\n",
    "        self.categories = {\n",
    "            \"tree\": r\"\\btree\\b\",\n",
    "            \"person\": r\"\\bperson\\b\",\n",
    "            \"house\": r\"\\bhouse\\b\"\n",
    "        }\n",
    "        \n",
    "        if custom_categories:\n",
    "            self.categories.update(custom_categories)\n",
    "        \n",
    "        self.english_instruction = \"Please provide a psychological interpretation of the following HTP test image caption\"\n",
    "    \n",
    "    def extract_categories(self, text: str) -> str:\n",
    "        \"\"\"input 텍스트에서 category 추출\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        found_categories = []\n",
    "        \n",
    "        for category, pattern in self.categories.items():\n",
    "            if re.search(pattern, text_lower):\n",
    "                found_categories.append(category)\n",
    "        \n",
    "        return \", \".join(found_categories) if found_categories else \"other\"\n",
    "    \n",
    "    def validate_item(self, item: Dict) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        데이터 아이템 유효성 검증\n",
    "        \n",
    "        Returns:\n",
    "            (유효 여부, 에러 메시지)\n",
    "        \"\"\"\n",
    "        required_fields = [\"instruction\", \"input\", \"output\"]\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if field not in item:\n",
    "                return False, f\"필수 필드 '{field}' 누락\"\n",
    "            if not isinstance(item[field], str) or not item[field].strip():\n",
    "                return False, f\"필드 '{field}'가 비어있음\"\n",
    "        \n",
    "        return True, \"OK\"\n",
    "    \n",
    "    def process_single_item(self, item: Dict) -> Optional[Dict]:\n",
    "        \"\"\"단일 데이터 아이템 처리 및 검증\"\"\"\n",
    "        is_valid, error_msg = self.validate_item(item)\n",
    "        if not is_valid:\n",
    "            return None\n",
    "        \n",
    "        new_item = item.copy()\n",
    "        new_item[\"instruction\"] = self.english_instruction\n",
    "        new_item[\"category\"] = self.extract_categories(item[\"input\"])\n",
    "        return new_item\n",
    "    \n",
    "    def process_data(self, data_list: List[Dict], verbose: bool = True) -> Tuple[List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        전체 데이터 리스트 처리\n",
    "        \n",
    "        Returns:\n",
    "            (처리된 데이터, 실패한 데이터)\n",
    "        \"\"\"\n",
    "        processed = []\n",
    "        failed = []\n",
    "        \n",
    "        for i, item in enumerate(data_list):\n",
    "            if verbose:\n",
    "                print(f\"처리 중: {i+1}/{len(data_list)}\", end='\\r')\n",
    "            \n",
    "            result = self.process_single_item(item)\n",
    "            if result:\n",
    "                processed.append(result)\n",
    "            else:\n",
    "                failed.append(item)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"✓ {len(processed)}/{len(data_list)} 처리 완료\" + \" \" * 20)\n",
    "        \n",
    "        return processed, failed\n",
    "    \n",
    "    def save_to_json(self, data: List[Dict], filename: str):\n",
    "        \"\"\"JSON 형식으로 저장\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✓ JSON 저장: {filename}\")\n",
    "    \n",
    "    def save_to_jsonl(self, data: List[Dict], filename: str):\n",
    "        \"\"\"JSONL 형식으로 저장 (Hugging Face 학습 포맷)\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        print(f\"✓ JSONL 저장: {filename}\")\n",
    "    \n",
    "    def generate_statistics(self, data: List[Dict]) -> Dict:\n",
    "        \"\"\"데이터 통계 생성\"\"\"\n",
    "        categories = [item.get(\"category\", \"other\") for item in data]\n",
    "        all_cats = []\n",
    "        for cat_str in categories:\n",
    "            all_cats.extend([c.strip() for c in cat_str.split(\",\")])\n",
    "        \n",
    "        return {\n",
    "            \"total_samples\": len(data),\n",
    "            \"category_distribution\": dict(Counter(all_cats)),\n",
    "            \"avg_input_length\": sum(len(item[\"input\"].split()) for item in data) / len(data) if data else 0,\n",
    "            \"avg_output_length\": sum(len(item[\"output\"].split()) for item in data) / len(data) if data else 0,\n",
    "            \"min_input_length\": min(len(item[\"input\"].split()) for item in data) if data else 0,\n",
    "            \"max_input_length\": max(len(item[\"input\"].split()) for item in data) if data else 0,\n",
    "        }\n",
    "    \n",
    "    def generate_report(self, data: List[Dict], filename: str = \"processing_report.txt\"):\n",
    "        \"\"\"처리 결과 리포트 생성\"\"\"\n",
    "        stats = self.generate_statistics(data)\n",
    "        \n",
    "        report = f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════╗\n",
    "║           HTP 데이터 처리 리포트                              ║\n",
    "╚══════════════════════════════════════════════════════════════╝\n",
    "\n",
    "📊 기본 통계:\n",
    "  - 총 샘플 수: {stats['total_samples']}\n",
    "  - Input 평균 길이: {stats['avg_input_length']:.1f} 단어\n",
    "  - Output 평균 길이: {stats['avg_output_length']:.1f} 단어\n",
    "  - Input 최소/최대 길이: {stats['min_input_length']} / {stats['max_input_length']} 단어\n",
    "\n",
    "📈 카테고리 분포:\n",
    "\"\"\"\n",
    "        for cat, count in sorted(stats['category_distribution'].items(), key=lambda x: x[1], reverse=True):\n",
    "            percentage = (count / stats['total_samples']) * 100 if stats['total_samples'] > 0 else 0\n",
    "            bar = \"█\" * int(percentage / 5) + \"░\" * (20 - int(percentage / 5))\n",
    "            report += f\"  - {cat:15s}: {count:4d} ({percentage:5.1f}%) {bar}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "✅ 처리 완료!\n",
    "   - Instruction 변환: 한국어 → 영어\n",
    "   - Category 추출: input 텍스트 기반\n",
    "   - 데이터 검증: 완료\n",
    "\n",
    "처리 시간: {stats['total_samples']} 샘플\n",
    "\"\"\"\n",
    "        \n",
    "        print(report)\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        print(f\"📄 리포트 저장: {filename}\\n\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "220500c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📝 HTP 데이터 처리 시작\n",
      "============================================================\n",
      "\n",
      "📂 데이터 로드 중: htp_output1_eng/htp_alpaca_format.json\n",
      "✓ 2257개 샘플 로드 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 설정값 직접 지정 (변경하려면 코드 수정)\n",
    "input_file = 'htp_output1_eng/htp_alpaca_format.json'\n",
    "output_dir = './htp_processed_eng'\n",
    "use_jsonl = True\n",
    "use_json = False\n",
    "report_filename = 'processing_report.txt'\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📝 HTP 데이터 처리 시작\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# 데이터 로드\n",
    "print(f\"📂 데이터 로드 중: {input_file}\")\n",
    "try:\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 파일을 찾을 수 없습니다: {input_file}\")\n",
    "   \n",
    "except json.JSONDecodeError:\n",
    "    print(f\"❌ JSON 파일 형식이 잘못되었습니다: {input_file}\")\n",
    "\n",
    "print(f\"✓ {len(raw_data)}개 샘플 로드 완료\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf7534f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2257/2257 처리 완료                    \n",
      "\n",
      "╔══════════════════════════════════════════════════════════════╗\n",
      "║           HTP 데이터 처리 리포트                              ║\n",
      "╚══════════════════════════════════════════════════════════════╝\n",
      "\n",
      "📊 기본 통계:\n",
      "  - 총 샘플 수: 2257\n",
      "  - Input 평균 길이: 9.2 단어\n",
      "  - Output 평균 길이: 41.3 단어\n",
      "  - Input 최소/최대 길이: 4 / 22 단어\n",
      "\n",
      "📈 카테고리 분포:\n",
      "  - house          : 1023 ( 45.3%) █████████░░░░░░░░░░░\n",
      "  - person         :  894 ( 39.6%) ███████░░░░░░░░░░░░░\n",
      "  - tree           :  691 ( 30.6%) ██████░░░░░░░░░░░░░░\n",
      "  - other          :  252 ( 11.2%) ██░░░░░░░░░░░░░░░░░░\n",
      "\n",
      "✅ 처리 완료!\n",
      "   - Instruction 변환: 한국어 → 영어\n",
      "   - Category 추출: input 텍스트 기반\n",
      "   - 데이터 검증: 완료\n",
      "\n",
      "처리 시간: 2257 샘플\n",
      "\n",
      "📄 리포트 저장: htp_processed_eng\\processing_report.txt\n",
      "\n",
      "💾 데이터 저장 중...\n",
      "\n",
      "✓ JSONL 저장: htp_processed_eng\\htp_data_processed.jsonl\n",
      "\n",
      "✨ 모든 처리가 완료되었습니다!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 프로세서 생성 및 데이터 처리\n",
    "processor = HTPDataProcessor()\n",
    "processed_data, failed_data = processor.process_data(raw_data)\n",
    "\n",
    "if failed_data:\n",
    "    print(f\"\\n⚠️ {len(failed_data)}개 샘플 처리 실패\\n\")\n",
    "\n",
    "# 통계 생성 및 리포트\n",
    "report_path = Path(output_dir) / report_filename\n",
    "processor.generate_report(processed_data, str(report_path))\n",
    "\n",
    "# 데이터 저장\n",
    "print(\"💾 데이터 저장 중...\\n\")\n",
    "\n",
    "if use_jsonl or (not use_json):\n",
    "    processor.save_to_jsonl(\n",
    "        processed_data,\n",
    "        str(Path(output_dir) / 'htp_data_processed.jsonl')\n",
    "    )\n",
    "\n",
    "if use_json or (not use_jsonl):\n",
    "    processor.save_to_json(\n",
    "        processed_data,\n",
    "        str(Path(output_dir) / 'htp_data_processed.json')\n",
    "    )\n",
    "\n",
    "print(\"\\n✨ 모든 처리가 완료되었습니다!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70d56387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSONL 저장: ./htp_processed_eng/filtered_data.jsonl\n",
      "필터링 결과: 1453개 (전체 2257개 중)\n"
     ]
    }
   ],
   "source": [
    "# 단일 카테고리만 추출\n",
    "training_data = [item for item in processed_data\n",
    "                 if item['category'] not in ('other',) and ',' not in item['category']]\n",
    "\n",
    "# 저장\n",
    "from pathlib import Path\n",
    "Path('./htp_processed_eng').mkdir(exist_ok=True)\n",
    "processor.save_to_jsonl(training_data, './htp_processed_eng/filtered_data.jsonl')\n",
    "\n",
    "# 확인\n",
    "print(f\"필터링 결과: {len(training_data)}개 (전체 {len(processed_data)}개 중)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413fce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "필터링된 데이터 통계\n",
      "\n",
      "총 샘플: 1453개\n",
      "  tree: 408개\n",
      "  person: 458개\n",
      "  house: 587개\n",
      "\n",
      "Input  길이: 평균 8.6 단어\n",
      "Output 길이: 평균 40.2 단어\n",
      "\n",
      "데이터 품질: ✓ 양호\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"\\n필터링된 데이터 통계\\n\")\n",
    "\n",
    "# 1. 기본 정보\n",
    "print(f\"총 샘플: {len(training_data)}개\")\n",
    "\n",
    "# 2. 카테고리\n",
    "categories = Counter(item['category'] for item in training_data)\n",
    "for cat, count in categories.items():\n",
    "    print(f\"  {cat}: {count}개\")\n",
    "\n",
    "# 3. 길이\n",
    "input_lens = [len(item['input'].split()) for item in training_data]\n",
    "output_lens = [len(item['output'].split()) for item in training_data]\n",
    "\n",
    "print(f\"\\nInput  길이: 평균 {sum(input_lens)/len(input_lens):.1f} 단어\")\n",
    "print(f\"Output 길이: 평균 {sum(output_lens)/len(output_lens):.1f} 단어\")\n",
    "\n",
    "# 4. 품질\n",
    "empty_in = sum(1 for x in training_data if not x['input'].strip())\n",
    "empty_out = sum(1 for x in training_data if not x['output'].strip())\n",
    "\n",
    "print(f\"\\n데이터 품질: {'✓ 양호' if empty_in == 0 and empty_out == 0 else '⚠ 확인'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08ddad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
