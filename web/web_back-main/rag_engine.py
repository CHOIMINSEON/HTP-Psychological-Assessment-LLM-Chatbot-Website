# rag_engine.py
import torch
import json
from typing import List, Dict
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.documents import Document
from embeddings import vectorstore, cross_encoder


# ===============================================================
# 1) Multi Query Generator (OpenAI GPT-4o-mini)
# ===============================================================

class MultiQueryGenerator(BaseModel):
    queries: List[str] = Field(description="ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡")


class AdvancedQueryRewriter:
    def __init__(self, model_name="gpt-4o", temperature=0):
        self.llm = ChatOpenAI(
            model_name=model_name,
            temperature=temperature,
            max_tokens=1000
        )
        self.parser = JsonOutputParser(pydantic_object=MultiQueryGenerator)

        self.template = """
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•©ë‹ˆë‹¤.

        # ì§€ì¹¨
        1. ì•„ë˜ì˜ history ì— í¬í•¨ëœ ëª¨ë“  ì´ì „ ì§ˆì˜/ê²€ìƒ‰ë¬¸ì„œ/ë‹µë³€ì„ ì°¸ê³ í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
        2. í˜„ì¬ ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ìƒëµëœ ê²½ìš°, history ë¥¼ ì°¸ê³ í•´ ë¬¸ë§¥ìƒ ì™„ì „í•œ ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.
        3. ì´ì „ ëŒ€í™”ê°€ ì—†ê±°ë‚˜ ê´€ë ¨ì´ ì—†ëŠ” ê²½ìš° í˜„ì¬ ì§ˆë¬¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        4. ë°˜ë“œì‹œ ëª…í™•í•˜ê³  ê²€ìƒ‰ì— ì í•©í•œ ì¿¼ë¥¼ ìƒì„±í•˜ì„¸ìš”.
        6. ì¶œë ¥ì€ ì¬ìƒì„±ëœ ì¿¼ë¦¬ ë¬¸ìì—´ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        7. í˜„ì¬ ë¬¸ì¥ì´ ì—¬ëŸ¬ ì†ì„±ì„ í¬í•¨í•˜ê³  ìˆë‹¤ë©´, ê°ê°ì„ ë³„ë„ì˜ ì¿¼ë¦¬ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.
        8. ê° ì¿¼ë¦¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ ë²¡í„° DBì—ì„œ ê²€ìƒ‰ë  ìˆ˜ ìˆë„ë¡ ì™„ì „í•˜ê³  ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.
        10. ë¶„ë¦¬ëœ ì¿¼ë¦¬ë“¤ì„ í•©ì³¤ì„ ë•Œ ì›ë˜ ì¿¼ë¦¬ì˜ ì˜ë¯¸ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.

        ì „ì²´ ëŒ€í™”: {history_text}
        ì‚¬ìš©ì ì§ˆë¬¸: {current_query}

        ì¶œë ¥ ì˜ˆì‹œ:
        {{
            "queries": ["ì¿¼ë¦¬1", "ì¿¼ë¦¬2"]
        }}

        ì˜ˆì‹œ :
        í˜„ì¬ ì§ˆë¬¸ì´ "ì„œìš¸ì€ ? ê·¸ë¦¬ê³  ë§›ì§‘ì€?"ì´ê³  ì´ì „ ëŒ€í™”ê°€ "í•œêµ­ì˜ ê´€ê´‘ì§€ ì¶”ì²œí•´ì¤˜"ë¼ë©´,
        {{{{
            "queries" : ["ì„œìš¸ì˜ ê´€ê´‘ì§€ ì¶”ì²œí•´ì¤˜", "ì„œìš¸ì˜ ë§›ì§‘ ì¶”ì²œí•´ì¤˜"]
        }}}}

        ë‹¨ì¼ ì¿¼ë¦¬ì¸ ê²½ìš°:
        {{{{
            "queries" : ["í•œêµ­ì˜ ê´€ê´‘ì§€ ì¶”ì²œí•´ì¤˜"]
        }}}}

        {format_instructions}
        """

        self.prompt = PromptTemplate(
            input_variables=["history_text", "current_query"],
            template=self.template,
        )

    def rewrite_query(self, history_text: str, current_query: str) -> List[str]:
        if not history_text.strip():
            history_text = "ëŒ€í™” ê¸°ë¡ ì—†ìŒ"

        format_instructions = self.parser.get_format_instructions()

        prompt = self.prompt.format(
            history_text=history_text,
            current_query=current_query,
            format_instructions=format_instructions
        )

        llm_response = self.llm.invoke(prompt).content

        try:
            data = json.loads(llm_response)
            return data.get("queries", [current_query])
        except:
            print("âš  JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
            return [current_query]


# ===============================================================
# 2) Multi Query Retriever
# ===============================================================

class MultiQueryRetriever:
    def __init__(self, vectorstore, query_rewriter):
        self.vectorstore = vectorstore
        self.cross_encoder = cross_encoder
        self.history = []
        self.query_rewriter = query_rewriter

    def build_history_text(self):
        out = ""
        for h in self.history:
            out += f"[USER]\n{h['user_query']}\n"
            out += f"[REWRITTEN]\n{h['rewritten_queries']}\n"
            out += "[DOCS]\n"
            for d in h["retrieved_docs"]:
                out += f"- {d['content']}\n"
            out += f"[ANSWER]\n{h['final_answer']}\n"
            out += "-" * 30 + "\n"
        return out

    def retrieve(self, query: str, category: str, num_docs=5):

        history_text = self.build_history_text()
        rewritten_queries = self.query_rewriter.rewrite_query(history_text, query)

        print("ì¬ì‘ì„±ëœ ì¿¼ë¦¬:", rewritten_queries)

        all_docs = []
        seen = set()

        for q in rewritten_queries:
            # 1) ì¿¼ë¦¬ë‹¹ 5ê°œ ê²€ìƒ‰
            docs = self.vectorstore.similarity_search(
                q,
                k=num_docs,
                filter={"category": category}
            )

            if not docs:
                continue

            # 2) ì¿¼ë¦¬ë³„ CrossEncoder Top-2 ì¶”ì¶œ
            pairs = [(q, d.page_content) for d in docs]
            scores = self.cross_encoder.predict(pairs)

            # numpy/torch ë³€í™˜ ì²˜ë¦¬
            if hasattr(scores, "detach"):
                scores = scores.detach().cpu().numpy()
            scores = scores.squeeze().tolist()

            reranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
    
            # â˜… ì—¬ê¸°ì„œ ì¿¼ë¦¬ë‹¹ Top-2ë§Œ ìœ ì§€
            top_docs = [doc for doc, score in reranked[:2]]

            # 3) ìµœì¢… í›„ë³´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            for d in top_docs:
                if d.page_content not in seen:
                    all_docs.append(d)
                    seen.add(d.page_content)

        return all_docs, rewritten_queries


# ===============================================================
# 3) RAG ê²€ìƒ‰ ì—”ì§„ (ê²€ìƒ‰ ì „ìš©)
# ===============================================================

# RAG ê²€ìƒ‰ í´ë˜ìŠ¤ (í•´ì„ ìƒì„± ì—†ì´ ê²€ìƒ‰ë§Œ ìˆ˜í–‰)
class AdvancedConversationalRAG:
    def __init__(self, vectorstore, query_model_name="gpt-4o"):
        """
        Hugging Faceì— ì—…ë¡œë“œëœ fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•œ ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ
        Args:
            vectorstore: ë²¡í„° ì €ì¥ì†Œ
            query_model_name: ì¿¼ë¦¬ ì¬ì‘ì„±ìš© OpenAI ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gpt-4o)
        """
        # historyì— ëŒ€í™” ì €ì¥
        self.history = []
        
        # ì¿¼ë¦¬ ì¬ìƒì„±ê¸° (OpenAI GPT ì‚¬ìš©)
        self.query_rewriter = AdvancedQueryRewriter(model_name=query_model_name)
        
        # ê°ê°ì˜ ê²€ìƒ‰ì–´ë¥¼ ë”°ë¡œ ê²€ìƒ‰í•œ ë’¤ì— ê²€ìƒ‰ê²°ê³¼ë¥¼ ì·¨í•©í•˜ëŠ” ë©€í‹°ì¿¼ë¦¬ ë¦¬íŠ¸ë¦¬ë²„
        self.retriever = MultiQueryRetriever(vectorstore=vectorstore, query_rewriter=self.query_rewriter)
        
        print("âœ… RAG ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (ê²€ìƒ‰ ì „ìš© ëª¨ë“œ)")
    
    def search_only(self, current_query: str, category: str) -> Dict:
        """
        ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•˜ê³  í•´ì„ì€ ìƒì„±í•˜ì§€ ì•ŠìŒ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ /interpret_single ì‚¬ìš©)
        """
        print("ğŸ” [RAG] ê²€ìƒ‰ ì „ìš© ëª¨ë“œ - í•´ì„ ìƒì„± ìŠ¤í‚µ")
        
        # ê´€ë ¨ ë¬¸ì„œê²€ìƒ‰ë§Œ ìˆ˜í–‰
        docs, rewritten_queries = self.retriever.retrieve(current_query, category)
        
        # ë¬¸ì„œ ë‚´ìš©ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        rag_docs = [doc.page_content for doc in docs]
        
        print(f"âœ… [RAG] ê²€ìƒ‰ ì™„ë£Œ - {len(rag_docs)}ê°œ ë¬¸ì„œ ë°œê²¬")
        
        # ê²°ê³¼ ë°˜í™˜ (í•´ì„ ì—†ì´ ê²€ìƒ‰ ê²°ê³¼ë§Œ)
        return {
            "query": current_query,
            "rewritten_queries": rewritten_queries,
            "source_documents": docs,
            "rag_docs": rag_docs
        }
