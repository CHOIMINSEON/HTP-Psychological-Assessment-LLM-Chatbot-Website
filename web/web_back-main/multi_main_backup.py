from dotenv import load_dotenv
load_dotenv()
from embeddings import vectorstore           # ë²¡í„° DB
from rag_engine import AdvancedConversationalRAG  # ë©€í‹°ì¿¼ë¦¬ RAG ì—”ì§„

from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional, Dict, Any
from caption import generate_caption
from model import generate_with_qwen
from fastapi.middleware.cors import CORSMiddleware
import logging
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI()
# CORS ì„¤ì • - ë” ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì¶œì²˜ í—ˆìš©
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# -------------------------------------
# RAG ì—”ì§„ ì´ˆê¸°í™”
# -------------------------------------
rag = AdvancedConversationalRAG(vectorstore)

# ----------------------------- #
# 1) ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
# ----------------------------- #
class CaptionRequest(BaseModel):
    image_base64: str

@app.post("/caption")
def caption(req: CaptionRequest):
    logger.info("=" * 80)
    logger.info("ğŸ“¸ [CAPTION] ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Florence-2-large")
    logger.info(f"ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {len(req.image_base64)} bytes")
    
    caption = generate_caption(req.image_base64)
    
    logger.info(f"âœ… [CAPTION] ìƒì„±ëœ ìº¡ì…˜: {caption}")
    logger.info("=" * 80)
    return {"caption": caption}

# ----------------------------- #
# 2) ë©€í‹°ì¿¼ë¦¬ ê¸°ë°˜ RAG ê²€ìƒ‰
# ----------------------------- #
class RagRequest(BaseModel):
    caption: str
    image_type: str    # "ì§‘" | "ë‚˜ë¬´" | "ì‚¬ëŒ"

@app.post("/rag")
def rag_search_api(req: RagRequest):
    logger.info("=" * 80)
    logger.info("ğŸ” [RAG] RAG ê²€ìƒ‰ ì‹œì‘ (ê²€ìƒ‰ ì „ìš© ëª¨ë“œ)")
    logger.info("ğŸ¤– ì¿¼ë¦¬ ì¬ì‘ì„± ëª¨ë¸: GPT-4o (OpenAI)")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì…: {req.image_type}")
    
    try:
        # search_only ë©”ì„œë“œ ì‚¬ìš© (í•´ì„ ìƒì„± ì œê±°)
        result = rag.search_only(req.caption, req.image_type)
        
        logger.info(f"âœ… [RAG] ê²€ìƒ‰ ì™„ë£Œ")
        logger.info(f"ì¬ì‘ì„±ëœ ì¿¼ë¦¬: {result.get('rewritten_queries', [])}")
        logger.info(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result.get('rag_docs', []))}")
        
        # ê° ë¬¸ì„œì˜ ë‚´ìš© ì¶œë ¥
        for idx, doc in enumerate(result.get('rag_docs', []), 1):
            logger.info(f"\nğŸ“„ ë¬¸ì„œ {idx}:")
            logger.info(f"  ë‚´ìš©: {doc[:200]}..." if len(doc) > 200 else f"  ë‚´ìš©: {doc}")
        
        logger.info("=" * 80)
        return result
        
    except Exception as e:
        logger.error(f"âŒ [RAG] ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        logger.info("=" * 80)
        
        # ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ì—ëŸ¬ ë°œìƒ ì‹œ)
        return {
            "rewritten_queries": [req.caption],
            "rag_docs": [],
            "error": str(e)
        }

# ----------------------------- #
# 3) Qwen ë¡œë¼ ëª¨ë¸ ê°œë³„ í•´ì„
# ----------------------------- #
class InterpretSingle(BaseModel):
    caption: str
    rag_docs: list
    image_type: str

@app.post("/interpret_single")
def interpret_single(req: InterpretSingle):
    logger.info("=" * 80)
    logger.info("ğŸ§  [INTERPRET_SINGLE] ê°œë³„ í•´ì„ ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Qwen (helena29/Qwen2.5_LoRA_for_HTP)")
    logger.info(f"ì´ë¯¸ì§€ íƒ€ì…: {req.image_type}")
    logger.info(f"ì…ë ¥ ìº¡ì…˜: {req.caption}")
    logger.info(f"RAG ë¬¸ì„œ ìˆ˜: {len(req.rag_docs)}")
    
    # RAG ë¬¸ì„œê°€ ìˆìœ¼ë©´ ì°¸ê³ ë¬¸í—Œìœ¼ë¡œ í™œìš©
    reference_context = ""
    if req.rag_docs and len(req.rag_docs) > 0:
        reference_context = f"\n\nReference Literature (Korean):\n{' '.join(req.rag_docs)}"
        logger.info("âœ… RAG ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í•´ì„")
    else:
        logger.info("âš ï¸  RAG ë¬¸ì„œ ì—†ìŒ - ì¼ë°˜ì ì¸ HTP ì›ë¦¬ë¡œ í•´ì„")
    
    # ëª¨ë¸ì˜ fine-tuning í˜•ì‹ì— ë§ì¶˜ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°
    prompt = f"""Please provide a psychological interpretation of the following HTP test image caption.

Drawing Type: {req.image_type}
Caption: {req.caption}{reference_context}

Provide a detailed psychological interpretation analyzing the visual features and their psychological significance. Structure your response as:

1. **Feature Analysis**: Identify and interpret specific visual elements from the caption (e.g., size, placement, details, omissions).
2. **Psychological Synthesis**: Integrate these features into a comprehensive psychological assessment of emotional state, personality traits, and coping mechanisms.

Use professional psychological terminology and maintain an analytical, empathetic tone. Write the response in English."""
    
    logger.info(f"\nğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} characters")

    result = generate_with_qwen(prompt)
    
    logger.info(f"âœ… [INTERPRET_SINGLE] í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ í•´ì„: {result}")
    logger.info("=" * 80)
    return {"interpretation": result}

# ----------------------------- #
# 4) GPT ë²ˆì—­ API
# ----------------------------- #
from openai import OpenAI
client = OpenAI()

class TranslateRequest(BaseModel):
    text: str

@app.post("/translate")
def translate(req: TranslateRequest):
    """ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    logger.info("ğŸŒ [TRANSLATE] ë²ˆì—­ ì‹œì‘")
    logger.info(f"ì›ë¬¸ (ì˜ì–´): {req.text[:100]}...")
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a professional translator. Translate the given English text to natural Korean. Only provide the translation, nothing else."},
                {"role": "user", "content": req.text}
            ],
            temperature=0.3
        )
        
        translated = response.choices[0].message.content
        logger.info(f"ë²ˆì—­ ê²°ê³¼ (í•œêµ­ì–´): {translated[:100]}...")
        return {"translated": translated}
        
    except Exception as e:
        logger.error(f"âŒ [TRANSLATE] ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")
        return {"translated": req.text}  # ì‹¤íŒ¨ì‹œ ì›ë¬¸ ë°˜í™˜

# ----------------------------- #
# 5) Qwen ëª¨ë¸ë¡œ ì¶”ê°€ ì§ˆë¬¸ ìƒì„± (ì˜ì–´)
# ----------------------------- #

class QuestionReq(BaseModel):
    conversation: list
    interpretations: Optional[Dict[str, Any]] = None  # { house: str, tree: str, person: str }

@app.post("/questions")
def questions(req: QuestionReq):
    logger.info("=" * 80)
    logger.info("â“ [QUESTIONS] ì¶”ê°€ ì§ˆë¬¸ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: Qwen (helena29/Qwen2.5_LoRA_for_HTP)")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    for idx, msg in enumerate(req.conversation[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ ë¡œê¹…
        logger.info(f"  ë©”ì‹œì§€ {idx}: {msg.get('role')} - {msg.get('content')[:100]}...")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
    conversation_text = "\n".join([
        f"{msg.get('role').upper()}: {msg.get('content')}" 
        for msg in req.conversation
    ])

    # í•´ì„ ì»¨í…ìŠ¤íŠ¸(ìˆëŠ” ê²½ìš°) í¬í•¨
    interp_text = ""
    if req.interpretations:
        house = req.interpretations.get("house", "")
        tree = req.interpretations.get("tree", "")
        person = req.interpretations.get("person", "")
        interp_text = (
            "\nHTP Individual Interpretations (Korean):\n"
            f"- House: {house}\n"
            f"- Tree: {tree}\n"
            f"- Person: {person}\n"
        )

    prompt = f"""
You are a professional psychologist conducting an HTP (House-Tree-Person) assessment interview.

Conversation History:
{conversation_text}
{interp_text}

Task: Ask exactly ONE concrete follow-up question (English) that probes observable drawing decisions and missing elements related to the HTP drawings.

Strict Requirements:
- One sentence only, must end with a question mark.
- Refer explicitly to the drawing (House/Tree/Person) or a concrete feature inferred from the interpretation text.
- Focus on drawing-specific clarifications, such as:
  â€¢ reason for emphasizing/omitting a feature (chimney, windows, roots, hands/feet, etc.)
  â€¢ placement on the page (top/bottom/left/right, margins)
  â€¢ size/proportion or balance (very small/large, centered, crowded/empty background)
  â€¢ line quality/pressure or shading (pressed hard, repeated strokes)
  â€¢ order of drawing or number of erasures/redo actions
- Do NOT ask meta/process questions (e.g., â€œShall I continue?â€, â€œProvide more contextâ€).
- Do NOT ask about the test procedure itself; ask about the drawing choices and feelings during drawing.
- No preambles, no explanations, output only the question.
"""
    
    result = generate_with_qwen(prompt)

    # ê²°ê³¼ í›„ì²˜ë¦¬: í•œ ë¬¸ì¥(ì§ˆë¬¸ë¶€í˜¸ë¡œ ëë‚˜ëŠ”)ë§Œ ë°˜í™˜
    try:
        import re

        text = (result or "").strip()
        # ì¤„ë°”ê¿ˆ/ë¶ˆë¦¿/ë²ˆí˜¸ ì œê±°
        text = re.sub(r"^[\-\d\.)\s]+", "", text)
        # ì²˜ìŒ ë¬¼ìŒí‘œê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ì˜ ë¬¸ì¥ë§Œ ì·¨ë“
        m = re.search(r"(.+?\?)", text, flags=re.S)
        if m:
            cleaned = m.group(1)
        else:
            # ë¬¼ìŒí‘œê°€ ì—†ë‹¤ë©´ ì²« ì¤„ë§Œ ì‚¬ìš©, ê¸¸ì´ ì œí•œ
            cleaned = text.splitlines()[0] if text else ""
            cleaned = cleaned[:200]
        cleaned = cleaned.strip().strip('"â€œâ€')
    except Exception as e:
        logger.warning(f"[QUESTIONS] í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        cleaned = result

    logger.info(f"âœ… [QUESTIONS] ìµœì¢… ì§ˆë¬¸: {cleaned}")
    logger.info("=" * 80)
    return {"question": cleaned}

# ----------------------------- #
# 6) ìµœì¢… í•´ì„ (GPT-4o)
# ----------------------------- #
class InterpretFinal(BaseModel):
    single_results: dict
    conversation: list
    user_info: Optional[Dict[str, Any]] = None  # { name: str, age: str/int, gender: 'male'|'female' }

@app.post("/interpret_final")
def interpret_final(req: InterpretFinal):
    logger.info("=" * 80)
    logger.info("ğŸ¯ [INTERPRET_FINAL] ìµœì¢… í•´ì„ ìƒì„± ì‹œì‘")
    logger.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: GPT-4o (OpenAI)")
    logger.info(f"ì§‘ í•´ì„: {req.single_results.get('house', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ë‚˜ë¬´ í•´ì„: {req.single_results.get('tree', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ì‚¬ëŒ í•´ì„: {req.single_results.get('person', 'ì—†ìŒ')[:100]}...")
    logger.info(f"ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(req.conversation)}")
    
    # ì‚¬ìš©ì ì •ë³´ ë°˜ì˜
    name = None
    age = None
    gender = None
    if req.user_info:
        name = req.user_info.get('name')
        age = req.user_info.get('age')
        gender = req.user_info.get('gender')

    # ì„±ë³„/ë‚˜ì´ ì„¤ëª… ë¬¸êµ¬ êµ¬ì„± (í•´ì„ ì°¸ê³ ìš©)
    demo_context_lines = []
    if age:
        demo_context_lines.append(f"- ê²€ì‚¬ìì˜ ë‚˜ì´: {age} (ë°œë‹¬ ë‹¨ê³„ ë° ì—°ë ¹ íŠ¹ì„±ì„ ê³ ë ¤í•´ í•´ì„ì— ì°¸ê³ )\n")
    if gender:
        ko_gender = 'ì—¬ì„±' if str(gender).lower() == 'female' else ('ë‚¨ì„±' if str(gender).lower() == 'male' else str(gender))
        demo_context_lines.append(f"- ê²€ì‚¬ìì˜ ì„±ë³„: {ko_gender} (ì„±ë³„ì— ë”°ë¥¸ ì¼ë°˜ì  ê²½í–¥ì„ ì°¸ê³ í•˜ë˜, ê³ ì •ê´€ë…ì€ í”¼í•  ê²ƒ)\n")
    demo_context = "".join(demo_context_lines)

    # GPT ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        {
            "role": "system",
            "content": "You are a professional psychological counselor specializing in HTP (House-Tree-Person) test interpretation. Provide comprehensive, insightful psychological analysis in Korean."
        },
        {
            "role": "user",
            "content": f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ HTP ê²€ì‚¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‹¬ë¦¬ í•´ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§‘ í•´ì„ (House Interpretation):
{req.single_results.get('house','N/A')}

ë‚˜ë¬´ í•´ì„ (Tree Interpretation):
{req.single_results.get('tree','N/A')}

ì‚¬ëŒ í•´ì„ (Person Interpretation):
{req.single_results.get('person','N/A')}

ì‚¬ìš©ìì™€ ë‚˜ëˆˆ ëŒ€í™”:
{req.conversation}

ê²€ì‚¬ì ì •ë³´:
{('- ì´ë¦„: ' + str(name) + '\n') if name else ''}{demo_context}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… HTP ì‹¬ë¦¬ í•´ì„ì„ 5ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì¤‘ìš” ì§€ì¹¨:
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ê° ê·¸ë¦¼(ì§‘, ë‚˜ë¬´, ì‚¬ëŒ)ì˜ ê°œë³„ í•´ì„ì„ í†µí•©í•˜ì—¬ ì „ì²´ì ì¸ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë¶„ì„í•˜ì„¸ìš”
- ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” í•´ì„ì„ ì œê³µí•˜ì„¸ìš”
- ì „ë¬¸ì ì´ê³  ë”°ëœ»í•œ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”
- 5ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”
"""
        }
    ]
    
    logger.info(f"ğŸ“ GPT ìš”ì²­ ì „ì†¡ ì¤‘...")
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7,
        max_tokens=2000
    )
    
    result = response.choices[0].message.content
    
    logger.info(f"âœ… [INTERPRET_FINAL] ìµœì¢… í•´ì„ ì™„ë£Œ")
    logger.info(f"ìƒì„±ëœ ìµœì¢… í•´ì„ (ì²˜ìŒ 200ì): {result[:200]}...")
    logger.info("=" * 80)
    return {"final": result}
