# 📚 HTP 해석 데이터 종합 청킹 및 추출 파이프라인

## 💡 프로젝트 개요

이 프로젝트는 RAG(Retrieval-Augmented Generation) 시스템의 기초 데이터를 구축하기 위한 두 가지 핵심 전처리 단계를 통합합니다.

1.  **HTP 해석본 텍스트 청킹:** 수기본 텍스트를 정제하고, 의미 단위로 분할(청킹)하며, '집', '나무', '사람' 카테고리를 정확하게 태깅합니다.
2.  **PDF 멀티모달 추출:** HTP 반응특성 PDF에서 **이미지(레이아웃)와 XML(텍스트)**을 활용하여 LLM(GPT-4.1-mini)이 복잡한 테이블 정보를 정확하게 추출하도록 합니다.

최종적으로 이 두 단계를 통해 얻은 고품질의 구조화된 텍스트는 임베딩 모델 학습 및 RAG 코퍼스로 활용됩니다.

---

## 🛠️ 기술 스택 (Tech Stack)

| 구분 | 기술 / 라이브러리 | 용도 |
| :--- | :--- | :--- |
| **PDF 처리** | `fitz` (PyMuPDF) | PDF 페이지를 이미지 및 XML 텍스트로 추출 |
| **LLM 기반 추출** | `OpenAI (GPT-4.1-mini)` | Multi-modal 프롬프트를 통한 테이블 구조 해석 및 텍스트 추출 |
| **텍스트/청킹** | `re`, `langchain` | 텍스트 정제, 청킹, 카테고리 태깅 및 `Document` 객체 생성 |
| **데이터 처리** | `PIL`, `numpy`, `base64` | 이미지 처리 및 인코딩 |

---

## 💻 단계 1: HTP 해석본 텍스트 청킹 및 카테고리 태깅

이 단계는 `/content/브런치_집-나무-사람 해석 수기본.txt` 파일의 내용을 정제하고 RAG 코퍼스에 적합한 `Document` 형태로 변환합니다.

### 1. 텍스트 정규화 및 청킹 (Chunking)

* **1차 분리:** 텍스트를 **번호 + 마침표** (`\d+\.`)를 기준으로 주요 항목을 청크로 분리합니다.
* **2차 분리:** 청크 내 **`■` 또는 `*` 기호**를 기준으로 세부 항목을 추출하여 최종 청크를 생성합니다.

### 2. 카테고리 태깅 및 보정

* `detect_category` 함수를 이용해 청크 내용에 따라 초기 카테고리('집', '나무', '사람')를 자동 할당합니다.
* 자동 할당된 카테고리를 **인덱스 범위 기반**으로 다시 수동 보정하여 데이터의 정확도를 높입니다.
* **결과:** `page_content`와 `metadata`(`category`, `chunk_index`)를 포함하는 `langchain_docs` 리스트로 저장됩니다.

### 3. 데이터 정제 (Filtering)

* 내용의 길이가 **10자 이하**인 불필요한 청크를 제거합니다.
* **최종 결과:** 총 194개 청크 중 3개 제거되어 **191개**의 고품질 학습 문서가 확보됩니다.

---

## 💻 단계 2: PDF 멀티모달 텍스트 추출

이 단계는 복잡한 테이블 구조를 가진 `HTP해석.pdf` 파일을 LLM을 통해 정확히 텍스트화합니다.

### 1. PDF 페이지 변환 (PNG 및 XML)

* **이미지 변환:** `process_pdf` 함수로 PDF 페이지를 고해상도 **PNG 이미지**로 변환 (시각적 레이아웃 정보 확보).
* **XML 변환:** `convert_pdf_to_xml` 함수로 PDF 페이지의 디지털 텍스트를 **XML 구조**로 변환 (텍스트 누락 방지).

### 2. Multi-modal LLM 호출

페이지 번호에 맞게 매칭된 PNG 이미지와 XML 텍스트를 GPT-4.1-mini에 입력합니다.

* **프롬프트 지침:** 모델에게 요약 없이, **테이블을 구조를 해석하여 풀어서 작성**하도록 엄격하게 지시합니다. XML은 텍스트 누락 방지를 위한 보조 정보로 사용됩니다.
* **모델 입력:** Base64 이미지 + XML 텍스트 + 시스템 프롬프트.
* **결과:** 추출된 텍스트는 `{ 'content': ..., 'source': 'page_x.png' }` 형식의 리스트로 저장됩니다.

---

## ✅ 최종 결과물

두 단계의 파이프라인을 거쳐 **HTP 해석에 특화된 두 종류의 고품질 텍스트 코퍼스**가 준비됩니다. 이 데이터는 다음 단계인 **임베딩 모델 파인튜닝** 및 실제 **RAG 기반 검색 시스템** 구축에 활용될 핵심 자원입니다.
